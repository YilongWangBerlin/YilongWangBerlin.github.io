<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Obsidian Vault]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>lib/media/favicon.png</url><title>Obsidian Vault</title><link></link></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Tue, 23 Apr 2024 08:33:16 GMT</lastBuildDate><atom:link href="lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Tue, 23 Apr 2024 08:33:09 GMT</pubDate><ttl>60</ttl><dc:creator></dc:creator><item><title><![CDATA[Mikro_06]]></title><description><![CDATA[<br><br><br><img src="mikro/20230203203903.png" target="_self"> <br><img src="mikro/20230203203935.png" target="_self"><br>
<img src="mikro/20230203203958.png" target="_self"><br>
<img src="mikro/20230203204025.png" target="_self"><br>
<img src="mikro/20230203204056.png" target="_self"> <br><br>####Neues Haushaltsoptimum nach Preiserhoehung von Gut 1:<br>
<img src="mikro/20230204003627.png" target="_self"> <br>
<br>A:HHO vor Preisaenderung: <br>Ursachen:<br>
<br>Substitutionsverhaeltnis
<br>Realeinkommen
<br><br><img src="mikro/20230204005508.png" target="_self"> <br>
<br>A:HHO vor Preisaenderung:
<br>C:HHO nach Preisaenderung:
<br>B:HHO nach Preisaenderung bei Kaufkrafterhaltung(durch Einnkommenskompensation):
<br> <br><br>
Substitutionseffekt ist immer der Preisaenderung entgegengesetzt! <br><br><img src="mikro/20230204011052.png" target="_self"><br>
<br>
<br>normales Gut: <br>inferiores Gut: <br><br><br>
<br>gewoehnliches Gut: <br>Giffen-Gut: <br><br><img src="mikro/20230205103044.png" target="_self"><br>
<img src="mikro/20230205103153.png" target="_self"><br>
<img src="mikro/20230205103256.png" target="_self"> ]]></description><link>mikro/mikro_06.html</link><guid isPermaLink="false">Mikro/Mikro_06.md</guid><pubDate>Tue, 23 Apr 2024 08:32:19 GMT</pubDate><enclosure url="mikro/20230203203903.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;mikro/20230203203903.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Mikro_12]]></title><description><![CDATA[<br><br><br>Bestimmung des Konkurrenzgleichgewichtes fÃ¼r 2 GÃ¼t, 2 Konsumenten, allg. Cobb-Douglas PrÃ¤ferenzen<br>
<img src="mikro/20230206154832.png" target="_self"><br>
<img src="mikro/20230206154915.png" target="_self"><br>
<img src="mikro/20230206174217.png" target="_self"><br>
<img src="mikro/img_045039d5abaf-1.jpeg" target="_self"><br><br>
<br>
<br>Nettonachfrage = Bruttonachfrage - Erstausstattung
<br>wenn Nettonachfrage &gt; 0, Nachfrager
<br>wenn Nettonachfrage &lt; 0, Anbieter
<br><img src="mikro/20230206175857.png" target="_self"> <br><br><img src="mikro/20230206180014.png" target="_self"> <br><br><img src="mikro/img_5122b71db030-1.jpeg" target="_self"><br><br><img src="mikro/20230206180928.png" target="_self"> ]]></description><link>mikro/mikro_12.html</link><guid isPermaLink="false">Mikro/Mikro_12.md</guid><pubDate>Tue, 23 Apr 2024 08:32:03 GMT</pubDate><enclosure url="mikro/20230206154832.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;mikro/20230206154832.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[index]]></title><description><![CDATA[<br><a data-href="mikro" href="mikro/mikro.html" class="internal-link" target="_self" rel="noopener">mikro</a><br>
<a data-href="Rorg" href="rechnerorganisation/rorg.html" class="internal-link" target="_self" rel="noopener">Rorg</a>]]></description><link>index.html</link><guid isPermaLink="false">index.md</guid><pubDate>Mon, 22 Apr 2024 17:19:20 GMT</pubDate></item><item><title><![CDATA[Rorg]]></title><description><![CDATA[<br><a data-href="Rorg_tut07" href="rechnerorganisation/rorg_tut07.html" class="internal-link" target="_self" rel="noopener">Rorg_tut07</a><br>
<a data-href="Rorg_tut09" href="rechnerorganisation/rorg_tut09.html" class="internal-link" target="_self" rel="noopener">Rorg_tut09</a><br>
<a data-href="Rorg_tut10" href="rechnerorganisation/rorg_tut10.html" class="internal-link" target="_self" rel="noopener">Rorg_tut10</a><br>
<a data-href="Rorg_tut11" href="rechnerorganisation/rorg_tut11.html" class="internal-link" target="_self" rel="noopener">Rorg_tut11</a><br>
<a data-href="Rorg_tut12" href="rechnerorganisation/rorg_tut12.html" class="internal-link" target="_self" rel="noopener">Rorg_tut12</a>]]></description><link>rechnerorganisation/rorg.html</link><guid isPermaLink="false">Rechnerorganisation/Rorg.md</guid><pubDate>Sun, 21 Apr 2024 21:03:26 GMT</pubDate></item><item><title><![CDATA[mikro]]></title><description><![CDATA[<br><a data-href="Mikro_06_" href="mikro/mikro_06_.html" class="internal-link" target="_self" rel="noopener">Mikro_06_</a><br>
<a data-href="Mikro_06" href="mikro/mikro_06.html" class="internal-link" target="_self" rel="noopener">Mikro_06</a><br>
<a data-href="Mikro_07" href="mikro/mikro_07.html" class="internal-link" target="_self" rel="noopener">Mikro_07</a><br>
<a data-href="Mikro_12" href="mikro/mikro_12.html" class="internal-link" target="_self" rel="noopener">Mikro_12</a><br>
<a data-href="Mikro_12" href="mikro/mikro_12.html" class="internal-link" target="_self" rel="noopener">Mikro_12</a><br>
<a data-href="Mikro_vl13" href="mikro/mikro_vl13.html" class="internal-link" target="_self" rel="noopener">Mikro_vl13</a>]]]></description><link>mikro/mikro.html</link><guid isPermaLink="false">Mikro/mikro.md</guid><pubDate>Sun, 21 Apr 2024 21:01:24 GMT</pubDate></item><item><title><![CDATA[Mikro_vl13]]></title><description><![CDATA[<br><br>LÃ¶sungsweg<br>
Nicht Vergessen!!<br><br>
<br>
GÃ¼ter: Konsum C und Arbeit L (bzw. Freizeit R) mit Preisen p bzw. w <br>
Unternehmen: <br>Outputgut: Konsumgut (C) <br>Inputgut: Arbeit (L) (bzw. Freizeit, ) <br> ist das maximal mÃ¶gliche Arbeitsangebot (bzw. maximale mÃ¶gliche Freizeit), z.B. 24 Stunden pro Tag <br>Produktionsfunktion: <br>
Zwei Konsumenten: A, B <br>Nutzenfunktion: ,
<br>Anfangsausstattungen: <br>Unternehmensanteile: <br>Konsument A:
<br>Konsument B: <br>
Konsumenten: <br>Nutzenfunktion: <br>Anfangsausstattungen: <br>Unternehmensanteile: <br>Konsument : <br><br><img src="mikro/20230209113338.png" target="_self"><br>
äºcè½´ç›¸äº¤ç‚¹ä¸º<br><br><img src="mikro/20230209113432.png" target="_self"> <br><br><img src="mikro/20230209113522.png" target="_self"> <br><br><img src="mikro/20230209113600.png" target="_self"> <br><br><img src="mikro/20230209113637.png" target="_self"> <br>
<br>Erstes Theorem der WohlfahrtsÃ¶konomie: Das Konkurrenzgleichgewicht ist Pareto-effizient
<br>Zweites Theorem der WohlfahrtsÃ¶konomie: Wenn alle PrÃ¤ferenzen konvex sind, dann ist jede Pareto-effiziente Allokation ein Gleichgewicht fÃ¼r eine entsprechende Ausstattung
<br><br>sieht Video 17: ProduktionsÃ¶komomie<br><br><img src="mikro/20230209114132.png" target="_self"> <br>
<br>Ein allgemeines Gleichgewicht liegt vor, wenn die Preise genau so sind, dass die MÃ¤rkte fÃ¼r alle GÃ¼ter gerÃ¤umt sind, d.h. die Summe der Nettonachfragen aller Konsumenten nach jedem Gut ist gleich der Summe des Nettoangebots an diesem Gut
<br><br><img src="mikro/20230209114324.png" target="_self"> <br><br><br><img src="mikro/20230211144930.png" target="_self"><br>
<img src="mikro/20230211144953.png" target="_self"><br>
<img src="mikro/20230211145010.png" target="_self"> <br><br> fÃ¼r alle GÃ¼ter<br><br><img src="mikro/20230211145420.png" target="_self"> <br>
<br>
<br> <br><img src="mikro/20230211150241.png" target="_self"> <br><br><img src="mikro/20230211150308.png" target="_self"> <br><br><br><img src="mikro/20230211150650.png" target="_self"><br>
<img src="mikro/20230211150738.png" target="_self"><br>
<img src="mikro/20230211150808.png" target="_self"><br>
<img src="mikro/20230211150831.png" target="_self"><br>
<img src="mikro/20230211150850.png" target="_self"> <br><br><img src="mikro/20230211150915.png" target="_self"> <br><br><img src="mikro/20230211151012.png" target="_self"> ]]></description><link>mikro/mikro_vl13.html</link><guid isPermaLink="false">Mikro/Mikro_vl13.md</guid><pubDate>Sun, 21 Apr 2024 20:29:41 GMT</pubDate><enclosure url="mikro/20230209113338.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;mikro/20230209113338.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Mikro_07]]></title><description><![CDATA[<br><br><br><img src="mikro/20230205120910.png" target="_self"><br>
<img src="mikro/20230205121013.png" target="_self"><br>
<img src="mikro/20230205121041.png" target="_self"><br>
<img src="mikro/20230205121105.png" target="_self"> ]]></description><link>mikro/mikro_07.html</link><guid isPermaLink="false">Mikro/Mikro_07.md</guid><pubDate>Sun, 21 Apr 2024 20:29:41 GMT</pubDate><enclosure url="mikro/20230205120910.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;mikro/20230205120910.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[MikroÃ¶konomik VL06]]></title><description><![CDATA[<br><br><br><img src="mikro/20230203203903.png" target="_self"><br>
<img src="mikro/20230203203935.png" target="_self"><br>
<img src="mikro/20230203203958.png" target="_self"><br>
<img src="mikro/20230203204025.png" target="_self"><br>
<img src="mikro/20230203204056.png" target="_self"><br>
]]></description><link>mikro/mikro_06_.html</link><guid isPermaLink="false">Mikro/Mikro_06_.md</guid><pubDate>Sun, 21 Apr 2024 20:29:41 GMT</pubDate><enclosure url="mikro/20230203203903.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;mikro/20230203203903.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Readme]]></title><description><![CDATA[<br>Hier findest du die Folien, die ich in meinen Tutorien verwende. Sie behandeln den Stoff unvollstÃ¤ndig und sind nur eine ErgÃ¤nzung zum Tutorium. FÃ¼rs lernen empfehle ich euch die Zusatzvideos sehr :)]]></description><link>rechnerorganisation/tut/readme.html</link><guid isPermaLink="false">Rechnerorganisation/tut/Readme.md</guid><pubDate>Sun, 21 Apr 2024 20:27:54 GMT</pubDate></item><item><title><![CDATA[Rorg_tut12]]></title><description><![CDATA[<br><br><br><br><img src="rechnerorganisation/img_b88a7876cfcd-1.jpeg" target="_self"><br>
<img src="rechnerorganisation/20230209205748.png" target="_self"><br>
<img src="rechnerorganisation/img_46ed4549b8b6-1.jpeg" target="_self"><br>
<img src="rechnerorganisation/20230209211444.png" target="_self"><br>
ps æœ¬å›¾ä¸»è¦çœ‹ppt<br><br><img src="rechnerorganisation/20230209211620.png" target="_self"> <br><br><img src="rechnerorganisation/20230209212059.png" target="_self"><br>
å…ˆè¿›å…ˆå‡ºçš„ç®—æ³•ï¼ˆFIFOï¼‰ï¼šé€‰æ‹©åœ¨å†…å­˜ä¸­é©»ç•™æ—¶é—´æœ€ä¹…çš„é¡µé¢äºˆä»¥æ›¿æ¢ã€‚<br><br><img src="rechnerorganisation/20230209212748.png" target="_self"><br>
æœ€è¿‘æœ€ä¹…æœªä½¿ç”¨ç®—æ³•ï¼ˆLRUï¼‰ï¼šé€‰æ‹©è¿‡å»æœ€é•¿æ—¶é—´æœªè¢«è®¿é—®çš„é¡µé¢äºˆä»¥æ›¿æ¢ã€‚<br><br><img src="rechnerorganisation/20230209213148.png" target="_self"> <br>æœ€ä½³æ·˜æ±°ç®—æ³•ï¼ˆOPTï¼‰ï¼šé€‰æ‹©æ°¸ä¸ä½¿ç”¨æˆ–åœ¨æœªæ¥æœ€é•¿æ—¶é—´å†…ä¸å†è¢«è®¿é—®çš„é¡µé¢äºˆä»¥æ›¿æ¢ã€‚<br>
åœ¨tag=4æ—¶å‡ºç°missçš„æƒ…å†µ:<br>
<br>way 0: 3åœ¨æœªæ¥å‡ºç°äº†2æ¬¡
<br>way 1: 0åœ¨æœªæ¥å‡ºç°äº†3æ¬¡
<br>way 2: 1åœ¨æœªæ¥å‡ºç°äº†2æ¬¡
<br>way 3: 2åœ¨æœªæ¥å‡ºç°äº†2æ¬¡
<br>æ›¿æ¢way2çš„ç†ç”±ï¼šå› ä¸ºway 0ï¼Œ2ï¼Œ3çš„å€¼åœ¨æœªæ¥å‡ºç°çš„æ¬¡æ•°ç›¸ç­‰ï¼Œæ ¹æ®fifo,way 2æœ€ä¹…æ²¡æœ‰è¢«è®¿é—®<br><br>TU CLOUD: bit.lz/ROrgTUT<br><img src="rechnerorganisation/20230210102121.png" target="_self"> <br><br>
<br>Problem1 <br>wie findet die Seite("Cache-Block")ins Archiv zurueck?
<br>"Tag": merkt sich Herkunftsort("Blockadress")einer Seite <br>Problem 2 <br>Wo legen wir die Seite in die Ablage("Cache"<br>
)?
<br>z.B beliebige Stelle, wo nach Platz ist("vollassoziativ") <br>Problem 3 <br>Sortierung der Seiten in Ablage?(um Seiten schneller zu finden)
<br>"Cache-Sets": Faecher fuer Seiten mit gleichen "Anfangsbuchstaben" <br>Problem 4 <br>was machen, wenn die Ablage voll ist?
<br>"Ersetzungsstragie": alte Seite ausstauchen und zurueckbringen <br><br><img src="rechnerorganisation/20230210105051.png" target="_self"> <br><br>cache-Typen:<br>
<br>vollassoziati("fully associative"): <br>1.Satz ("Stapel"),wo alle Cache-Block <br>direkt abgebildet("Direct Mapped"): <br>assoziativitaet = 1. jeder Satz enthaelt maximal einen Cache-Block <br>n-fach satz assoziativ: <br>Assoziativtaet = n <br><br>
<br>direkt abgebildet -&gt; Assoziativitaet = 1
<br>Kapazitaet = 8 KiB = 8 * 1024 Bytes = 2^13 Bytes (und nicht 8000 Byte!!)
<br>Cacheblock-Groesse = 2^5 Bytes
<br>32, 8192, 48, 8208, 32, 8224, 48, 8240, 32, 8256<br>
Simulation: â€¢ Index, â€¢ Tag <br>Wie viele Bits hat der Blockoffset? (die Adresse innerhalb des Blocks)<br>
<br>:
<br>Wie viele Bits hat der Index?<br>
<br>Zuerst: wie viele SÃ¤tze gibt es im Cache?
<br>SatzgrÃ¶ÃŸe = (Cacheblock-GrÃ¶ÃŸe â€¢ AssoziativitÃ¤t) = 2^5 Bytes
<br>
<br>
<br>wie viele Bits hat der Tag?<br>
<br>Das wissen wir nicht, mÃ¼ssen wir nicht wissen (sagen wir, es sind genug Bits;-).)
<br>Lustig: wir haben keine vorgegebene GrÃ¶ÃŸe fÃ¼r die Adresse des Prozessor.)
<br>Blockadresse = (Adresse / CacheblockgrÃ¶ÃŸe)<br>
Blockadresse = (Adresse &gt;&gt;(blockoffset Bits))<br>Index = Blockadresse % (2^(Index Bits))<br>
Index = â€¢ Blockadresse &amp; (grÃ¶ÃŸten Index) <br>grÃ¶ÃŸter Index = 2^(index bits) - 1 = 2^8 - 1 = FF16<br>
Tag = Blockadresse / 2^(Index Bits)<br>
Tag = Blockadresse &gt;&gt; (Index â€¢ Bits)<br>
<img src="rechnerorganisation/20230210160153.png" target="_self"> <br><br>
<br>2-fachâ€¢satz-assoziativ - AssoziativitÃ¤t=2
<br>KapazitÃ¤t = 8KiB = 8 â€¢ 1024 Bytes = 2^13 Bytes
<br>CacheblockgrÃ¶ÃŸe = 8 WÃ¶rter = 8â€¢4 Bytes = 2^5 Bytes
<br>ByteaddressengrÃ¶ÃŸe = 40 Bits
<br>Prozessor schickt Byteadresse (1 Byte = 2 Nybble = Hexadezimalziffer):<br>
a)<br>
Wie grÃ¶ÃŸ ist der Index?
<br>SatzgrÃ¶ÃŸe = BlockgrÃ¶ÃŸe * AssoziativitÃ¤t = 2^5 â€¢ 2^1 Bytes = 2^6 Bytes <br>Anzahn an SÃ¤tze = KapazitÃ¤t / SatzgrÃ¶ÃŸe = 2^13 / 2^6 â€¢ Bytes = 2^7 Bytes:
<br>IndexgrÃ¶ÃŸe = log2 ( Anzahl an SÃ¤tze ) = 7 Bit<br>
Wie groÃŸ ist der Tag?
<br>BlockoffsetgrÃ¶ÃŸe = log2 ( BlockgrÃ¶ÃŸe)Bits = log2 (2^5)Bits = 5 Bits
<br>AdressgrÃ¶ÃŸe - IndexgrÃ¶ÃŸe - BlockoffsetgrÃ¶ÃŸe = 40 - 7 - 5 = 28 Bits<br>
b)<br>
Adresse = [tag = 28 Bits, index = 7 Bits, blockoffset = 5 Bits ]<br>
Adresse = 55236<br>
Blockadresse = (Adresse / BlockgrÃ¶ÃŸe)<br>
Index = Blockadresse % 2^7 = 62
<br><br>AMAT = Average Memory Access Time (durchschnittliche Zugriffszeit)<br>
Es gibt jetzt verschiedene FÃ¤lle (verschiedene FÃ¤lle).<br>
<br>Fall: wir-finden denâ€¢ Cache-Block im sog. L1-Cache
<br>Fall: wenn nicht im LI-Cache, finden wir den Cache-Block im L2-Cache
<br>Fall: wenn nicht im L2-Cache, finden wir den-Cache-Block im RAM (Random Access Memory)<br>
FÃ¼r jeden Fall die HÃ¤ufigkeit (Wahrscheinlichkeit) berechnen.<br>
FÃ¼r jeden Fall die Zeitdauer berechnen.
<br>-&gt; AMAT = gewichtete Mittelwert<br>
-&gt; Miss-Rate = HÃ¤ufigkeit eines Cache-Misses (in Prozent)<br>
<br>lokal: fÃ¼r jeden Cache-Zugriff, wie hÃ¤ufig gibt es einen Cache-Miss? (Dieser ist gegeben!! wenn nichts weiter gesagt ist.).
<br>global: wie viele Speicherzugriffe vom Prozessor landen im Cache und erzeugen einen Cache-Miss?
<br>1.Fall (L1-Cache):<br>
<br>
Zeit = 3 Takte <br>
globale HÃ¤ufigkeit = 100% - 7% = 93% <br>
100% der FÃ¤lle erreichen L1-Cache, davon 93% der FÃ¤lle ein Cache-Hit
1.Fall (L2-Cache): <br>
Zeit = L1-Cache-Zeit + 15 Takte = 18 Takte <br>
globale HÃ¤ufigkeit = 7% (100% - 34%) = 7% 66% = 4.62% <br>
7% der FÃ¤lle erreichen den L2-Cache, davon 66% der FÃ¤lle ein Cache-Hit
2.Fall (RAM): <br>
Zeit = L2-Cache-Zeit + 100 Takte = 118 Takte <br>
globale HÃ¤ufigkeit = 7% * 34% = 100% - 93% - 4.62% = 2.38% <br>
7% der FÃ¤lle erreichen L2-Cache und dort in 34% der FÃ¤lle gehen wir zum RAM weiter <br>AMAT = 93% 3 Takte + 4.62% 18 Takte + 2.38% * 118 Takte AMAT = 6.43 Takte]]></description><link>rechnerorganisation/rorg_tut12.html</link><guid isPermaLink="false">Rechnerorganisation/Rorg_tut12.md</guid><pubDate>Sun, 21 Apr 2024 20:24:33 GMT</pubDate><enclosure url="rechnerorganisation/img_b88a7876cfcd-1.jpeg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;rechnerorganisation/img_b88a7876cfcd-1.jpeg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Rechnerorganisasion TUT 11]]></title><description><![CDATA[<br><br><br><br>was ist ein nop-Befehl<br>
<br>No Operation
<br>Befehl der nichts ausfÃ¼hrt(keinen Zustand verÃ¤ndert)
<br>gewÃ¶hnlich Befehl dessen 32 Bit auf 0 gesetzt sind
<br>in MIPS: sll $zero, $zero, 0<br>
AuflÃ¶sung von Datenkonflikten in Pipelined-Prozessoren:
<br>nop-Befehle <br>simpleres Design(weniger Baauteile/kostengÃ¼nstig)
<br>Compiler/Programmierer muss manuell nop's einfÃ¼gen <br>alternativ: Hardware-Forwarding
<br><br>
<br>
ursprÃ¼ngliches Proplem bei Eintaktprozessor: Abschnitten im Eintaktprozessor werden nicht vollstÃ¤ndig ausgenutzt. <br>
Idee: wir fangen an, Befehle auszufÃ¼hren, bevor der vorherige Befehl fertig ist. <br>damit die Datenpfad-Abschnitte mehr genutzt werden (mehr Arbeit ausfÃ¼hren)
<br>sobald der Befehl zu den Registern geht, wird schon ein neuer Befehl aus dem Speicher geladen <br>
wir haben 5 Abschnitte: Instruction Fetch, Instruction Decode, Execute, Memory (Read/Write), Write Back <br>sobald ein Befehl in Instruction Decode ist, wird der nÃ¤chste Befehl angefangen <br><br>
<br>manche Bestandteile aus dem Eintaktprozessor wurden "bewegt" an andere Stelle
<br>es gibt solche "Balken" (zusÃ¤tzlichen Rechtecke) = Pipeline-Register
<br><br>
<br>
diese trennen die verschiedenen Stufen <br>
aber warum brauchen wir diese Register wirklich? <br>weil wir jede Stufe in der gleichen Zeit ausfÃ¼hren wollen
<br>wir wissen aus letzter Woche: die Stufen sind unterschiedlich schnell<br>
(z.B. Instruction Fetch = Speicherzugriff 150ps, Register-Lesen = 50 ps, ALU = 100ps)
<br>wir wollen nicht, dass eine frÃ¼here Stufe die nÃ¤chste vorzeitig unterbricht =&gt; die Pipeline-Register halten die Eingangsdaten (fÃ¼r eine Stufe) und warten, bis der nÃ¤chste Takt anfÃ¤ngt (Synchronisation) <br><br>
<br>
Datenkonflikte (Data Hazard) <br>
Register-Werte fehlen, wenn diese gebraucht werden <br>
wenn ein Befehl das Ergebnis von dem vorherigen Befehl braucht, dann ist der vorherige Befehl noch nicht fertig!!<br>
Die Daten des vorherigen Befehls sind nicht da<br>
Die gelesen Register vom nÃ¤chsten Befehl (weiter links in der Pipeline) sind noch nicht upgedatet, also falsch <br>
wir kÃ¶nnen das richtige Ergebnis erst aus dem Register laden, wÃ¤hrend das Ergebnis geschrieben wird<br>
warum? <br>Idee: wir kÃ¶nnen den Takt in zwei HÃ¤lften unterteilen
<br>erste HÃ¤lfte: schreibe das Ergebnis in Register in Write Back
<br>zweite HÃ¤lfte: Register werden gelesen in Instruction Decode <br>
wie kann machen, damit Data Hazards weniger Zeit verschwenden? <br>Forwarding Unit + Hazard Detection (Ergebnis wird weitergereicht, sobald das Ergebnis berechnet wurde, also schon vor Write-Back) <br>
Steuerkonflikte (Control Hazard) <br>
die Sprungentscheidung, Sprungadresse fehlt, wenn wir diese bereits brauchen <br>
der Kontrollfluss (also die BefehlsausfÃ¼hrung) ist verzÃ¶gert (ist noch nicht entschieden) <br>
wir kÃ¶nnen Befehle ausfÃ¼hren, die eigentlich nicht ausgefÃ¼hrt werden sollen <br>
wie schneller machen? <br>"Branch Prediction" (siehe unten) <br>wenn wir hÃ¤ufig richtig raten, sind wir schneller <br>Sprungentscheidung viel frÃ¼her berechnen (z.B. in Instruction-Decode, dafÃ¼r Extra-Hardware nÃ¶tig) <br>
Strukturelle Konflikte (Structural Hazard) (nennen wir nur wegen der VollstÃ¤ndigkeit) <br>wenn zwei Befehle dieselbe Pipeline-Stufe gleichzeitig nutzen wollen
<br>z.B. wenn es zwei Pipelines gibt (2K-Zahlen und Floating-Point-Zahlen) und diese zusammenlaufen (zusammengefÃ¼hrt werden) <br>Advanced Computer Architectures <br>kommen bei uns nicht vor <br>
wie verhindern (entschÃ¤rfen) wir die Hazards? <br>"Stall Cycles" (Takte wo angehalten wird), "der Prozessor hÃ¤lt die vordere Pipeline an (Instruction Fetch und Instruction Decode)
<br>wir ignorieren das Problem, Compiler soll das Problem lÃ¶sen <br>Compiler fÃ¼gt "Wartebefehle" ein, "NOP"s = No operation
<br>Delay Slot (= Takte die gewartet werden mÃ¼ssen, bis das richtige Ergebnis da ist) = Latenz ("Bearbeitungszeit") <br>wir kÃ¶nnen auch andere Befehle statt NOPs nutzen, die fehlende Ergebnis nicht brauchen <br>"Flushing" ("herunterspÃ¼len") <br>die Pipeline bis zu Instruction Decode wird geleert (d.h. das wir die Befehle spÃ¤ter nochmal laden) <br>fÃ¼r Control Hazards: wir kÃ¶nnen raten (Spekulation, "Branch Prediction"), welche Sprungentscheidung genommen wird <br>wenn wir falsch raten, dann werden wir bestraft, indem wir alle falsch ausgefÃ¼hrten Befehle rÃ¼ckgÃ¤ngig machen mÃ¼ssen ("Flushing" + andere Sachen)
<br>wenn wir richtig raten, dann sind wir richtig schnell ğŸ˜€ <br><br>a)<br>
<br>ohne Optimierung: <br>wenn ein Register-Ergebnis berechnet wird, dann ist das Ergebnis die nÃ¤chsten zwei Takte nicht verfÃ¼gbar
<br>siehe Bild <br>0 addi *$t0* ,$a0 ,4
1 addi *$t1* ,$a1 ,4
2 sub $t2 ,*$t0* ,*$t1*
3 sll *$t3* ,$a2 ,2
4 add *$t4* ,$t0 ,*$t3*
5 add $t5 ,$t1 ,*$t3*
6 sw $t2 ,0( *$t4* )
å¤åˆ¶<br>b)<br>
<br>keine Reihenfolge Ã¤ndern, nur Wartebefehle (NOPs) einfÃ¼gen
<br>0 addi $t0 ,$a0 ,4 1 addi $t1 ,$a1 ,4 1.2 nop
1.3 nop 2 sub $t2 , $t0 , $t1 3 sll $t3 ,$a2 ,2 3.1 nop
3.2 nop 4 add $t4 ,$t0 , $t3 5 add $t5 ,$t1 , $t3 5.1 nop 6 sw $t2 ,0( $t4 )
å¤åˆ¶<br>c)<br>
<br>noch besser machen: jetzt so wenig wie mÃ¶glich NOPs brauchen, Befehle umordnen
<br>wie vorgehen ? wir gucken, welche Befehle brauchen das Ergebnis von welchen anderen Befehlen? =&gt; grafisch aufzeichnen <br>List Scheduling (siehe Internet? â†’ Compiler Design Kurs. Statt "AuftrÃ¤ge" "Maschinen" zuzuweisen, weisen wir der Pipeline neue Befehle zu) <br><br>a)<br>
<br>
Speicherzugriff = 200ps, ALU-Operation = 100ps, Registerzugriff = 50ps <br>
Benchmark (Programm, um die AusfÃ¼hrungszeit zu messen) <br>
Annahmen: gleiche Anzahl an Befehle fÃ¼r beide Prozessoren <br>
Jeder Prozessor hat eine (eigene) konstante Taktzeit, T_SC = Taktdauer des Eintaktprozessor (Single Cycle), T_PP = Taktdauer fÃ¼r Pipeline-Prozessor <br>
es gibt keine Data Hazards mehr (wurden entfernt durch Umordnung) <br>
es gibt aber alle Control-Hazards noch! -&gt; jeder Sprungbefehl dauert 4 Takte! Der Prozessor hÃ¤lt bei Sprungbefehlen einfach an! <br>
Speicherbefehle -&gt; 12% (1 Takt pro Speicherbefehl weil keine Datenkonflikte Data Hazards) <br>
ALU-Befehle -&gt; 72% (1 Takt pro Speicherbefehl weil keine Datenkonflikte) <br>
Sprung-Befehle -&gt; 16% (4 Takte pro Sprungbefehl, wegen den Steuerkonflikten Control Hazards) <br>
wozu die Informationen? Damit wir die Schnelligkeit des Pipeline-Prozessors berechnen kÃ¶nnen. Eintaktprozessor fÃ¼hrt jeden Befehl gleichschnell aus <br>
unbekannte Anzahl N an Befehlen <br>
Pipeline ist zu Beginn der Benchmark gefÃ¼llt <br>
Speedup berechnen, S = Vergleichszeit t_SC / (betrachtete Zeit) t_PP -&gt; wie viel Faktor schneller ist der betrachtete Prozessor <br>
t_SC = AusfÃ¼hrungszeit Eintaktprozessor = (Anzahl an Takte) Â· (Taktdauer) = (N Â· CPI_SC) Â· T_SC <br>
t_PP = AusfÃ¼hrungszeit Pipelineprozessor = (Anzahl an Takte) Â· (Taktdauer) = (N Â· CPI_PP) Â· T_PP <br>
CPI = Befehlsdauer in Takten = wie lange braucht ein Befehl an Takten zur AusfÃ¼hrung <br>CPI_SC = 1 da jeder Befehl einen Takt braucht
<br>CPI_PP = jeder Befehl braucht unterschiedlich viele Takte (hÃ¤ngt ab von den Hazards) <br>gewichteter Mittelwert: 12% 1 + 72% 1 + 16% * 4 = 1.48 <br>
T = Taktdauer, wie viel Sekunden braucht ein Takt <br>T_SC = 600ps = 2Â·200ps + 100ps + 2Â·50ps (2-mal Speicherzugriff, 2-mal Registerzugriff, 1-mal ALU)
<br>T_PP = maximale Dauer einer Stufe = 200ps (wir brauchen eine Taktdauer in der jede Stufe ausgefÃ¼hrt wird) <br>
S = (N Â· CPI_SC) Â· T_SC / ((N Â· CPI_PP) Â· T_PP) = 600ps / (1.48 * 200ps) = 2,027027027â€¦ = 2 + 27/999 <br>b) wie kÃ¶nnen wir den Pipeline-Prozessor schneller machen? siehe Aufgabe 1<br>c) Was ist, wenn wir nur die ALU schneller machen, um 25% ?<br>ALU-Operation braucht nur 75ps<br>-&gt; T_SC = 2Â·200ps + 75ps + 2Â·50ps = 575ps<br>T_PP Ã¤ndert sich nicht!! Immernoch die gleichen Hazards, und Speicherbefehle dauern immernoch 200ps<br>=&gt; der Speedup wird schlechter, weil der Pipeline-Prozessor nicht profitiert<br>=&gt; Pipeline wird nur schneller, wenn man die am lÃ¤ngsten dauernde Stufe optimiert.<br><br><img src="rechnerorganisation/20230203105924.png" target="_self"><br>
<img src="rechnerorganisation/bildschirmÂ­foto-2023-02-03-um-10.51.40.png" target="_self"><br>
<img src="rechnerorganisation/bildschirmÂ­foto-2023-02-03-um-11.48.40.png" target="_self"><br>Aufgabe 3<br>a) Verbesserung ist, dass man die EX und MEM-Stufe zusammenlegen kann. Die Pipeline wird kÃ¼rzer. Load-Use-Konflikte sind einen Takt schneller (0 statt 1 Takte VerzÃ¶gerung).<br>b)<br>Verbesserungen gibt es, wenn Speicherfefehle keinen Offset brauchen<br>das ist der Fall bei Array-Zugriffen in Schleifen oder Integer-Pointer<br>alle anderen Zugriffe brauchen einen Offset<br>wenn man einen konstanten Offset braucht, wird man verlangsamt<br>der Offset muss in Extra-Befehl berechnet werden<br>der zusÃ¤tzliche Befehl wird nur durch kÃ¼rzere Load-Use-Hazards kompensiert<br>verbraucht ein Register (erhÃ¶ht den Registerdruck), sowie zusÃ¤tzlichen Platz im Befehlsspeicher (Cache-Verschmutzung)<br>in Praxis brauchen wahrscheinlich mehr Befehle einen konstanten Offset als keinen<br>alle struct-, Objekt-Zugriffe brauchen einen; hÃ¤ufiger Spezialfall: Stack-Frames<br>hÃ¤ufig in Praxis, vor allem Stack Frames, da es viel mehr innere Funktionsaufrufe mit Stack als Blatt-Funktionsaufrufe ohne Stack gibt.<br><img src="rechnerorganisation/20230203131555.png" target="_self"><br>
<img src="rechnerorganisation/20230203131618.png" target="_self"><br>
<img src="rechnerorganisation/20230203131640.png" target="_self"> ]]></description><link>rechnerorganisation/rorg_tut11.html</link><guid isPermaLink="false">Rechnerorganisation/Rorg_tut11.md</guid><pubDate>Sun, 21 Apr 2024 20:24:33 GMT</pubDate><enclosure url="rechnerorganisation/20230203105924.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;rechnerorganisation/20230203105924.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Rechnerorganisasion TUT 10 - Leistung]]></title><description><![CDATA[<br><br><br>Taktfrequenz = 1 / T (wie viele Befehle passen in eine Sekunde)<br>
T = die Zeitdauer eines (jedes) Befehls (im Eintaktprozessor und im Pipeline-Prozessor)<br>minimale Taktzykluszeit = kÃ¼rzestes Zeitdauer, die man mindestens braucht, um JEDEN ausfÃ¼hren zu kÃ¶nnen<br>
-&gt; man guckt sich den lÃ¤ngsten Befehl an (weil wir keine unterschiedliche Taktdauer fÃ¼r unterschiedliche Befehle haben kÃ¶nnen)<br>Hauptspeicher = RAM (Random Access Memory) , [aber in allermeisten FÃ¤llen liegen noch Caches zwischen dem Prozessor und dem RAM]<br><br>a) Taktze<br>
it berechnen:<br>tâ‚ = Zeitdauer fÃ¼r Fetch (Speicherzugriff)<br>
tâ‚‚ = Zeitdauer fÃ¼r Decode (Registerzugriff) [es werden auch Steuersignale berechnen, kommt aber in Aufgabe nicht vor]<br>
tâ‚ƒ = Zeitdauer fÃ¼r Execute (ALU-Operation)<br>
tâ‚„ = Zeitdauer fÃ¼r Memory (Speicherzugriff)<br>
tâ‚… = Zeitdauer fÃ¼r WriteBack (Registerzugriff)<br>load-word ist der lÃ¤ngste Befehl, weil load-word alle Befehlsschritte ausfÃ¼hren muss<br>Deshalb, alle Befehlsschritt addieren:<br>T = Summe( tâ‚ + tâ‚‚ + tâ‚ƒ + tâ‚„ + tâ‚… ) = 2Â·150ps + 2Â·50ps + 100ps = 500ps<br>
entspricht 2 GHz<br>echo "$(( 2 * 150 + 2 * 50 + 100 ))"
å¤åˆ¶<br>b)<br>
Ziel: Befehl um 1.15x schneller machen, indem wir eine Komponente (d.h. Speicherzugrif, Registerzugriff oder ALU-Operation) schneller (= kÃ¼rzer) machen<br>Speedup =! 1.15<br>
S = / = T / ( 2Â·150ps / Î± + 2Â·50ps / Î² + 100ps / Î³ )<br>
T = 500ps<br>ps = Pikosekunde = 10â»Â¹Â² (1 Billionstel)<br>Î± = Verschnellerung von Speicherzugriff<br>
Î² = Verschnellerung von Registerzugriff<br>
Î³ = Verschnellerung von ALU-Operation<br>
<br>
Fall 1: Î² = Î³ = 1,
Î± = ? damit S = 1.15 ist?<br>
1.15 = 500ps<br>
&lt;=&gt; ( 2Â·150ps / Î± + 2Â·50ps / Î² + 100ps / Î³ ) Â· 1.15 = 500ps<br>
&lt;=&gt; 2Â·150ps / Î± = 500ps / 1.15 - (2Â·50ps / Î² + 100ps / Î³)<br>
&lt;=&gt; Î± = 2Â·150ps / ( 500ps / 1.15 - (2Â·50ps + 100ps) ) # Î² = Î³ = 1<br>
&lt;=&gt; Î± = 1.2777... = 115/90
Zeit Speicherzugriff neu = 150ps / Î± = 117.4ps <br>
Fall 2: Î± = Î³ = 1
Î² = 2Â·50ps / ( 500ps / 1.15 - (2Â·150ps / Î± + 100ps / Î³) )<br>
Î² = 2.875 = 23/8
Zeit Registerzugriff neu = 50ps / Î² = 17.4ps <br>
Fall 3: Î± = Î² = 1
Î³ = 100ps / ( 500ps / 1.15 - (2Â·50ps / Î² + 2Â·150ps / Î±) )<br>
Î³ = Î²
Zeit ALU-Operation neu = 100ps / Î³ = 34.78ps <br>[schneller heiÃŸt: kÃ¼rzere Zeit]<br>
Speicherzugriff: S = 500ps / (2Â·150ps / Sâ‚ + 200ps) =! 1.15 <br>Sâ‚ = 2Â·150ps / (500ps / 1.15 - 200ps) = 1.2777â€¦ = 1 + 2/9 + 5/90 = 115/90 Registerzugriff: S = 500ps / (400ps + 2Â·50ps / Sâ‚‚) =! 1.15 <br>Sâ‚‚ = 2Â·50ps / (500ps / 1.15 - 400ps) = 2.875 = 3 - 1/8 = 23/8 ALU-Operation: S = 500ps / (400ps + 100ps / Sâ‚ƒ) =! 1.15 <br>Sâ‚ƒ = 100ps / (500ps / 1.15 - 400ps) = Sâ‚‚ <br><br>a)<br>
Durschnittslaufzeit der Programme berechnen.<br>( âˆ‘ )/n = ( + + + ) / 4 = sum( liste ) / len( liste )<br>Computer 1: = 67.25<br>
Computer 2: = 88.25<br>Computer 1 gewinnt, da weniger Zeit pro Progamm nÃ¶tig!<br>b)<br>
HÃ¤ufigkeit der Programme berÃ¼cksichtigen.<br>Fehler: ( âˆ‘ Â· ) / n = ( Â· + â€¦ Â· ) / 4<br>
Richtig: âˆ‘ Â· = Â· + â€¦ Â· <br>Computer 1: = 46.16<br>
Computer 2: = 23.5<br>Computer 2 gewinnt!<br>c) Warum oder wie lÃ¤sst sich das (der Unterschied) erklÃ¤ren?<br>
<br>Der Unterschied kommt dadurch zustande, dass die Programme, in denen C1 besser ist, so selten gebraucht werden, dass C2 insgesamt in der Nutzungszeit alle Programmaufrufe schneller ausfÃ¼hrt.
<br>MÃ¶glichkeit:<br>
Programm 1: Browser fÃ¼rs Internet<br>
Programm 2: Computerspiele (3D-Grafik-Berechnungen)<br>
Programm 3: numerische Berechnungen als Uni-Hausaufgaben<br>
Programm 4: MARS-Simulator oder andere seltene GUI-Anwendungen<br>=&gt; Computer 2 wÃ¤re ein Gaming-PC<br>=&gt; andere MÃ¶glichkeit: Server-Computer<br>
Programm 1: VerschlÃ¼sselung und Sicherheit<br>
Programm 2: Nutzeranfrangen bearbeiten<br>
Programm 3: Konsolenprogramme<br>
Programm 4: grafische Anwendungen<br><br>Wir vergleichen 3 Computer anhand der Speedups zwischen Programmen.<br>Referenzmaschine heiÃŸt, als MaÃŸstab zum Vergleich anderer Maschinen (Computer).<br>Wir bilden die VerhÃ¤ltnisse zwischen den AusfÃ¼hrungszeiten. Referenzmaschine soll Computer 2 sein.<br> = / # elementweise Division!<br> = / = 1<br> = / <br>Produkt = Â· Â· ( numpy.prod() )<br>
geometrische Mittel = nâˆšProdukt (in diesem Fall n = 3)<br>3âˆš( x ) mit numpy.cbrt() (cube root) berechnen<br>geometrisches Mittel = numpy.cbrt( numpy.prod( ) )<br>Computer 1: geom. Mittel = 1.918<br>
Computer 2: geom. Mittel = 1<br>
Computer 3: geom. Mittel = 1.32<br>Schneller ist Computer mit geringsten geometrischen Mittel. Das kleinste geometrische Mittel hat der Computer, der im Vergleich zu C2 am schnellsten. (Je schneller der Computer, desto kleiner ist der Speedup von C2)<br>Problem:<br>
verschiedene Speedups kÃ¶nnen wir nicht vergleichen. Mehrere Speedupwerte verhalten wie Vektoren.<br>Der gleiche Speedup kann in der menschlichen Wahrnehmung einen riesigen Unterschied bedeuten.<br>
Beispiel: S = 3<br>
Fall 1: Programm 1 von Computer 1 braucht 100ms und Programm 1 von Computer 2 braucht dann 300ms<br>
Fall 2: Programm 2 von Computer 1 braucht 3 Tage und Programm 2 von Computer 2 braucht 1 Tag.<br>=&gt; geometrische Mittel hat hier keine richtige Bedeutung<br><br>$ python3
Python 3.8.10 (default, Nov 14 2022, 12:59:47) [GCC 9.4.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; 2 * 150 / ( 500 / 1.15 - 200 )
1.2777777777777777
&gt;&gt;&gt; 2 * 50 / ( 500 / 1.15 - 400 )
2.874999999999999
&gt;&gt;&gt; 115 / 180 * 150
95.83333333333333
&gt;&gt;&gt; 23 / 8 / 2 * 50
71.875
&gt;&gt;&gt; (23 / 8) / 2 * 50
71.875
&gt;&gt;&gt; 50 / (23 / 8)
17.391304347826086
&gt;&gt;&gt; 100 / (23/8)
34.78260869565217
&gt;&gt;&gt; 150 / ( 115/90 )
117.3913043478261
&gt;&gt;&gt; t_C1 = [ 23, 55, 82, 109 ]
&gt;&gt;&gt; t_C2 = [ 16, 21, 127, 189 ]
&gt;&gt;&gt; import numpy
&gt;&gt;&gt; numpy.mean( t_C1 )
67.25
&gt;&gt;&gt; numpy.mean( t_C2 )
88.25
&gt;&gt;&gt; w = [ 0.31, 0.66, 0.02, 0.01 ]
&gt;&gt;&gt; numpy.dot( w, t_C1 )
46.16000000000001
&gt;&gt;&gt; numpy.dot( w, t_C2 )
23.25
&gt;&gt;&gt; numpy.dot( w, t_C1 ) / 4
11.540000000000003
&gt;&gt;&gt; numpy.dot( w, t_C2 ) / 4
5.8125
&gt;&gt;&gt; exit()
elmar@linux:~$ python3
Python 3.8.10 (default, Nov 14 2022, 12:59:47) [GCC 9.4.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; t_C1 = [ 16, 60, 50 ]
&gt;&gt;&gt; t_C2 = [ 5, 17, 80 ]
&gt;&gt;&gt; t_C3 = [ 25 ] * 3
&gt;&gt;&gt; import numpy
&gt;&gt;&gt; t_C1 = numpy.array( t_C1 )
&gt;&gt;&gt; t_C2 = numpy.array( t_C2 )
&gt;&gt;&gt; t_C3 = numpy.array( t_C3 )
&gt;&gt;&gt; S_C1 = t_C1 / t_C2
&gt;&gt;&gt; S_C2 = t_C2 / t_C2
&gt;&gt;&gt; S_C3 = t_C3 / t_C2
&gt;&gt;&gt; print(S_C1)
[3.2 3.52941176 0.625 ]
&gt;&gt;&gt; print(S_C2)
[1. 1. 1.]
&gt;&gt;&gt; print(S_C3)
[5. 1.47058824 0.3125 ]
&gt;&gt;&gt; numpy.cbrt( numpy.prod( S_C1 ) )
1.9182745937205048
&gt;&gt;&gt; numpy.cbrt( numpy.prod( S_C2 ) )
1.0
&gt;&gt;&gt; numpy.cbrt( numpy.prod( S_C3 ) )
1.319583989972501 å¤åˆ¶<br><br>Wir haben 2 engere Kandidaten fÃ¼r die Wahl eine Computer-Systems.<br>Dieses Computer-System soll P1 und P2 ausfÃ¼hren, wobei P1 doppelt so hÃ¤ufig ausgefÃ¼hrt wird.<br>Der schneller Computer soll diese Programm-Kombination in einer kÃ¼rzeren Zeit ausfÃ¼hren.<br>Zeit fÃ¼r ein Computer-System: AusfÃ¼hrungsdauer = 2 Â· + 1 Â· <br>Jedes Programm hat eine feste Anzahl an Befehlen.<br>
Dauer eines Programms = Anzahl an Befehlen / Taktfrequenz = Anzahl an Befehlen / (Befehle / Sekunde)<br> = Befehle von P1 / ( Taktfrequenz )<br> = Befehle von P2 / ( Taktfrequenz )<br>GHz = 10â¹ (Milliarden Befehle pro Sekunde)<br>System C1:<br> = 8 Â· 10â¹ / ( 2 Â· 10â¹ ) = 4s<br> = 6 Â· 10â¹ / ( 2 Â· 10â¹ ) = 3s<br>
AusfÃ¼hrungsdauer = 2Â·4s + 3s = 11s<br>System C2:<br> = 11 Â· 10â¹ / ( 2.5 Â· 10â¹ ) = 4.4s<br> = 10 Â· 10â¹ / ( 2.5 Â· 10â¹ ) = 4s<br>
AusfÃ¼hrungsdauer = 2Â·4.4s + 4s = 12.8s<br>System 1 fÃ¼hrt die Programmme schneller aus und wÃ¤re nach dem Schnelligkeits-Kriterium besser geeignet.<br><br>Verschiedene Zeitdauern (LÃ¤ngen) verschiedener Befehle.<br>
Wir wollen (ausschlieÃŸlich) Speicherbefehle schneller machen.<br>gegeben: wie viele Befehle in unseren Programmen sind Speicherbefehle? Î± = 80% = 0.8<br>Die Frage ist natÃ¼rlich, wie viel mÃ¼ssen wir die Speicherbefehle optimieren?<br>Die Befehle werden jetzt aufgeteilt<br> = (1 - Î±) Â· T + Î± Â· T = T<br> = (1 - Î±) Â· T + Î± Â· T / <br>S = / = / <br>Es soll S = 3 oder S = 5 Ã¼berprÃ¼ft werden. Wir wollen gucken, ob es Ã¼berhaupt mÃ¶glich ist.<br>Wie groÃŸ ist ? Betrachtung fÃ¼r S = 3, S = 5<br>LÃ¶sung:<br>S = T / ( (1 - Î±) Â· T + Î± Â· T / ) = 1 / ( (1 - Î±) + Î± / )<br> ? Umstellen<br> = Î± / (1 / S - (1 - Î±))<br>Fall 1: S = 3<br> = 0.8 / (1 / 3 - 0.2 ) = (4/5) / ( 1/3 - 1/5 ) = (12/15) / ( 2/15 ) = 12/2 = 6<br>=&gt; hoher Speedup der Speicherbefehle nÃ¶tig<br>Fall 2: S = 5<br> = Î± / (1 / S - (1 - Î±))<br> = 0.8 / ( 1 / 5 - 0.2 ) = 0.8 / 0 !!<br>
Durch 0 zu teilen ist nicht definiert!<br>
d.h. es gibt kein <br>Grenzwertbetrachtung: =&gt; <br>
Unendlich bedeutet, dass Speicherzugriff 0s benÃ¶tigen.<br>was wÃ¤re denn, wenn wir sogar S &gt; 5 wollen?<br>
Dann wÃ¼rde rauskommen, dass &lt; 0 . Speicherzugriffe fÃ¼hren in die Zeit zurÃ¼ck!! Geht nicht.]]></description><link>rechnerorganisation/rorg_tut10.html</link><guid isPermaLink="false">Rechnerorganisation/Rorg_tut10.md</guid><pubDate>Sun, 21 Apr 2024 20:24:33 GMT</pubDate></item><item><title><![CDATA[Rorg_tut09]]></title><description><![CDATA[<br><br><br><br><img src="rechnerorganisation/20230211202202.png" target="_self"><br>
<img src="rechnerorganisation/20230211202257.png" target="_self"> <br><br><img src="rechnerorganisation/20230211202413.png" target="_self"> <br><br><img src="rechnerorganisation/20230211202621.png" target="_self"><br>
å³ä¸‹å›¾:Wie viele Takte benÃ¶tigt eine Instruktion?(CPI)<br><br><img src="rechnerorganisation/20230211202841.png" target="_self"><br>
<img src="rechnerorganisation/20230211202918.png" target="_self"><br>
<img src="rechnerorganisation/20230211202943.png" target="_self"> <br><br>
<br>R-Typ-Befehl (ALUSrc = 0, RegDst = 1)
<br>I-Typ-Befehl (ALUSrc = 1 (meistens), RegDst = 0)
<br>J-Typ-Befehl (haben wir nicht im Datenpfad)
<br>Speicherbefehle (lw, sw) <br>MemToReg = 1, MemWrite, MemRead, RegWrite
<br>Branch = 0 <br>Rechenbefehle (add, sub, and, or, sll, â€¦) <br>MemToReg = 0, RegWrite = 1
<br>MemRead = 0!!, MemWrite = 0, Branch = 0 <br>Sprungbefehle <br>Branch = 1 (bzw. Jump = 1)
<br>RegWrite = 0, MemRead = 0!!, MemWrite = 0 <br><br>
<br>Schritt 1: Befehlsverhalten definieren
<br>Schritt 2: Funktion als Schaltnetz entwerfen <br>Eingabe: <br>â‰¤ 2 Register-Werte, â‰¤ 1 16-Bit-Konstanten, 32-Bit-Befehl <br>Ausgabe: <br>nÃ¤chste Befehlsadresse (PC)
<br>Ergebniswert(e) (optional)
<br>Zieladresse (Register und/oder RAM, optional) <br>Schritt 3: Schaltnetz auf bestehenden Datenpfad abbilden <br>alle nutzbaren Elemente im Datenpfad wiederverwenden <br>Schritt 4: Steuersignale/Muxe hinzufÃ¼gen (um Befehl zu aktivieren)
<br><br><br>a) was beeinflusst die VerÃ¤nderung des Registerinhalts in einem Befehl?<br>direkten Einfluss:<br>
<br>RegDst: R-Typ und I-Typ-Befehle -&gt; RT = Instruction[16 bis 20] und RD = Instruction[11 bis 15] (als Bitfelder im Befehl) <br>RegDst = 0 =&gt; RT ausgewÃ¤hlt (immer fÃ¼r I-Typ), RegDst = 1 =&gt; RD ausgewÃ¤hlt (immer fÃ¼r R-Typ)
<br>R-Typ [ Opcode, RS, RT, RD, shift amount, Func ] =&gt; RD = ...
<br>I-Typ [ Opcode, RS, RT, imm16 ] =&gt; RT = ... <br>RegWrite: Bestimmt, ob die Daten am Write-Data-Port in das Zielregister geschrieben werden sollen
<br>MemToReg: gibt an, von wo die Daten zum Schreiben kommen. MemToReg = 1 heiÃŸt, dass die Daten vom "Memory" kommen.
<br>indirekten Einflus:<br>
<br>MemRead: wenn = 1, kann es Daten fÃ¼r die Register aus dem Hauptspeicher lesen
<br>ALUOp: bestimmt, wie mÃ¶gliche Daten zum Schreiben berechnet werden
<br>ALUSrc: bestimmt, wie mÃ¶gliche Daten zum Schreiben berechnet werden (meistens: I-Typ =&gt; ALUSrc = 1, immer: R-Typ =&gt; ALUSrc = 0)
<br>keinen Einfluss:<br>
<br>Branch (beeinflusst nur PC)
<br>MemWrite: das Schreiben vom Hauptspeicher verÃ¤ndert die mÃ¶glichen geschriebenen Registerdaten nicht
<br>b) welche Steuersignale beeinflussen das Beschreiben des Hauptspeicher (RAM â€“ Random Access Memory)<br>
<br>MemWrite
<br>MemRead (es gibt eine Optimierung des Speicherzugriffs, die nennt sich Cache, und dort werden Lesezugriffe gemerkt. Dieser Cache verÃ¤ndert sich, wenn man liest, was zwar keine funktionale aber einen Performance-Unterschied macht. ZusÃ¤tzlich kann man beim Lesen auf bestimmte Speicheraddressen Register von Hardware auÃŸerhalb des Prozessors verÃ¤ndern, weil diese so funktioniert. Deshalb sollte fÃ¼hrt das Lesen zu einer ZustandsÃ¤nderung des Computers bzw. des Speichers.)
<br>Andere Steuersignale nicht, denn diese beschreiben nur VerÃ¤nderungen in den Prozessorregistern.<br><br>a) welche Steuersignale dÃ¼rfen niemals (bei keinem Befehl) einen nicht-definierten (beliebigen) Wert annehmen?<br>
<br>Branch: <br>weil Branch das Ãœberschreiben des Programm-Counters direkt beeinflusst und der nÃ¤chste Wert des PCs fÃ¼r jeden Befehl fest definiert ist <br>RegWrite, MemWrite: <br>es ist fÃ¼r jeden fest definiert, ob und welche Register wir schreiben und welche Speicheradresse <br>MemRead: <br>nur = 1, wenn wir wirklich lesen wollen
<br>weil: das Lesen von Hauptspeicher beeinflusst den Cache (eine Hardware-Optimierung), die sich Lesezugriffe merkt, um diese zu beschleunigen <br>b) welche Steuersignale sind egal, wenn RegWrite = 0?<br>
<br>in dem Fall: Write-Data und Write-Register-Ports (vom Register File) sind dann egal, sodass <br>RegDst beliebig sein kann
<br>MemToReg beliebig sein kann <br>NICHT EGAL! ist <br>ALUSrc
<br>ALUOp
<br>weil ist mÃ¶glich, dass wir einen Schreibbefehl ausfÃ¼hren (sw, sb) <br>in dem Fall nutzen wird die ALU, um die Speicheradresse zu berechnen <br>c) welche FunktionalitÃ¤t (oder welcher Befehl) passiert (wohl), wenn RegWrite = 1, MemRead = 1, MemToReg = 1 ist?<br>
<br>MemRead = 1 liest Daten aus dem Speicher,
<br>MemToReg = 1 leitet gelesene Daten aus Hauptspeicher zu Register-File (Registersatz) weiter
<br>anliegende Daten am Register-File werden mit RegWrite = 1 in ein Register geschrieben
<br>naheliegender Befehl: load word (lw)<br>
Berechnung der Speicheradresse nicht vorgegeben (kÃ¶nnte beliebig sein)<br><br>ADDI:<br>
<br>RegDst: wegen I-Typ wollen wir nach RT schreiben, das machen wir mit RegDst = 0
<br>Branch = 0, da wir nach dem Befehl den nachfolgenden Befehl ausfÃ¼hren
<br>MemRead = 0, da wir nur ein Registerwert berechnen wollen, keine SpeicherverÃ¤nderung
<br>MemToReg = 0, damit wir das ALU-Ergebnis an das Register weiterleiten kÃ¶nnen
<br>ALUOp = 00; die linke 0 sagt, dass es keinen Func-Code gibt und das rechte Bit bestimmt, ob Addition (= 0) oder Subtraktion (= 1) ist
<br>MemWrite = 0, weil wir den Hauptspeicher nicht verÃ¤ndern wollen
<br>ALUSrc = 1, da wir einen I-Typ-Befehl haben und mit der Immediate rechnen wollen
<br>RegWrite = 1, damit wir unser Additionsergebnis in das Register reinschreiben kÃ¶nnen
<br><br>a) BGTZ zum Datenpfad hinzufÃ¼gen.<br>Schritt 1: Verhalten definieren.<br>
BGTZ $rs, Label (Label = PC + 4 + imm4 )<br>
PC = PC + 4 + ( RS &gt; 0 ? immediate 4 : 0) // a ? b : c === if a then b else c<br>Schritt 2:<br>
<br>Eingabe: PC, RS, imm = (Label - 4)/4 =&gt; RT = $0 (weil nicht angegeben)
<br>Ausgabe: PC
<br> Schaltnetz:<br>
PC = PC + 4 + X -&gt; 2-mal Addition<br>
X = ( RS &gt; 0 ? immediate * 4 : 0)<br>PC = ( RS &gt; 0 ? PC + 4 + immediate * 4 : PC + 4 ) =&gt; nur noch 2 Additionen
å¤åˆ¶<br> Nebenbemerkung: $rs &gt; 0 &lt;==&gt; $rs[31] = 0 (d.h. $rs â‰¥ 0) und $rs â‰  0<br> PC ---+---+ | + |--+-----------------+---+ 4 ----+---+ | |MUX|----- PC | +--+---+ | | | +------+---+ | | | + |---+ | imm --- (&lt;&lt; 2) -----+---+ | | $rs[31] -----------------o+---+ | | &amp; |--+ $rs --------(NOR32)------o+---+
å¤åˆ¶<br>Schritt 3: Schaltung in Datenpfad einfÃ¼gen und mÃ¶glichst viele Komponenten wiederverwenden<br>
<br>
Zero-Signal gibt an, ob das ALU-Ergebnis = 0 ist! NOR32 kann durch zero-Signal ersetzt werden. <br>
Addierer und Multiplexer sind schon vorhanden, Befehle und Operanden (Register) laden ist auch vollstÃ¤ndig vorhanden.<br>
=&gt; $rs[31] kÃ¶nnen wir durch das oberste Bit des ALU-Ergebnisses (oder des oberen ALU-Eingangs) erhalten <br>
ZusÃ¤tzlich brauchen wir ein OR-Gatter zwischen dem AND und dem Multiplexer, um die MÃ¶glichkeit fÃ¼r andere Branch-Befehle offen zu halten. <br>Schritt 4: ein Steuersignal (und gegebenenfalls ein zusÃ¤tzlicher Multiplexer) hinzufÃ¼gen, um unseren Befehl zu de-/aktiveren<br>
<br>bgtz-Steuersignal ausgehend von der Control Unit bis zu dem neu eingefÃ¼gten AND-Gatter einzeichnen. Dieses schaltet das UND-Gatter an/aus und damit auch den Befehl.
<br>b) Steuersignale setzen, um den Befehl auszufÃ¼hren.<br>
<br>neues Steuersignal: BGTZ muss = 1 sein
<br>Branch = 0, das ist zwingend notwendig, den Branch = 1 bedeutet, dass BEQ ausgefÃ¼hrt wird.
<br>RegWrite = 0 =&gt; RegDst = X, MemToReg = X
<br>MemRead = MemWrite = 0
<br>Rechenoperation auswÃ¤hlen (Addition) <br>ALUOp = 00
<br>ALUSrc = 0!! obwohl I-Typ-Befehl (weil wir die Immediate nicht fÃ¼r ALU sondern PC-Berechnung nutzen) <br>das kÃ¶nnen wir machen, weil $rt = $0 ist ]]></description><link>rechnerorganisation/rorg_tut09.html</link><guid isPermaLink="false">Rechnerorganisation/Rorg_tut09.md</guid><pubDate>Sun, 21 Apr 2024 20:24:33 GMT</pubDate><enclosure url="rechnerorganisation/20230211202202.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;rechnerorganisation/20230211202202.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Rorg_tut07]]></title><description><![CDATA[<br><br>li = load immediate = lui + ori<br>bgt = branch if greater than = slt + bne<br>Core Instruction (echte Befehle)<br>add, sll, slt<br>Register<br>at = v0 = $2<br>
...<br>t(x) = t8 = $24<br>s1 = s2 = s3 = $19 + 3<br>$s(x) = $16 + x<br>Opcode-Tabelle (MIPS-Green-Card)<br>Linker Kasten wichtig:<br>
Mittlere Spalte = R-Typ<br>
Linke Spalte = I-Typ und J-Typ<br>(Rechte Spalte = Floating-Point)<br>Mittlerer Kasten: Name des Befehls als Zahl in verschiedener Darstellung<br>Rechter Kasten: nicht wichtig, nur um ASCII-Zeichen zu Ã¼bersetzen<br>J-Typ-Format<br>Speichern die unteren 28-Bit des Program Counters (aber nicht die obersten 4 Bits!!)<br>Jeder Befehl ist 32-Bit = 4 Byte groÃŸ, d.h. dass jede Befehlsadresse ist durch 4 teilbar. D.h. die letzten beiden Bits = 0 sind.<br>0x000101011101010101...110100<br><br>jr	$ra =&gt; R-Typ, Func rs<br>
rs = $ra = 31<br>
[ 000000, 31 , 0 , 0 , 0 , 8 ]
<br>addi $a0, $a0, 4 =&gt; I-Typ (Opcode wird verwendet)<br>
Opcode rt, rs, imm<br>
[ Opcode = 8 , rt = $a0 = 4, rs = $a0 = 4, 4 ]
<br><br><br>Bei BEQ haben wir nur kleine Immediate (16-Bit) zum springen<br>
<br>BEQ-Befehlsadresse (Beispiel):<br>
1011 0111 0101 01 [0000 0000 0000 0101] 00<br>
16-Bit
<br>Addition mit PC erlaubt uns, auch Adressbits Ã¼berhalb den 18 untersten Bits zu verÃ¤ndern.<br>
HÃ¤ufig sind Programme groÃŸ, sodass hÃ¤ufiger SprÃ¼nge vorkommen, in denen die Adressbits Ã¼ber den unteren 18 Bits sich verÃ¤ndern.<br>
<br>J-Befehlsadresse:<br>
1011 [00 0000 0000 0000 0000 0000 0101] 00<br>
26-Bit
<br>obere 4 Bits der Befehlsadresse Ã¤ndern sich in einem Program selten, deshalb reicht es, wenn die Konstante im J-Typ-Befehl bloÃŸ die unteren Adressbits ersetzt (ohne Addition).<br>Falls ein Sprung alle Adressbits verÃ¤ndern kÃ¶nnen soll: JR-Befehl (Zieladresse ist ein Registerinhalt)<br>a)<br>
[ bne, â€¦ , â€¦ , imm = 13 ]<br>PC = 100 020 + 4 = 100 024 (nÃ¤chster Befehl)<br>
13 &lt;&lt; 2 == 13 * 4 = 52<br>Zieladresse = L1 = 52 + PC = 100 076<br>
=&gt; 100 076 (Ergebnis)<br>b)è¯¦ç»†è§single cycle ppt p42<br>
[ j , imm = 170 012 ]<br> PC[28..31] å¤åˆ¶<br>PC = 150 020 + 4 = [0000] â€¦ â€¦ â€¦ â€¦ â€¦ â€¦ â€¦00 â‚‚<br>
é«˜4ä½ä¸º0<br>
Zieladresse = L1 = { PC[28..31] , 170 012 &lt;&lt; 2 } // "," bedeutet Bits nebeneinander zu stecken (konkatenieren)<br>170 012 &lt;&lt; 2 == 170 012 * 4 == 680 048<br>"&lt;&lt; 2" bedeutet einfach nur, dass zwei untere 0-Bits dazukommen<br>L1 = { 0 , 680 048 } // oberen 4 Bits sind 0 und haben daher keinen Einfluss auf den Zahlenwert der Adresse<br>
L1 = 680 048<br>7.4)<br>
<br>Schritt: obere 6-Bit (Opcode) anschauen
<br>Schritt: welches Format, dann welcher Befehlsname herausfinden
<br>Schritt: die Felder aus dem Machinenbefehl ablesen (rs, rt, rd, shamt, imm)
<br>Schritt: in richtiger Reihenfolge in den Befehl schreiben (siehe Mips-Greencard bei Core Instructions)
<br>Zeile 1 Befehlsadresse = L1 = 0x1004:<br> Opcode rs rt rd shamt Func
å¤åˆ¶<br>0x00004020 = [0000 00][00 000][0 0000] [0100 0][000 00][10 0000] â‚‚<br>Opcode = 0 =&gt; R-Typ-befehl<br>
Func = 10 0000 =&gt; 32 =&gt; ADD rd, rs, rt<br>
rd = 01000 = $8 = $t0<br>
rs = 00000 = $0 = $zero<br>
rt = 00000 = $0 = $zero<br>=&gt; L1: ADD $t0, $zero, $zero<br>Zeile 2 Befehlsadresse = L2 = 0x1008:<br> Opcode rt rs imm
å¤åˆ¶<br>0x21080001 = [0010 00][01 000][0 1000][0000 0000 0000 0001] â‚‚<br>Opcode = 8 =&gt; kein R-Typ =&gt; ADDI rt, rs, imm<br>
rt = 01000 = $8 = $t0<br>
rs = 01000 = $8 = $t0<br>
imm = 00â€¦01 = 1<br>=&gt; L2: ADDI $t0, $t0, 1<br>Zeile 3 Befehlsadresse = L3 = 0x100C:<br> Opcode imm = 0x401
å¤åˆ¶<br>0x08000401 = [0000 10] [00 0000 0000 0000 0100 0000 0001] _2<br>Opcode = 2 =&gt; kein R-Typ =&gt; J imm<br>Sprungziel = imm &lt;&lt; 2 == 0x1004 == L1 !!<br>=&gt; L3: J L1]]></description><link>rechnerorganisation/rorg_tut07.html</link><guid isPermaLink="false">Rechnerorganisation/Rorg_tut07.md</guid><pubDate>Sun, 21 Apr 2024 20:24:33 GMT</pubDate></item></channel></rss>