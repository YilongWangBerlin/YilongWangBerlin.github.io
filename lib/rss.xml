<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Obsidian Vault]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>lib/media/favicon.png</url><title>Obsidian Vault</title><link></link></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Tue, 23 Apr 2024 08:33:16 GMT</lastBuildDate><atom:link href="lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Tue, 23 Apr 2024 08:33:09 GMT</pubDate><ttl>60</ttl><dc:creator></dc:creator><item><title><![CDATA[Mikro_06]]></title><description><![CDATA[<br><br><br><img src="mikro/20230203203903.png" target="_self"> <br><img src="mikro/20230203203935.png" target="_self"><br>
<img src="mikro/20230203203958.png" target="_self"><br>
<img src="mikro/20230203204025.png" target="_self"><br>
<img src="mikro/20230203204056.png" target="_self"> <br><br>####Neues Haushaltsoptimum nach Preiserhoehung von Gut 1:<br>
<img src="mikro/20230204003627.png" target="_self"> <br>
<br>A:HHO vor Preisaenderung: <br>Ursachen:<br>
<br>Substitutionsverhaeltnis
<br>Realeinkommen
<br><br><img src="mikro/20230204005508.png" target="_self"> <br>
<br>A:HHO vor Preisaenderung:
<br>C:HHO nach Preisaenderung:
<br>B:HHO nach Preisaenderung bei Kaufkrafterhaltung(durch Einnkommenskompensation):
<br> <br><br>
Substitutionseffekt ist immer der Preisaenderung entgegengesetzt! <br><br><img src="mikro/20230204011052.png" target="_self"><br>
<br>
<br>normales Gut: <br>inferiores Gut: <br><br><br>
<br>gewoehnliches Gut: <br>Giffen-Gut: <br><br><img src="mikro/20230205103044.png" target="_self"><br>
<img src="mikro/20230205103153.png" target="_self"><br>
<img src="mikro/20230205103256.png" target="_self"> ]]></description><link>mikro/mikro_06.html</link><guid isPermaLink="false">Mikro/Mikro_06.md</guid><pubDate>Tue, 23 Apr 2024 08:32:19 GMT</pubDate><enclosure url="mikro/20230203203903.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;mikro/20230203203903.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Mikro_12]]></title><description><![CDATA[<br><br><br>Bestimmung des Konkurrenzgleichgewichtes für 2 Güt, 2 Konsumenten, allg. Cobb-Douglas Präferenzen<br>
<img src="mikro/20230206154832.png" target="_self"><br>
<img src="mikro/20230206154915.png" target="_self"><br>
<img src="mikro/20230206174217.png" target="_self"><br>
<img src="mikro/img_045039d5abaf-1.jpeg" target="_self"><br><br>
<br>
<br>Nettonachfrage = Bruttonachfrage - Erstausstattung
<br>wenn Nettonachfrage &gt; 0, Nachfrager
<br>wenn Nettonachfrage &lt; 0, Anbieter
<br><img src="mikro/20230206175857.png" target="_self"> <br><br><img src="mikro/20230206180014.png" target="_self"> <br><br><img src="mikro/img_5122b71db030-1.jpeg" target="_self"><br><br><img src="mikro/20230206180928.png" target="_self"> ]]></description><link>mikro/mikro_12.html</link><guid isPermaLink="false">Mikro/Mikro_12.md</guid><pubDate>Tue, 23 Apr 2024 08:32:03 GMT</pubDate><enclosure url="mikro/20230206154832.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;mikro/20230206154832.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[index]]></title><description><![CDATA[<br><a data-href="mikro" href="mikro/mikro.html" class="internal-link" target="_self" rel="noopener">mikro</a><br>
<a data-href="Rorg" href="rechnerorganisation/rorg.html" class="internal-link" target="_self" rel="noopener">Rorg</a>]]></description><link>index.html</link><guid isPermaLink="false">index.md</guid><pubDate>Mon, 22 Apr 2024 17:19:20 GMT</pubDate></item><item><title><![CDATA[Rorg]]></title><description><![CDATA[<br><a data-href="Rorg_tut07" href="rechnerorganisation/rorg_tut07.html" class="internal-link" target="_self" rel="noopener">Rorg_tut07</a><br>
<a data-href="Rorg_tut09" href="rechnerorganisation/rorg_tut09.html" class="internal-link" target="_self" rel="noopener">Rorg_tut09</a><br>
<a data-href="Rorg_tut10" href="rechnerorganisation/rorg_tut10.html" class="internal-link" target="_self" rel="noopener">Rorg_tut10</a><br>
<a data-href="Rorg_tut11" href="rechnerorganisation/rorg_tut11.html" class="internal-link" target="_self" rel="noopener">Rorg_tut11</a><br>
<a data-href="Rorg_tut12" href="rechnerorganisation/rorg_tut12.html" class="internal-link" target="_self" rel="noopener">Rorg_tut12</a>]]></description><link>rechnerorganisation/rorg.html</link><guid isPermaLink="false">Rechnerorganisation/Rorg.md</guid><pubDate>Sun, 21 Apr 2024 21:03:26 GMT</pubDate></item><item><title><![CDATA[mikro]]></title><description><![CDATA[<br><a data-href="Mikro_06_" href="mikro/mikro_06_.html" class="internal-link" target="_self" rel="noopener">Mikro_06_</a><br>
<a data-href="Mikro_06" href="mikro/mikro_06.html" class="internal-link" target="_self" rel="noopener">Mikro_06</a><br>
<a data-href="Mikro_07" href="mikro/mikro_07.html" class="internal-link" target="_self" rel="noopener">Mikro_07</a><br>
<a data-href="Mikro_12" href="mikro/mikro_12.html" class="internal-link" target="_self" rel="noopener">Mikro_12</a><br>
<a data-href="Mikro_12" href="mikro/mikro_12.html" class="internal-link" target="_self" rel="noopener">Mikro_12</a><br>
<a data-href="Mikro_vl13" href="mikro/mikro_vl13.html" class="internal-link" target="_self" rel="noopener">Mikro_vl13</a>]]]></description><link>mikro/mikro.html</link><guid isPermaLink="false">Mikro/mikro.md</guid><pubDate>Sun, 21 Apr 2024 21:01:24 GMT</pubDate></item><item><title><![CDATA[Mikro_vl13]]></title><description><![CDATA[<br><br>Lösungsweg<br>
Nicht Vergessen!!<br><br>
<br>
Güter: Konsum C und Arbeit L (bzw. Freizeit R) mit Preisen p bzw. w <br>
Unternehmen: <br>Outputgut: Konsumgut (C) <br>Inputgut: Arbeit (L) (bzw. Freizeit, ) <br> ist das maximal mögliche Arbeitsangebot (bzw. maximale mögliche Freizeit), z.B. 24 Stunden pro Tag <br>Produktionsfunktion: <br>
Zwei Konsumenten: A, B <br>Nutzenfunktion: ,
<br>Anfangsausstattungen: <br>Unternehmensanteile: <br>Konsument A:
<br>Konsument B: <br>
Konsumenten: <br>Nutzenfunktion: <br>Anfangsausstattungen: <br>Unternehmensanteile: <br>Konsument : <br><br><img src="mikro/20230209113338.png" target="_self"><br>
于c轴相交点为<br><br><img src="mikro/20230209113432.png" target="_self"> <br><br><img src="mikro/20230209113522.png" target="_self"> <br><br><img src="mikro/20230209113600.png" target="_self"> <br><br><img src="mikro/20230209113637.png" target="_self"> <br>
<br>Erstes Theorem der Wohlfahrtsökonomie: Das Konkurrenzgleichgewicht ist Pareto-effizient
<br>Zweites Theorem der Wohlfahrtsökonomie: Wenn alle Präferenzen konvex sind, dann ist jede Pareto-effiziente Allokation ein Gleichgewicht für eine entsprechende Ausstattung
<br><br>sieht Video 17: Produktionsökomomie<br><br><img src="mikro/20230209114132.png" target="_self"> <br>
<br>Ein allgemeines Gleichgewicht liegt vor, wenn die Preise genau so sind, dass die Märkte für alle Güter geräumt sind, d.h. die Summe der Nettonachfragen aller Konsumenten nach jedem Gut ist gleich der Summe des Nettoangebots an diesem Gut
<br><br><img src="mikro/20230209114324.png" target="_self"> <br><br><br><img src="mikro/20230211144930.png" target="_self"><br>
<img src="mikro/20230211144953.png" target="_self"><br>
<img src="mikro/20230211145010.png" target="_self"> <br><br> für alle Güter<br><br><img src="mikro/20230211145420.png" target="_self"> <br>
<br>
<br> <br><img src="mikro/20230211150241.png" target="_self"> <br><br><img src="mikro/20230211150308.png" target="_self"> <br><br><br><img src="mikro/20230211150650.png" target="_self"><br>
<img src="mikro/20230211150738.png" target="_self"><br>
<img src="mikro/20230211150808.png" target="_self"><br>
<img src="mikro/20230211150831.png" target="_self"><br>
<img src="mikro/20230211150850.png" target="_self"> <br><br><img src="mikro/20230211150915.png" target="_self"> <br><br><img src="mikro/20230211151012.png" target="_self"> ]]></description><link>mikro/mikro_vl13.html</link><guid isPermaLink="false">Mikro/Mikro_vl13.md</guid><pubDate>Sun, 21 Apr 2024 20:29:41 GMT</pubDate><enclosure url="mikro/20230209113338.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;mikro/20230209113338.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Mikro_07]]></title><description><![CDATA[<br><br><br><img src="mikro/20230205120910.png" target="_self"><br>
<img src="mikro/20230205121013.png" target="_self"><br>
<img src="mikro/20230205121041.png" target="_self"><br>
<img src="mikro/20230205121105.png" target="_self"> ]]></description><link>mikro/mikro_07.html</link><guid isPermaLink="false">Mikro/Mikro_07.md</guid><pubDate>Sun, 21 Apr 2024 20:29:41 GMT</pubDate><enclosure url="mikro/20230205120910.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;mikro/20230205120910.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Mikroökonomik VL06]]></title><description><![CDATA[<br><br><br><img src="mikro/20230203203903.png" target="_self"><br>
<img src="mikro/20230203203935.png" target="_self"><br>
<img src="mikro/20230203203958.png" target="_self"><br>
<img src="mikro/20230203204025.png" target="_self"><br>
<img src="mikro/20230203204056.png" target="_self"><br>
]]></description><link>mikro/mikro_06_.html</link><guid isPermaLink="false">Mikro/Mikro_06_.md</guid><pubDate>Sun, 21 Apr 2024 20:29:41 GMT</pubDate><enclosure url="mikro/20230203203903.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;mikro/20230203203903.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Readme]]></title><description><![CDATA[<br>Hier findest du die Folien, die ich in meinen Tutorien verwende. Sie behandeln den Stoff unvollständig und sind nur eine Ergänzung zum Tutorium. Fürs lernen empfehle ich euch die Zusatzvideos sehr :)]]></description><link>rechnerorganisation/tut/readme.html</link><guid isPermaLink="false">Rechnerorganisation/tut/Readme.md</guid><pubDate>Sun, 21 Apr 2024 20:27:54 GMT</pubDate></item><item><title><![CDATA[Rorg_tut12]]></title><description><![CDATA[<br><br><br><br><img src="rechnerorganisation/img_b88a7876cfcd-1.jpeg" target="_self"><br>
<img src="rechnerorganisation/20230209205748.png" target="_self"><br>
<img src="rechnerorganisation/img_46ed4549b8b6-1.jpeg" target="_self"><br>
<img src="rechnerorganisation/20230209211444.png" target="_self"><br>
ps 本图主要看ppt<br><br><img src="rechnerorganisation/20230209211620.png" target="_self"> <br><br><img src="rechnerorganisation/20230209212059.png" target="_self"><br>
先进先出的算法（FIFO）：选择在内存中驻留时间最久的页面予以替换。<br><br><img src="rechnerorganisation/20230209212748.png" target="_self"><br>
最近最久未使用算法（LRU）：选择过去最长时间未被访问的页面予以替换。<br><br><img src="rechnerorganisation/20230209213148.png" target="_self"> <br>最佳淘汰算法（OPT）：选择永不使用或在未来最长时间内不再被访问的页面予以替换。<br>
在tag=4时出现miss的情况:<br>
<br>way 0: 3在未来出现了2次
<br>way 1: 0在未来出现了3次
<br>way 2: 1在未来出现了2次
<br>way 3: 2在未来出现了2次
<br>替换way2的理由：因为way 0，2，3的值在未来出现的次数相等，根据fifo,way 2最久没有被访问<br><br>TU CLOUD: bit.lz/ROrgTUT<br><img src="rechnerorganisation/20230210102121.png" target="_self"> <br><br>
<br>Problem1 <br>wie findet die Seite("Cache-Block")ins Archiv zurueck?
<br>"Tag": merkt sich Herkunftsort("Blockadress")einer Seite <br>Problem 2 <br>Wo legen wir die Seite in die Ablage("Cache"<br>
)?
<br>z.B beliebige Stelle, wo nach Platz ist("vollassoziativ") <br>Problem 3 <br>Sortierung der Seiten in Ablage?(um Seiten schneller zu finden)
<br>"Cache-Sets": Faecher fuer Seiten mit gleichen "Anfangsbuchstaben" <br>Problem 4 <br>was machen, wenn die Ablage voll ist?
<br>"Ersetzungsstragie": alte Seite ausstauchen und zurueckbringen <br><br><img src="rechnerorganisation/20230210105051.png" target="_self"> <br><br>cache-Typen:<br>
<br>vollassoziati("fully associative"): <br>1.Satz ("Stapel"),wo alle Cache-Block <br>direkt abgebildet("Direct Mapped"): <br>assoziativitaet = 1. jeder Satz enthaelt maximal einen Cache-Block <br>n-fach satz assoziativ: <br>Assoziativtaet = n <br><br>
<br>direkt abgebildet -&gt; Assoziativitaet = 1
<br>Kapazitaet = 8 KiB = 8 * 1024 Bytes = 2^13 Bytes (und nicht 8000 Byte!!)
<br>Cacheblock-Groesse = 2^5 Bytes
<br>32, 8192, 48, 8208, 32, 8224, 48, 8240, 32, 8256<br>
Simulation: • Index, • Tag <br>Wie viele Bits hat der Blockoffset? (die Adresse innerhalb des Blocks)<br>
<br>:
<br>Wie viele Bits hat der Index?<br>
<br>Zuerst: wie viele Sätze gibt es im Cache?
<br>Satzgröße = (Cacheblock-Größe • Assoziativität) = 2^5 Bytes
<br>
<br>
<br>wie viele Bits hat der Tag?<br>
<br>Das wissen wir nicht, müssen wir nicht wissen (sagen wir, es sind genug Bits;-).)
<br>Lustig: wir haben keine vorgegebene Größe für die Adresse des Prozessor.)
<br>Blockadresse = (Adresse / Cacheblockgröße)<br>
Blockadresse = (Adresse &gt;&gt;(blockoffset Bits))<br>Index = Blockadresse % (2^(Index Bits))<br>
Index = • Blockadresse &amp; (größten Index) <br>größter Index = 2^(index bits) - 1 = 2^8 - 1 = FF16<br>
Tag = Blockadresse / 2^(Index Bits)<br>
Tag = Blockadresse &gt;&gt; (Index • Bits)<br>
<img src="rechnerorganisation/20230210160153.png" target="_self"> <br><br>
<br>2-fach•satz-assoziativ - Assoziativität=2
<br>Kapazität = 8KiB = 8 • 1024 Bytes = 2^13 Bytes
<br>Cacheblockgröße = 8 Wörter = 8•4 Bytes = 2^5 Bytes
<br>Byteaddressengröße = 40 Bits
<br>Prozessor schickt Byteadresse (1 Byte = 2 Nybble = Hexadezimalziffer):<br>
a)<br>
Wie größ ist der Index?
<br>Satzgröße = Blockgröße * Assoziativität = 2^5 • 2^1 Bytes = 2^6 Bytes <br>Anzahn an Sätze = Kapazität / Satzgröße = 2^13 / 2^6 • Bytes = 2^7 Bytes:
<br>Indexgröße = log2 ( Anzahl an Sätze ) = 7 Bit<br>
Wie groß ist der Tag?
<br>Blockoffsetgröße = log2 ( Blockgröße)Bits = log2 (2^5)Bits = 5 Bits
<br>Adressgröße - Indexgröße - Blockoffsetgröße = 40 - 7 - 5 = 28 Bits<br>
b)<br>
Adresse = [tag = 28 Bits, index = 7 Bits, blockoffset = 5 Bits ]<br>
Adresse = 55236<br>
Blockadresse = (Adresse / Blockgröße)<br>
Index = Blockadresse % 2^7 = 62
<br><br>AMAT = Average Memory Access Time (durchschnittliche Zugriffszeit)<br>
Es gibt jetzt verschiedene Fälle (verschiedene Fälle).<br>
<br>Fall: wir-finden den• Cache-Block im sog. L1-Cache
<br>Fall: wenn nicht im LI-Cache, finden wir den Cache-Block im L2-Cache
<br>Fall: wenn nicht im L2-Cache, finden wir den-Cache-Block im RAM (Random Access Memory)<br>
Für jeden Fall die Häufigkeit (Wahrscheinlichkeit) berechnen.<br>
Für jeden Fall die Zeitdauer berechnen.
<br>-&gt; AMAT = gewichtete Mittelwert<br>
-&gt; Miss-Rate = Häufigkeit eines Cache-Misses (in Prozent)<br>
<br>lokal: für jeden Cache-Zugriff, wie häufig gibt es einen Cache-Miss? (Dieser ist gegeben!! wenn nichts weiter gesagt ist.).
<br>global: wie viele Speicherzugriffe vom Prozessor landen im Cache und erzeugen einen Cache-Miss?
<br>1.Fall (L1-Cache):<br>
<br>
Zeit = 3 Takte <br>
globale Häufigkeit = 100% - 7% = 93% <br>
100% der Fälle erreichen L1-Cache, davon 93% der Fälle ein Cache-Hit
1.Fall (L2-Cache): <br>
Zeit = L1-Cache-Zeit + 15 Takte = 18 Takte <br>
globale Häufigkeit = 7% (100% - 34%) = 7% 66% = 4.62% <br>
7% der Fälle erreichen den L2-Cache, davon 66% der Fälle ein Cache-Hit
2.Fall (RAM): <br>
Zeit = L2-Cache-Zeit + 100 Takte = 118 Takte <br>
globale Häufigkeit = 7% * 34% = 100% - 93% - 4.62% = 2.38% <br>
7% der Fälle erreichen L2-Cache und dort in 34% der Fälle gehen wir zum RAM weiter <br>AMAT = 93% 3 Takte + 4.62% 18 Takte + 2.38% * 118 Takte AMAT = 6.43 Takte]]></description><link>rechnerorganisation/rorg_tut12.html</link><guid isPermaLink="false">Rechnerorganisation/Rorg_tut12.md</guid><pubDate>Sun, 21 Apr 2024 20:24:33 GMT</pubDate><enclosure url="rechnerorganisation/img_b88a7876cfcd-1.jpeg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;rechnerorganisation/img_b88a7876cfcd-1.jpeg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Rechnerorganisasion TUT 11]]></title><description><![CDATA[<br><br><br><br>was ist ein nop-Befehl<br>
<br>No Operation
<br>Befehl der nichts ausführt(keinen Zustand verändert)
<br>gewöhnlich Befehl dessen 32 Bit auf 0 gesetzt sind
<br>in MIPS: sll $zero, $zero, 0<br>
Auflösung von Datenkonflikten in Pipelined-Prozessoren:
<br>nop-Befehle <br>simpleres Design(weniger Baauteile/kostengünstig)
<br>Compiler/Programmierer muss manuell nop's einfügen <br>alternativ: Hardware-Forwarding
<br><br>
<br>
ursprüngliches Proplem bei Eintaktprozessor: Abschnitten im Eintaktprozessor werden nicht vollständig ausgenutzt. <br>
Idee: wir fangen an, Befehle auszuführen, bevor der vorherige Befehl fertig ist. <br>damit die Datenpfad-Abschnitte mehr genutzt werden (mehr Arbeit ausführen)
<br>sobald der Befehl zu den Registern geht, wird schon ein neuer Befehl aus dem Speicher geladen <br>
wir haben 5 Abschnitte: Instruction Fetch, Instruction Decode, Execute, Memory (Read/Write), Write Back <br>sobald ein Befehl in Instruction Decode ist, wird der nächste Befehl angefangen <br><br>
<br>manche Bestandteile aus dem Eintaktprozessor wurden "bewegt" an andere Stelle
<br>es gibt solche "Balken" (zusätzlichen Rechtecke) = Pipeline-Register
<br><br>
<br>
diese trennen die verschiedenen Stufen <br>
aber warum brauchen wir diese Register wirklich? <br>weil wir jede Stufe in der gleichen Zeit ausführen wollen
<br>wir wissen aus letzter Woche: die Stufen sind unterschiedlich schnell<br>
(z.B. Instruction Fetch = Speicherzugriff 150ps, Register-Lesen = 50 ps, ALU = 100ps)
<br>wir wollen nicht, dass eine frühere Stufe die nächste vorzeitig unterbricht =&gt; die Pipeline-Register halten die Eingangsdaten (für eine Stufe) und warten, bis der nächste Takt anfängt (Synchronisation) <br><br>
<br>
Datenkonflikte (Data Hazard) <br>
Register-Werte fehlen, wenn diese gebraucht werden <br>
wenn ein Befehl das Ergebnis von dem vorherigen Befehl braucht, dann ist der vorherige Befehl noch nicht fertig!!<br>
Die Daten des vorherigen Befehls sind nicht da<br>
Die gelesen Register vom nächsten Befehl (weiter links in der Pipeline) sind noch nicht upgedatet, also falsch <br>
wir können das richtige Ergebnis erst aus dem Register laden, während das Ergebnis geschrieben wird<br>
warum? <br>Idee: wir können den Takt in zwei Hälften unterteilen
<br>erste Hälfte: schreibe das Ergebnis in Register in Write Back
<br>zweite Hälfte: Register werden gelesen in Instruction Decode <br>
wie kann machen, damit Data Hazards weniger Zeit verschwenden? <br>Forwarding Unit + Hazard Detection (Ergebnis wird weitergereicht, sobald das Ergebnis berechnet wurde, also schon vor Write-Back) <br>
Steuerkonflikte (Control Hazard) <br>
die Sprungentscheidung, Sprungadresse fehlt, wenn wir diese bereits brauchen <br>
der Kontrollfluss (also die Befehlsausführung) ist verzögert (ist noch nicht entschieden) <br>
wir können Befehle ausführen, die eigentlich nicht ausgeführt werden sollen <br>
wie schneller machen? <br>"Branch Prediction" (siehe unten) <br>wenn wir häufig richtig raten, sind wir schneller <br>Sprungentscheidung viel früher berechnen (z.B. in Instruction-Decode, dafür Extra-Hardware nötig) <br>
Strukturelle Konflikte (Structural Hazard) (nennen wir nur wegen der Vollständigkeit) <br>wenn zwei Befehle dieselbe Pipeline-Stufe gleichzeitig nutzen wollen
<br>z.B. wenn es zwei Pipelines gibt (2K-Zahlen und Floating-Point-Zahlen) und diese zusammenlaufen (zusammengeführt werden) <br>Advanced Computer Architectures <br>kommen bei uns nicht vor <br>
wie verhindern (entschärfen) wir die Hazards? <br>"Stall Cycles" (Takte wo angehalten wird), "der Prozessor hält die vordere Pipeline an (Instruction Fetch und Instruction Decode)
<br>wir ignorieren das Problem, Compiler soll das Problem lösen <br>Compiler fügt "Wartebefehle" ein, "NOP"s = No operation
<br>Delay Slot (= Takte die gewartet werden müssen, bis das richtige Ergebnis da ist) = Latenz ("Bearbeitungszeit") <br>wir können auch andere Befehle statt NOPs nutzen, die fehlende Ergebnis nicht brauchen <br>"Flushing" ("herunterspülen") <br>die Pipeline bis zu Instruction Decode wird geleert (d.h. das wir die Befehle später nochmal laden) <br>für Control Hazards: wir können raten (Spekulation, "Branch Prediction"), welche Sprungentscheidung genommen wird <br>wenn wir falsch raten, dann werden wir bestraft, indem wir alle falsch ausgeführten Befehle rückgängig machen müssen ("Flushing" + andere Sachen)
<br>wenn wir richtig raten, dann sind wir richtig schnell 😀 <br><br>a)<br>
<br>ohne Optimierung: <br>wenn ein Register-Ergebnis berechnet wird, dann ist das Ergebnis die nächsten zwei Takte nicht verfügbar
<br>siehe Bild <br>0 addi *$t0* ,$a0 ,4
1 addi *$t1* ,$a1 ,4
2 sub $t2 ,*$t0* ,*$t1*
3 sll *$t3* ,$a2 ,2
4 add *$t4* ,$t0 ,*$t3*
5 add $t5 ,$t1 ,*$t3*
6 sw $t2 ,0( *$t4* )
复制<br>b)<br>
<br>keine Reihenfolge ändern, nur Wartebefehle (NOPs) einfügen
<br>0 addi $t0 ,$a0 ,4 1 addi $t1 ,$a1 ,4 1.2 nop
1.3 nop 2 sub $t2 , $t0 , $t1 3 sll $t3 ,$a2 ,2 3.1 nop
3.2 nop 4 add $t4 ,$t0 , $t3 5 add $t5 ,$t1 , $t3 5.1 nop 6 sw $t2 ,0( $t4 )
复制<br>c)<br>
<br>noch besser machen: jetzt so wenig wie möglich NOPs brauchen, Befehle umordnen
<br>wie vorgehen ? wir gucken, welche Befehle brauchen das Ergebnis von welchen anderen Befehlen? =&gt; grafisch aufzeichnen <br>List Scheduling (siehe Internet? → Compiler Design Kurs. Statt "Aufträge" "Maschinen" zuzuweisen, weisen wir der Pipeline neue Befehle zu) <br><br>a)<br>
<br>
Speicherzugriff = 200ps, ALU-Operation = 100ps, Registerzugriff = 50ps <br>
Benchmark (Programm, um die Ausführungszeit zu messen) <br>
Annahmen: gleiche Anzahl an Befehle für beide Prozessoren <br>
Jeder Prozessor hat eine (eigene) konstante Taktzeit, T_SC = Taktdauer des Eintaktprozessor (Single Cycle), T_PP = Taktdauer für Pipeline-Prozessor <br>
es gibt keine Data Hazards mehr (wurden entfernt durch Umordnung) <br>
es gibt aber alle Control-Hazards noch! -&gt; jeder Sprungbefehl dauert 4 Takte! Der Prozessor hält bei Sprungbefehlen einfach an! <br>
Speicherbefehle -&gt; 12% (1 Takt pro Speicherbefehl weil keine Datenkonflikte Data Hazards) <br>
ALU-Befehle -&gt; 72% (1 Takt pro Speicherbefehl weil keine Datenkonflikte) <br>
Sprung-Befehle -&gt; 16% (4 Takte pro Sprungbefehl, wegen den Steuerkonflikten Control Hazards) <br>
wozu die Informationen? Damit wir die Schnelligkeit des Pipeline-Prozessors berechnen können. Eintaktprozessor führt jeden Befehl gleichschnell aus <br>
unbekannte Anzahl N an Befehlen <br>
Pipeline ist zu Beginn der Benchmark gefüllt <br>
Speedup berechnen, S = Vergleichszeit t_SC / (betrachtete Zeit) t_PP -&gt; wie viel Faktor schneller ist der betrachtete Prozessor <br>
t_SC = Ausführungszeit Eintaktprozessor = (Anzahl an Takte) · (Taktdauer) = (N · CPI_SC) · T_SC <br>
t_PP = Ausführungszeit Pipelineprozessor = (Anzahl an Takte) · (Taktdauer) = (N · CPI_PP) · T_PP <br>
CPI = Befehlsdauer in Takten = wie lange braucht ein Befehl an Takten zur Ausführung <br>CPI_SC = 1 da jeder Befehl einen Takt braucht
<br>CPI_PP = jeder Befehl braucht unterschiedlich viele Takte (hängt ab von den Hazards) <br>gewichteter Mittelwert: 12% 1 + 72% 1 + 16% * 4 = 1.48 <br>
T = Taktdauer, wie viel Sekunden braucht ein Takt <br>T_SC = 600ps = 2·200ps + 100ps + 2·50ps (2-mal Speicherzugriff, 2-mal Registerzugriff, 1-mal ALU)
<br>T_PP = maximale Dauer einer Stufe = 200ps (wir brauchen eine Taktdauer in der jede Stufe ausgeführt wird) <br>
S = (N · CPI_SC) · T_SC / ((N · CPI_PP) · T_PP) = 600ps / (1.48 * 200ps) = 2,027027027… = 2 + 27/999 <br>b) wie können wir den Pipeline-Prozessor schneller machen? siehe Aufgabe 1<br>c) Was ist, wenn wir nur die ALU schneller machen, um 25% ?<br>ALU-Operation braucht nur 75ps<br>-&gt; T_SC = 2·200ps + 75ps + 2·50ps = 575ps<br>T_PP ändert sich nicht!! Immernoch die gleichen Hazards, und Speicherbefehle dauern immernoch 200ps<br>=&gt; der Speedup wird schlechter, weil der Pipeline-Prozessor nicht profitiert<br>=&gt; Pipeline wird nur schneller, wenn man die am längsten dauernde Stufe optimiert.<br><br><img src="rechnerorganisation/20230203105924.png" target="_self"><br>
<img src="rechnerorganisation/bildschirm­foto-2023-02-03-um-10.51.40.png" target="_self"><br>
<img src="rechnerorganisation/bildschirm­foto-2023-02-03-um-11.48.40.png" target="_self"><br>Aufgabe 3<br>a) Verbesserung ist, dass man die EX und MEM-Stufe zusammenlegen kann. Die Pipeline wird kürzer. Load-Use-Konflikte sind einen Takt schneller (0 statt 1 Takte Verzögerung).<br>b)<br>Verbesserungen gibt es, wenn Speicherfefehle keinen Offset brauchen<br>das ist der Fall bei Array-Zugriffen in Schleifen oder Integer-Pointer<br>alle anderen Zugriffe brauchen einen Offset<br>wenn man einen konstanten Offset braucht, wird man verlangsamt<br>der Offset muss in Extra-Befehl berechnet werden<br>der zusätzliche Befehl wird nur durch kürzere Load-Use-Hazards kompensiert<br>verbraucht ein Register (erhöht den Registerdruck), sowie zusätzlichen Platz im Befehlsspeicher (Cache-Verschmutzung)<br>in Praxis brauchen wahrscheinlich mehr Befehle einen konstanten Offset als keinen<br>alle struct-, Objekt-Zugriffe brauchen einen; häufiger Spezialfall: Stack-Frames<br>häufig in Praxis, vor allem Stack Frames, da es viel mehr innere Funktionsaufrufe mit Stack als Blatt-Funktionsaufrufe ohne Stack gibt.<br><img src="rechnerorganisation/20230203131555.png" target="_self"><br>
<img src="rechnerorganisation/20230203131618.png" target="_self"><br>
<img src="rechnerorganisation/20230203131640.png" target="_self"> ]]></description><link>rechnerorganisation/rorg_tut11.html</link><guid isPermaLink="false">Rechnerorganisation/Rorg_tut11.md</guid><pubDate>Sun, 21 Apr 2024 20:24:33 GMT</pubDate><enclosure url="rechnerorganisation/20230203105924.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;rechnerorganisation/20230203105924.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Rechnerorganisasion TUT 10 - Leistung]]></title><description><![CDATA[<br><br><br>Taktfrequenz = 1 / T (wie viele Befehle passen in eine Sekunde)<br>
T = die Zeitdauer eines (jedes) Befehls (im Eintaktprozessor und im Pipeline-Prozessor)<br>minimale Taktzykluszeit = kürzestes Zeitdauer, die man mindestens braucht, um JEDEN ausführen zu können<br>
-&gt; man guckt sich den längsten Befehl an (weil wir keine unterschiedliche Taktdauer für unterschiedliche Befehle haben können)<br>Hauptspeicher = RAM (Random Access Memory) , [aber in allermeisten Fällen liegen noch Caches zwischen dem Prozessor und dem RAM]<br><br>a) Taktze<br>
it berechnen:<br>t₁ = Zeitdauer für Fetch (Speicherzugriff)<br>
t₂ = Zeitdauer für Decode (Registerzugriff) [es werden auch Steuersignale berechnen, kommt aber in Aufgabe nicht vor]<br>
t₃ = Zeitdauer für Execute (ALU-Operation)<br>
t₄ = Zeitdauer für Memory (Speicherzugriff)<br>
t₅ = Zeitdauer für WriteBack (Registerzugriff)<br>load-word ist der längste Befehl, weil load-word alle Befehlsschritte ausführen muss<br>Deshalb, alle Befehlsschritt addieren:<br>T = Summe( t₁ + t₂ + t₃ + t₄ + t₅ ) = 2·150ps + 2·50ps + 100ps = 500ps<br>
entspricht 2 GHz<br>echo "$(( 2 * 150 + 2 * 50 + 100 ))"
复制<br>b)<br>
Ziel: Befehl um 1.15x schneller machen, indem wir eine Komponente (d.h. Speicherzugrif, Registerzugriff oder ALU-Operation) schneller (= kürzer) machen<br>Speedup =! 1.15<br>
S = / = T / ( 2·150ps / α + 2·50ps / β + 100ps / γ )<br>
T = 500ps<br>ps = Pikosekunde = 10⁻¹² (1 Billionstel)<br>α = Verschnellerung von Speicherzugriff<br>
β = Verschnellerung von Registerzugriff<br>
γ = Verschnellerung von ALU-Operation<br>
<br>
Fall 1: β = γ = 1,
α = ? damit S = 1.15 ist?<br>
1.15 = 500ps<br>
&lt;=&gt; ( 2·150ps / α + 2·50ps / β + 100ps / γ ) · 1.15 = 500ps<br>
&lt;=&gt; 2·150ps / α = 500ps / 1.15 - (2·50ps / β + 100ps / γ)<br>
&lt;=&gt; α = 2·150ps / ( 500ps / 1.15 - (2·50ps + 100ps) ) # β = γ = 1<br>
&lt;=&gt; α = 1.2777... = 115/90
Zeit Speicherzugriff neu = 150ps / α = 117.4ps <br>
Fall 2: α = γ = 1
β = 2·50ps / ( 500ps / 1.15 - (2·150ps / α + 100ps / γ) )<br>
β = 2.875 = 23/8
Zeit Registerzugriff neu = 50ps / β = 17.4ps <br>
Fall 3: α = β = 1
γ = 100ps / ( 500ps / 1.15 - (2·50ps / β + 2·150ps / α) )<br>
γ = β
Zeit ALU-Operation neu = 100ps / γ = 34.78ps <br>[schneller heißt: kürzere Zeit]<br>
Speicherzugriff: S = 500ps / (2·150ps / S₁ + 200ps) =! 1.15 <br>S₁ = 2·150ps / (500ps / 1.15 - 200ps) = 1.2777… = 1 + 2/9 + 5/90 = 115/90 Registerzugriff: S = 500ps / (400ps + 2·50ps / S₂) =! 1.15 <br>S₂ = 2·50ps / (500ps / 1.15 - 400ps) = 2.875 = 3 - 1/8 = 23/8 ALU-Operation: S = 500ps / (400ps + 100ps / S₃) =! 1.15 <br>S₃ = 100ps / (500ps / 1.15 - 400ps) = S₂ <br><br>a)<br>
Durschnittslaufzeit der Programme berechnen.<br>( ∑ )/n = ( + + + ) / 4 = sum( liste ) / len( liste )<br>Computer 1: = 67.25<br>
Computer 2: = 88.25<br>Computer 1 gewinnt, da weniger Zeit pro Progamm nötig!<br>b)<br>
Häufigkeit der Programme berücksichtigen.<br>Fehler: ( ∑ · ) / n = ( · + … · ) / 4<br>
Richtig: ∑ · = · + … · <br>Computer 1: = 46.16<br>
Computer 2: = 23.5<br>Computer 2 gewinnt!<br>c) Warum oder wie lässt sich das (der Unterschied) erklären?<br>
<br>Der Unterschied kommt dadurch zustande, dass die Programme, in denen C1 besser ist, so selten gebraucht werden, dass C2 insgesamt in der Nutzungszeit alle Programmaufrufe schneller ausführt.
<br>Möglichkeit:<br>
Programm 1: Browser fürs Internet<br>
Programm 2: Computerspiele (3D-Grafik-Berechnungen)<br>
Programm 3: numerische Berechnungen als Uni-Hausaufgaben<br>
Programm 4: MARS-Simulator oder andere seltene GUI-Anwendungen<br>=&gt; Computer 2 wäre ein Gaming-PC<br>=&gt; andere Möglichkeit: Server-Computer<br>
Programm 1: Verschlüsselung und Sicherheit<br>
Programm 2: Nutzeranfrangen bearbeiten<br>
Programm 3: Konsolenprogramme<br>
Programm 4: grafische Anwendungen<br><br>Wir vergleichen 3 Computer anhand der Speedups zwischen Programmen.<br>Referenzmaschine heißt, als Maßstab zum Vergleich anderer Maschinen (Computer).<br>Wir bilden die Verhältnisse zwischen den Ausführungszeiten. Referenzmaschine soll Computer 2 sein.<br> = / # elementweise Division!<br> = / = 1<br> = / <br>Produkt = · · ( numpy.prod() )<br>
geometrische Mittel = n√Produkt (in diesem Fall n = 3)<br>3√( x ) mit numpy.cbrt() (cube root) berechnen<br>geometrisches Mittel = numpy.cbrt( numpy.prod( ) )<br>Computer 1: geom. Mittel = 1.918<br>
Computer 2: geom. Mittel = 1<br>
Computer 3: geom. Mittel = 1.32<br>Schneller ist Computer mit geringsten geometrischen Mittel. Das kleinste geometrische Mittel hat der Computer, der im Vergleich zu C2 am schnellsten. (Je schneller der Computer, desto kleiner ist der Speedup von C2)<br>Problem:<br>
verschiedene Speedups können wir nicht vergleichen. Mehrere Speedupwerte verhalten wie Vektoren.<br>Der gleiche Speedup kann in der menschlichen Wahrnehmung einen riesigen Unterschied bedeuten.<br>
Beispiel: S = 3<br>
Fall 1: Programm 1 von Computer 1 braucht 100ms und Programm 1 von Computer 2 braucht dann 300ms<br>
Fall 2: Programm 2 von Computer 1 braucht 3 Tage und Programm 2 von Computer 2 braucht 1 Tag.<br>=&gt; geometrische Mittel hat hier keine richtige Bedeutung<br><br>$ python3
Python 3.8.10 (default, Nov 14 2022, 12:59:47) [GCC 9.4.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; 2 * 150 / ( 500 / 1.15 - 200 )
1.2777777777777777
&gt;&gt;&gt; 2 * 50 / ( 500 / 1.15 - 400 )
2.874999999999999
&gt;&gt;&gt; 115 / 180 * 150
95.83333333333333
&gt;&gt;&gt; 23 / 8 / 2 * 50
71.875
&gt;&gt;&gt; (23 / 8) / 2 * 50
71.875
&gt;&gt;&gt; 50 / (23 / 8)
17.391304347826086
&gt;&gt;&gt; 100 / (23/8)
34.78260869565217
&gt;&gt;&gt; 150 / ( 115/90 )
117.3913043478261
&gt;&gt;&gt; t_C1 = [ 23, 55, 82, 109 ]
&gt;&gt;&gt; t_C2 = [ 16, 21, 127, 189 ]
&gt;&gt;&gt; import numpy
&gt;&gt;&gt; numpy.mean( t_C1 )
67.25
&gt;&gt;&gt; numpy.mean( t_C2 )
88.25
&gt;&gt;&gt; w = [ 0.31, 0.66, 0.02, 0.01 ]
&gt;&gt;&gt; numpy.dot( w, t_C1 )
46.16000000000001
&gt;&gt;&gt; numpy.dot( w, t_C2 )
23.25
&gt;&gt;&gt; numpy.dot( w, t_C1 ) / 4
11.540000000000003
&gt;&gt;&gt; numpy.dot( w, t_C2 ) / 4
5.8125
&gt;&gt;&gt; exit()
elmar@linux:~$ python3
Python 3.8.10 (default, Nov 14 2022, 12:59:47) [GCC 9.4.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; t_C1 = [ 16, 60, 50 ]
&gt;&gt;&gt; t_C2 = [ 5, 17, 80 ]
&gt;&gt;&gt; t_C3 = [ 25 ] * 3
&gt;&gt;&gt; import numpy
&gt;&gt;&gt; t_C1 = numpy.array( t_C1 )
&gt;&gt;&gt; t_C2 = numpy.array( t_C2 )
&gt;&gt;&gt; t_C3 = numpy.array( t_C3 )
&gt;&gt;&gt; S_C1 = t_C1 / t_C2
&gt;&gt;&gt; S_C2 = t_C2 / t_C2
&gt;&gt;&gt; S_C3 = t_C3 / t_C2
&gt;&gt;&gt; print(S_C1)
[3.2 3.52941176 0.625 ]
&gt;&gt;&gt; print(S_C2)
[1. 1. 1.]
&gt;&gt;&gt; print(S_C3)
[5. 1.47058824 0.3125 ]
&gt;&gt;&gt; numpy.cbrt( numpy.prod( S_C1 ) )
1.9182745937205048
&gt;&gt;&gt; numpy.cbrt( numpy.prod( S_C2 ) )
1.0
&gt;&gt;&gt; numpy.cbrt( numpy.prod( S_C3 ) )
1.319583989972501 复制<br><br>Wir haben 2 engere Kandidaten für die Wahl eine Computer-Systems.<br>Dieses Computer-System soll P1 und P2 ausführen, wobei P1 doppelt so häufig ausgeführt wird.<br>Der schneller Computer soll diese Programm-Kombination in einer kürzeren Zeit ausführen.<br>Zeit für ein Computer-System: Ausführungsdauer = 2 · + 1 · <br>Jedes Programm hat eine feste Anzahl an Befehlen.<br>
Dauer eines Programms = Anzahl an Befehlen / Taktfrequenz = Anzahl an Befehlen / (Befehle / Sekunde)<br> = Befehle von P1 / ( Taktfrequenz )<br> = Befehle von P2 / ( Taktfrequenz )<br>GHz = 10⁹ (Milliarden Befehle pro Sekunde)<br>System C1:<br> = 8 · 10⁹ / ( 2 · 10⁹ ) = 4s<br> = 6 · 10⁹ / ( 2 · 10⁹ ) = 3s<br>
Ausführungsdauer = 2·4s + 3s = 11s<br>System C2:<br> = 11 · 10⁹ / ( 2.5 · 10⁹ ) = 4.4s<br> = 10 · 10⁹ / ( 2.5 · 10⁹ ) = 4s<br>
Ausführungsdauer = 2·4.4s + 4s = 12.8s<br>System 1 führt die Programmme schneller aus und wäre nach dem Schnelligkeits-Kriterium besser geeignet.<br><br>Verschiedene Zeitdauern (Längen) verschiedener Befehle.<br>
Wir wollen (ausschließlich) Speicherbefehle schneller machen.<br>gegeben: wie viele Befehle in unseren Programmen sind Speicherbefehle? α = 80% = 0.8<br>Die Frage ist natürlich, wie viel müssen wir die Speicherbefehle optimieren?<br>Die Befehle werden jetzt aufgeteilt<br> = (1 - α) · T + α · T = T<br> = (1 - α) · T + α · T / <br>S = / = / <br>Es soll S = 3 oder S = 5 überprüft werden. Wir wollen gucken, ob es überhaupt möglich ist.<br>Wie groß ist ? Betrachtung für S = 3, S = 5<br>Lösung:<br>S = T / ( (1 - α) · T + α · T / ) = 1 / ( (1 - α) + α / )<br> ? Umstellen<br> = α / (1 / S - (1 - α))<br>Fall 1: S = 3<br> = 0.8 / (1 / 3 - 0.2 ) = (4/5) / ( 1/3 - 1/5 ) = (12/15) / ( 2/15 ) = 12/2 = 6<br>=&gt; hoher Speedup der Speicherbefehle nötig<br>Fall 2: S = 5<br> = α / (1 / S - (1 - α))<br> = 0.8 / ( 1 / 5 - 0.2 ) = 0.8 / 0 !!<br>
Durch 0 zu teilen ist nicht definiert!<br>
d.h. es gibt kein <br>Grenzwertbetrachtung: =&gt; <br>
Unendlich bedeutet, dass Speicherzugriff 0s benötigen.<br>was wäre denn, wenn wir sogar S &gt; 5 wollen?<br>
Dann würde rauskommen, dass &lt; 0 . Speicherzugriffe führen in die Zeit zurück!! Geht nicht.]]></description><link>rechnerorganisation/rorg_tut10.html</link><guid isPermaLink="false">Rechnerorganisation/Rorg_tut10.md</guid><pubDate>Sun, 21 Apr 2024 20:24:33 GMT</pubDate></item><item><title><![CDATA[Rorg_tut09]]></title><description><![CDATA[<br><br><br><br><img src="rechnerorganisation/20230211202202.png" target="_self"><br>
<img src="rechnerorganisation/20230211202257.png" target="_self"> <br><br><img src="rechnerorganisation/20230211202413.png" target="_self"> <br><br><img src="rechnerorganisation/20230211202621.png" target="_self"><br>
右下图:Wie viele Takte benötigt eine Instruktion?(CPI)<br><br><img src="rechnerorganisation/20230211202841.png" target="_self"><br>
<img src="rechnerorganisation/20230211202918.png" target="_self"><br>
<img src="rechnerorganisation/20230211202943.png" target="_self"> <br><br>
<br>R-Typ-Befehl (ALUSrc = 0, RegDst = 1)
<br>I-Typ-Befehl (ALUSrc = 1 (meistens), RegDst = 0)
<br>J-Typ-Befehl (haben wir nicht im Datenpfad)
<br>Speicherbefehle (lw, sw) <br>MemToReg = 1, MemWrite, MemRead, RegWrite
<br>Branch = 0 <br>Rechenbefehle (add, sub, and, or, sll, …) <br>MemToReg = 0, RegWrite = 1
<br>MemRead = 0!!, MemWrite = 0, Branch = 0 <br>Sprungbefehle <br>Branch = 1 (bzw. Jump = 1)
<br>RegWrite = 0, MemRead = 0!!, MemWrite = 0 <br><br>
<br>Schritt 1: Befehlsverhalten definieren
<br>Schritt 2: Funktion als Schaltnetz entwerfen <br>Eingabe: <br>≤ 2 Register-Werte, ≤ 1 16-Bit-Konstanten, 32-Bit-Befehl <br>Ausgabe: <br>nächste Befehlsadresse (PC)
<br>Ergebniswert(e) (optional)
<br>Zieladresse (Register und/oder RAM, optional) <br>Schritt 3: Schaltnetz auf bestehenden Datenpfad abbilden <br>alle nutzbaren Elemente im Datenpfad wiederverwenden <br>Schritt 4: Steuersignale/Muxe hinzufügen (um Befehl zu aktivieren)
<br><br><br>a) was beeinflusst die Veränderung des Registerinhalts in einem Befehl?<br>direkten Einfluss:<br>
<br>RegDst: R-Typ und I-Typ-Befehle -&gt; RT = Instruction[16 bis 20] und RD = Instruction[11 bis 15] (als Bitfelder im Befehl) <br>RegDst = 0 =&gt; RT ausgewählt (immer für I-Typ), RegDst = 1 =&gt; RD ausgewählt (immer für R-Typ)
<br>R-Typ [ Opcode, RS, RT, RD, shift amount, Func ] =&gt; RD = ...
<br>I-Typ [ Opcode, RS, RT, imm16 ] =&gt; RT = ... <br>RegWrite: Bestimmt, ob die Daten am Write-Data-Port in das Zielregister geschrieben werden sollen
<br>MemToReg: gibt an, von wo die Daten zum Schreiben kommen. MemToReg = 1 heißt, dass die Daten vom "Memory" kommen.
<br>indirekten Einflus:<br>
<br>MemRead: wenn = 1, kann es Daten für die Register aus dem Hauptspeicher lesen
<br>ALUOp: bestimmt, wie mögliche Daten zum Schreiben berechnet werden
<br>ALUSrc: bestimmt, wie mögliche Daten zum Schreiben berechnet werden (meistens: I-Typ =&gt; ALUSrc = 1, immer: R-Typ =&gt; ALUSrc = 0)
<br>keinen Einfluss:<br>
<br>Branch (beeinflusst nur PC)
<br>MemWrite: das Schreiben vom Hauptspeicher verändert die möglichen geschriebenen Registerdaten nicht
<br>b) welche Steuersignale beeinflussen das Beschreiben des Hauptspeicher (RAM – Random Access Memory)<br>
<br>MemWrite
<br>MemRead (es gibt eine Optimierung des Speicherzugriffs, die nennt sich Cache, und dort werden Lesezugriffe gemerkt. Dieser Cache verändert sich, wenn man liest, was zwar keine funktionale aber einen Performance-Unterschied macht. Zusätzlich kann man beim Lesen auf bestimmte Speicheraddressen Register von Hardware außerhalb des Prozessors verändern, weil diese so funktioniert. Deshalb sollte führt das Lesen zu einer Zustandsänderung des Computers bzw. des Speichers.)
<br>Andere Steuersignale nicht, denn diese beschreiben nur Veränderungen in den Prozessorregistern.<br><br>a) welche Steuersignale dürfen niemals (bei keinem Befehl) einen nicht-definierten (beliebigen) Wert annehmen?<br>
<br>Branch: <br>weil Branch das Überschreiben des Programm-Counters direkt beeinflusst und der nächste Wert des PCs für jeden Befehl fest definiert ist <br>RegWrite, MemWrite: <br>es ist für jeden fest definiert, ob und welche Register wir schreiben und welche Speicheradresse <br>MemRead: <br>nur = 1, wenn wir wirklich lesen wollen
<br>weil: das Lesen von Hauptspeicher beeinflusst den Cache (eine Hardware-Optimierung), die sich Lesezugriffe merkt, um diese zu beschleunigen <br>b) welche Steuersignale sind egal, wenn RegWrite = 0?<br>
<br>in dem Fall: Write-Data und Write-Register-Ports (vom Register File) sind dann egal, sodass <br>RegDst beliebig sein kann
<br>MemToReg beliebig sein kann <br>NICHT EGAL! ist <br>ALUSrc
<br>ALUOp
<br>weil ist möglich, dass wir einen Schreibbefehl ausführen (sw, sb) <br>in dem Fall nutzen wird die ALU, um die Speicheradresse zu berechnen <br>c) welche Funktionalität (oder welcher Befehl) passiert (wohl), wenn RegWrite = 1, MemRead = 1, MemToReg = 1 ist?<br>
<br>MemRead = 1 liest Daten aus dem Speicher,
<br>MemToReg = 1 leitet gelesene Daten aus Hauptspeicher zu Register-File (Registersatz) weiter
<br>anliegende Daten am Register-File werden mit RegWrite = 1 in ein Register geschrieben
<br>naheliegender Befehl: load word (lw)<br>
Berechnung der Speicheradresse nicht vorgegeben (könnte beliebig sein)<br><br>ADDI:<br>
<br>RegDst: wegen I-Typ wollen wir nach RT schreiben, das machen wir mit RegDst = 0
<br>Branch = 0, da wir nach dem Befehl den nachfolgenden Befehl ausführen
<br>MemRead = 0, da wir nur ein Registerwert berechnen wollen, keine Speicherveränderung
<br>MemToReg = 0, damit wir das ALU-Ergebnis an das Register weiterleiten können
<br>ALUOp = 00; die linke 0 sagt, dass es keinen Func-Code gibt und das rechte Bit bestimmt, ob Addition (= 0) oder Subtraktion (= 1) ist
<br>MemWrite = 0, weil wir den Hauptspeicher nicht verändern wollen
<br>ALUSrc = 1, da wir einen I-Typ-Befehl haben und mit der Immediate rechnen wollen
<br>RegWrite = 1, damit wir unser Additionsergebnis in das Register reinschreiben können
<br><br>a) BGTZ zum Datenpfad hinzufügen.<br>Schritt 1: Verhalten definieren.<br>
BGTZ $rs, Label (Label = PC + 4 + imm4 )<br>
PC = PC + 4 + ( RS &gt; 0 ? immediate 4 : 0) // a ? b : c === if a then b else c<br>Schritt 2:<br>
<br>Eingabe: PC, RS, imm = (Label - 4)/4 =&gt; RT = $0 (weil nicht angegeben)
<br>Ausgabe: PC
<br> Schaltnetz:<br>
PC = PC + 4 + X -&gt; 2-mal Addition<br>
X = ( RS &gt; 0 ? immediate * 4 : 0)<br>PC = ( RS &gt; 0 ? PC + 4 + immediate * 4 : PC + 4 ) =&gt; nur noch 2 Additionen
复制<br> Nebenbemerkung: $rs &gt; 0 &lt;==&gt; $rs[31] = 0 (d.h. $rs ≥ 0) und $rs ≠ 0<br> PC ---+---+ | + |--+-----------------+---+ 4 ----+---+ | |MUX|----- PC | +--+---+ | | | +------+---+ | | | + |---+ | imm --- (&lt;&lt; 2) -----+---+ | | $rs[31] -----------------o+---+ | | &amp; |--+ $rs --------(NOR32)------o+---+
复制<br>Schritt 3: Schaltung in Datenpfad einfügen und möglichst viele Komponenten wiederverwenden<br>
<br>
Zero-Signal gibt an, ob das ALU-Ergebnis = 0 ist! NOR32 kann durch zero-Signal ersetzt werden. <br>
Addierer und Multiplexer sind schon vorhanden, Befehle und Operanden (Register) laden ist auch vollständig vorhanden.<br>
=&gt; $rs[31] können wir durch das oberste Bit des ALU-Ergebnisses (oder des oberen ALU-Eingangs) erhalten <br>
Zusätzlich brauchen wir ein OR-Gatter zwischen dem AND und dem Multiplexer, um die Möglichkeit für andere Branch-Befehle offen zu halten. <br>Schritt 4: ein Steuersignal (und gegebenenfalls ein zusätzlicher Multiplexer) hinzufügen, um unseren Befehl zu de-/aktiveren<br>
<br>bgtz-Steuersignal ausgehend von der Control Unit bis zu dem neu eingefügten AND-Gatter einzeichnen. Dieses schaltet das UND-Gatter an/aus und damit auch den Befehl.
<br>b) Steuersignale setzen, um den Befehl auszuführen.<br>
<br>neues Steuersignal: BGTZ muss = 1 sein
<br>Branch = 0, das ist zwingend notwendig, den Branch = 1 bedeutet, dass BEQ ausgeführt wird.
<br>RegWrite = 0 =&gt; RegDst = X, MemToReg = X
<br>MemRead = MemWrite = 0
<br>Rechenoperation auswählen (Addition) <br>ALUOp = 00
<br>ALUSrc = 0!! obwohl I-Typ-Befehl (weil wir die Immediate nicht für ALU sondern PC-Berechnung nutzen) <br>das können wir machen, weil $rt = $0 ist ]]></description><link>rechnerorganisation/rorg_tut09.html</link><guid isPermaLink="false">Rechnerorganisation/Rorg_tut09.md</guid><pubDate>Sun, 21 Apr 2024 20:24:33 GMT</pubDate><enclosure url="rechnerorganisation/20230211202202.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;rechnerorganisation/20230211202202.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Rorg_tut07]]></title><description><![CDATA[<br><br>li = load immediate = lui + ori<br>bgt = branch if greater than = slt + bne<br>Core Instruction (echte Befehle)<br>add, sll, slt<br>Register<br>at = v0 = $2<br>
...<br>t(x) = t8 = $24<br>s1 = s2 = s3 = $19 + 3<br>$s(x) = $16 + x<br>Opcode-Tabelle (MIPS-Green-Card)<br>Linker Kasten wichtig:<br>
Mittlere Spalte = R-Typ<br>
Linke Spalte = I-Typ und J-Typ<br>(Rechte Spalte = Floating-Point)<br>Mittlerer Kasten: Name des Befehls als Zahl in verschiedener Darstellung<br>Rechter Kasten: nicht wichtig, nur um ASCII-Zeichen zu übersetzen<br>J-Typ-Format<br>Speichern die unteren 28-Bit des Program Counters (aber nicht die obersten 4 Bits!!)<br>Jeder Befehl ist 32-Bit = 4 Byte groß, d.h. dass jede Befehlsadresse ist durch 4 teilbar. D.h. die letzten beiden Bits = 0 sind.<br>0x000101011101010101...110100<br><br>jr	$ra =&gt; R-Typ, Func rs<br>
rs = $ra = 31<br>
[ 000000, 31 , 0 , 0 , 0 , 8 ]
<br>addi $a0, $a0, 4 =&gt; I-Typ (Opcode wird verwendet)<br>
Opcode rt, rs, imm<br>
[ Opcode = 8 , rt = $a0 = 4, rs = $a0 = 4, 4 ]
<br><br><br>Bei BEQ haben wir nur kleine Immediate (16-Bit) zum springen<br>
<br>BEQ-Befehlsadresse (Beispiel):<br>
1011 0111 0101 01 [0000 0000 0000 0101] 00<br>
16-Bit
<br>Addition mit PC erlaubt uns, auch Adressbits überhalb den 18 untersten Bits zu verändern.<br>
Häufig sind Programme groß, sodass häufiger Sprünge vorkommen, in denen die Adressbits über den unteren 18 Bits sich verändern.<br>
<br>J-Befehlsadresse:<br>
1011 [00 0000 0000 0000 0000 0000 0101] 00<br>
26-Bit
<br>obere 4 Bits der Befehlsadresse ändern sich in einem Program selten, deshalb reicht es, wenn die Konstante im J-Typ-Befehl bloß die unteren Adressbits ersetzt (ohne Addition).<br>Falls ein Sprung alle Adressbits verändern können soll: JR-Befehl (Zieladresse ist ein Registerinhalt)<br>a)<br>
[ bne, … , … , imm = 13 ]<br>PC = 100 020 + 4 = 100 024 (nächster Befehl)<br>
13 &lt;&lt; 2 == 13 * 4 = 52<br>Zieladresse = L1 = 52 + PC = 100 076<br>
=&gt; 100 076 (Ergebnis)<br>b)详细见single cycle ppt p42<br>
[ j , imm = 170 012 ]<br> PC[28..31] 复制<br>PC = 150 020 + 4 = [0000] … … … … … … …00 ₂<br>
高4位为0<br>
Zieladresse = L1 = { PC[28..31] , 170 012 &lt;&lt; 2 } // "," bedeutet Bits nebeneinander zu stecken (konkatenieren)<br>170 012 &lt;&lt; 2 == 170 012 * 4 == 680 048<br>"&lt;&lt; 2" bedeutet einfach nur, dass zwei untere 0-Bits dazukommen<br>L1 = { 0 , 680 048 } // oberen 4 Bits sind 0 und haben daher keinen Einfluss auf den Zahlenwert der Adresse<br>
L1 = 680 048<br>7.4)<br>
<br>Schritt: obere 6-Bit (Opcode) anschauen
<br>Schritt: welches Format, dann welcher Befehlsname herausfinden
<br>Schritt: die Felder aus dem Machinenbefehl ablesen (rs, rt, rd, shamt, imm)
<br>Schritt: in richtiger Reihenfolge in den Befehl schreiben (siehe Mips-Greencard bei Core Instructions)
<br>Zeile 1 Befehlsadresse = L1 = 0x1004:<br> Opcode rs rt rd shamt Func
复制<br>0x00004020 = [0000 00][00 000][0 0000] [0100 0][000 00][10 0000] ₂<br>Opcode = 0 =&gt; R-Typ-befehl<br>
Func = 10 0000 =&gt; 32 =&gt; ADD rd, rs, rt<br>
rd = 01000 = $8 = $t0<br>
rs = 00000 = $0 = $zero<br>
rt = 00000 = $0 = $zero<br>=&gt; L1: ADD $t0, $zero, $zero<br>Zeile 2 Befehlsadresse = L2 = 0x1008:<br> Opcode rt rs imm
复制<br>0x21080001 = [0010 00][01 000][0 1000][0000 0000 0000 0001] ₂<br>Opcode = 8 =&gt; kein R-Typ =&gt; ADDI rt, rs, imm<br>
rt = 01000 = $8 = $t0<br>
rs = 01000 = $8 = $t0<br>
imm = 00…01 = 1<br>=&gt; L2: ADDI $t0, $t0, 1<br>Zeile 3 Befehlsadresse = L3 = 0x100C:<br> Opcode imm = 0x401
复制<br>0x08000401 = [0000 10] [00 0000 0000 0000 0100 0000 0001] _2<br>Opcode = 2 =&gt; kein R-Typ =&gt; J imm<br>Sprungziel = imm &lt;&lt; 2 == 0x1004 == L1 !!<br>=&gt; L3: J L1]]></description><link>rechnerorganisation/rorg_tut07.html</link><guid isPermaLink="false">Rechnerorganisation/Rorg_tut07.md</guid><pubDate>Sun, 21 Apr 2024 20:24:33 GMT</pubDate></item></channel></rss>