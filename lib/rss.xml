<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Obsidian Vault]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>lib/media/favicon.png</url><title>Obsidian Vault</title><link/></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Sun, 28 Apr 2024 11:43:17 GMT</lastBuildDate><atom:link href="lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Sun, 28 Apr 2024 11:43:11 GMT</pubDate><ttl>60</ttl><dc:creator/><item><title><![CDATA[Vererbung - Polymorphie]]></title><description><![CDATA[<br><br>
<br> Objekte einer Klasse kÃ¶nnen auch als Objekte der Superklasse<br>
behandelt werden
<br> Objekte gleicher Superklasse kÃ¶nnen so z.B. in einem Array<br>
zusammen gespeichert werden
<br><img alt="æˆªå±2024-04-27 16.08.36.png" src="algorithmen-und-datenstrukturen/attachment/æˆªå±2024-04-27-16.08.36.png" target="_self"><br><img alt="æˆªå±2024-04-27 16.09.14.png" src="algorithmen-und-datenstrukturen/attachment/æˆªå±2024-04-27-16.09.14.png" target="_self"><br><br>
<br> enthÃ¤lt nur MethodenkÃ¶pfe
<br> wird ein Interface von einer Klasse implementiert, muss diese auch die Methoden des Interfaces implementieren
<br> â€Vererbung" von mehreren â€Klassen"
<br><img alt="æˆªå±2024-04-27 16.10.42.png" src="algorithmen-und-datenstrukturen/attachment/æˆªå±2024-04-27-16.10.42.png" target="_self"><img alt="æˆªå±2024-04-27 16.10.54.png" src="algorithmen-und-datenstrukturen/attachment/æˆªå±2024-04-27-16.10.54.png" target="_self"><br><br>
<br> im Gegensatz zu Interfaces Vererbung (von Attributen und<br>
Methoden) mÃ¶glich
<br> zu implementierende Funktionen werden mit dem Stichwort abstract gekennzeichnet und sind (wie bei Interfaces) nur FunktionskÃ¶pfe
<br> wenn eine Klasse von einer abstrakten Klasse erbt, muss diese auch die abstrakten Funktionen der Superklasse implementieren
<br><img alt="æˆªå±2024-04-27 16.13.16.png" src="algorithmen-und-datenstrukturen/attachment/æˆªå±2024-04-27-16.13.16.png" target="_self"><img alt="æˆªå±2024-04-27 16.13.41.png" src="algorithmen-und-datenstrukturen/attachment/æˆªå±2024-04-27-16.13.41.png" target="_self"><br><br>â€¢ wenn noch unbekannt, welchen Datentyp ein Objekt hat<br>Beispiel:<br>Ihr schreibt einen Algorithmus, der zwei Arrays miteinander vergleicht.<br>Der Algorithmus funktioniert dabei immer gleich, egal welcher Datentyp in den Arrays gespeichert ist. Ihr wollt allerdings nicht fÃ¼r jeden Datentypen eine eigene Klasse schreiben.<br>
<img alt="æˆªå±2024-04-27 16.15.25.png" src="algorithmen-und-datenstrukturen/attachment/æˆªå±2024-04-27-16.15.25.png" target="_self"><br>
<img alt="æˆªå±2024-04-27 16.15.54.png" src="algorithmen-und-datenstrukturen/attachment/æˆªå±2024-04-27-16.15.54.png" target="_self"><br>
<img alt="æˆªå±2024-04-27 18.03.53.png" src="algorithmen-und-datenstrukturen/attachment/æˆªå±2024-04-27-18.03.53.png" target="_self"><br><br><img alt="æˆªå±2024-04-27 16.29.26.png" src="algorithmen-und-datenstrukturen/attachment/æˆªå±2024-04-27-16.29.26.png" target="_self"><img alt="æˆªå±2024-04-27 16.32.15.png" src="algorithmen-und-datenstrukturen/attachment/æˆªå±2024-04-27-16.32.15.png" target="_self">]]></description><link>algorithmen-und-datenstrukturen/tut01.html</link><guid isPermaLink="false">Algorithmen und Datenstrukturen/TUT01.md</guid><pubDate>Sat, 27 Apr 2024 16:03:58 GMT</pubDate><enclosure url="algorithmen-und-datenstrukturen/attachment/æˆªå±2024-04-27-16.08.36.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="algorithmen-und-datenstrukturen/attachment/æˆªå±2024-04-27-16.08.36.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Signale und System]]></title><link>signale-und-system/signale-und-system.html</link><guid isPermaLink="false">Signale und System/Signale und System.md</guid><pubDate>Tue, 23 Apr 2024 16:46:02 GMT</pubDate></item><item><title><![CDATA[Makro]]></title><link>makro/makro.html</link><guid isPermaLink="false">Makro/Makro.md</guid><pubDate>Tue, 23 Apr 2024 16:45:38 GMT</pubDate></item><item><title><![CDATA[Cognitive Algorithms]]></title><description><![CDATA[<br>here is lecture:<br><a data-href="lecture1_handout.pdf" href="cognitive-algorithms/lecture1_handout.pdf" class="internal-link" target="_self" rel="noopener">lecture1_handout.pdf</a><br>
<a data-href="lecture2.pdf.pdf" href="cognitive-algorithms/lecture2.pdf.pdf" class="internal-link" target="_self" rel="noopener">lecture2.pdf.pdf</a><br>
<a data-href="lecture_3LR.pdf" href="cognitive-algorithms/lecture_3lr.pdf" class="internal-link" target="_self" rel="noopener">lecture_3LR.pdf</a><br>
<a data-href="lecture4_Kernels-1.pdf" href="cognitive-algorithms/lecture4_kernels-1.pdf" class="internal-link" target="_self" rel="noopener">lecture4_Kernels-1.pdf</a><br>
<a data-href="lecture5_unsupervised.pdf" href="cognitive-algorithms/lecture5_unsupervised.pdf" class="internal-link" target="_self" rel="noopener">lecture5_unsupervised.pdf</a><br>
<a data-href="Lecture5-handout.pdf" href="cognitive-algorithms/lecture5-handout.pdf" class="internal-link" target="_self" rel="noopener">Lecture5-handout.pdf</a><br>
<a data-href="MLP6_lecture_new.pdf" href="cognitive-algorithms/mlp6_lecture_new.pdf" class="internal-link" target="_self" rel="noopener">MLP6_lecture_new.pdf</a>]]></description><link>cognitive-algorithms/cognitive-algorithms.html</link><guid isPermaLink="false">Cognitive Algorithms/Cognitive Algorithms.md</guid><pubDate>Tue, 23 Apr 2024 16:44:56 GMT</pubDate></item><item><title><![CDATA[Bilanzierung und Kostenrechnung]]></title><link>bilanzierung-und-kostenrechung/bilanzierung-und-kostenrechnung.html</link><guid isPermaLink="false">Bilanzierung und Kostenrechung/Bilanzierung und Kostenrechnung.md</guid><pubDate>Tue, 23 Apr 2024 16:41:37 GMT</pubDate></item><item><title><![CDATA[Analysis II]]></title><description><![CDATA[<br><a data-href="notiz-1.pdf" href="analysis-ii/notiz-1.pdf" class="internal-link" target="_self" rel="noopener">notiz-1.pdf</a><br>
<a data-href="notiz-2.pdf" href="analysis-ii/notiz-2.pdf" class="internal-link" target="_self" rel="noopener">notiz-2.pdf</a><br>
<a data-href="notiz-3.pdf" href="analysis-ii/notiz-3.pdf" class="internal-link" target="_self" rel="noopener">notiz-3.pdf</a>]]></description><link>analysis-ii/analysis-ii.html</link><guid isPermaLink="false">Analysis II/Analysis II.md</guid><pubDate>Tue, 23 Apr 2024 16:41:20 GMT</pubDate></item><item><title><![CDATA[Mikro_06]]></title><description><![CDATA[<br><br><br><img src="mikro/20230203203903.png" target="_self"> <br><img src="mikro/20230203203935.png" target="_self"><br>
<img src="mikro/20230203203958.png" target="_self"><br>
<img src="mikro/20230203204025.png" target="_self"><br>
<img src="mikro/20230203204056.png" target="_self"> <br><br>####Neues Haushaltsoptimum nach Preiserhoehung von Gut 1:<br>
<img src="mikro/20230204003627.png" target="_self"> <br>
<br>A:HHO vor Preisaenderung: <br>Ursachen:<br>
<br>Substitutionsverhaeltnis
<br>Realeinkommen
<br><br><img src="mikro/20230204005508.png" target="_self"> <br>
<br>A:HHO vor Preisaenderung:
<br>C:HHO nach Preisaenderung:
<br>B:HHO nach Preisaenderung bei Kaufkrafterhaltung(durch Einnkommenskompensation):
<br> <br><br>
Substitutionseffekt ist immer der Preisaenderung entgegengesetzt! <br><br><img src="mikro/20230204011052.png" target="_self"><br>
<br>
<br>normales Gut: <br>inferiores Gut: <br><br><br>
<br>gewoehnliches Gut: <br>Giffen-Gut: <br><br><img src="mikro/20230205103044.png" target="_self"><br>
<img src="mikro/20230205103153.png" target="_self"><br>
<img src="mikro/20230205103256.png" target="_self"> ]]></description><link>mikro/mikro_06.html</link><guid isPermaLink="false">Mikro/Mikro_06.md</guid><pubDate>Tue, 23 Apr 2024 08:32:19 GMT</pubDate><enclosure url="mikro/20230203203903.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="mikro/20230203203903.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Mikro_12]]></title><description><![CDATA[<br><br><br>Bestimmung des Konkurrenzgleichgewichtes fÃ¼r 2 GÃ¼t, 2 Konsumenten, allg. Cobb-Douglas PrÃ¤ferenzen<br>
<img src="mikro/20230206154832.png" target="_self"><br>
<img src="mikro/20230206154915.png" target="_self"><br>
<img src="mikro/20230206174217.png" target="_self"><br>
<img src="mikro/img_045039d5abaf-1.jpeg" target="_self"><br><br>
<br>
<br>Nettonachfrage = Bruttonachfrage - Erstausstattung
<br>wenn Nettonachfrage &gt; 0, Nachfrager
<br>wenn Nettonachfrage &lt; 0, Anbieter
<br><img src="mikro/20230206175857.png" target="_self"> <br><br><img src="mikro/20230206180014.png" target="_self"> <br><br><img src="mikro/img_5122b71db030-1.jpeg" target="_self"><br><br><img src="mikro/20230206180928.png" target="_self"> ]]></description><link>mikro/mikro_12.html</link><guid isPermaLink="false">Mikro/Mikro_12.md</guid><pubDate>Tue, 23 Apr 2024 08:32:03 GMT</pubDate><enclosure url="mikro/20230206154832.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="mikro/20230206154832.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Mikro]]></title><description><![CDATA[<br><a data-href="Mikro_06_" href="mikro/mikro_06_.html" class="internal-link" target="_self" rel="noopener">Mikro_06_</a><br>
<a data-href="Mikro_06" href="mikro/mikro_06.html" class="internal-link" target="_self" rel="noopener">Mikro_06</a><br>
<a data-href="Mikro_07" href="mikro/mikro_07.html" class="internal-link" target="_self" rel="noopener">Mikro_07</a><br>
<a data-href="Mikro_12" href="mikro/mikro_12.html" class="internal-link" target="_self" rel="noopener">Mikro_12</a><br>
<a data-href="Mikro_12" href="mikro/mikro_12.html" class="internal-link" target="_self" rel="noopener">Mikro_12</a><br>
<a data-href="Mikro_vl13" href="mikro/mikro_vl13.html" class="internal-link" target="_self" rel="noopener">Mikro_vl13</a>]]]></description><link>mikro/mikro.html</link><guid isPermaLink="false">Mikro/Mikro.md</guid><pubDate>Sun, 21 Apr 2024 21:01:24 GMT</pubDate></item><item><title><![CDATA[Mikro_vl13]]></title><description><![CDATA[<br><br>LÃ¶sungsweg<br>
Nicht Vergessen!!<br><br>
<br>
GÃ¼ter: Konsum C und Arbeit L (bzw. Freizeit R) mit Preisen p bzw. w <br>
Unternehmen: <br>Outputgut: Konsumgut (C) <br>Inputgut: Arbeit (L) (bzw. Freizeit, ) <br> ist das maximal mÃ¶gliche Arbeitsangebot (bzw. maximale mÃ¶gliche Freizeit), z.B. 24 Stunden pro Tag <br>Produktionsfunktion: <br>
Zwei Konsumenten: A, B <br>Nutzenfunktion: ,
<br>Anfangsausstattungen: <br>Unternehmensanteile: <br>Konsument A:
<br>Konsument B: <br>
Konsumenten: <br>Nutzenfunktion: <br>Anfangsausstattungen: <br>Unternehmensanteile: <br>Konsument : <br><br><img src="mikro/20230209113338.png" target="_self"><br>
äºcè½´ç›¸äº¤ç‚¹ä¸º<br><br><img src="mikro/20230209113432.png" target="_self"> <br><br><img src="mikro/20230209113522.png" target="_self"> <br><br><img src="mikro/20230209113600.png" target="_self"> <br><br><img src="mikro/20230209113637.png" target="_self"> <br>
<br>Erstes Theorem der WohlfahrtsÃ¶konomie: Das Konkurrenzgleichgewicht ist Pareto-effizient
<br>Zweites Theorem der WohlfahrtsÃ¶konomie: Wenn alle PrÃ¤ferenzen konvex sind, dann ist jede Pareto-effiziente Allokation ein Gleichgewicht fÃ¼r eine entsprechende Ausstattung
<br><br>sieht Video 17: ProduktionsÃ¶komomie<br><br><img src="mikro/20230209114132.png" target="_self"> <br>
<br>Ein allgemeines Gleichgewicht liegt vor, wenn die Preise genau so sind, dass die MÃ¤rkte fÃ¼r alle GÃ¼ter gerÃ¤umt sind, d.h. die Summe der Nettonachfragen aller Konsumenten nach jedem Gut ist gleich der Summe des Nettoangebots an diesem Gut
<br><br><img src="mikro/20230209114324.png" target="_self"> <br><br><br><img src="mikro/20230211144930.png" target="_self"><br>
<img src="mikro/20230211144953.png" target="_self"><br>
<img src="mikro/20230211145010.png" target="_self"> <br><br> fÃ¼r alle GÃ¼ter<br><br><img src="mikro/20230211145420.png" target="_self"> <br>
<br>
<br> <br><img src="mikro/20230211150241.png" target="_self"> <br><br><img src="mikro/20230211150308.png" target="_self"> <br><br><br><img src="mikro/20230211150650.png" target="_self"><br>
<img src="mikro/20230211150738.png" target="_self"><br>
<img src="mikro/20230211150808.png" target="_self"><br>
<img src="mikro/20230211150831.png" target="_self"><br>
<img src="mikro/20230211150850.png" target="_self"> <br><br><img src="mikro/20230211150915.png" target="_self"> <br><br><img src="mikro/20230211151012.png" target="_self"> ]]></description><link>mikro/mikro_vl13.html</link><guid isPermaLink="false">Mikro/Mikro_vl13.md</guid><pubDate>Sun, 21 Apr 2024 20:29:41 GMT</pubDate><enclosure url="mikro/20230209113338.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="mikro/20230209113338.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Mikro_07]]></title><description><![CDATA[<br><br><br><img src="mikro/20230205120910.png" target="_self"><br>
<img src="mikro/20230205121013.png" target="_self"><br>
<img src="mikro/20230205121041.png" target="_self"><br>
<img src="mikro/20230205121105.png" target="_self"> ]]></description><link>mikro/mikro_07.html</link><guid isPermaLink="false">Mikro/Mikro_07.md</guid><pubDate>Sun, 21 Apr 2024 20:29:41 GMT</pubDate><enclosure url="mikro/20230205120910.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="mikro/20230205120910.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[MikroÃ¶konomik VL06]]></title><description><![CDATA[<br><br><br><img src="mikro/20230203203903.png" target="_self"><br>
<img src="mikro/20230203203935.png" target="_self"><br>
<img src="mikro/20230203203958.png" target="_self"><br>
<img src="mikro/20230203204025.png" target="_self"><br>
<img src="mikro/20230203204056.png" target="_self"><br>
]]></description><link>mikro/mikro_06_.html</link><guid isPermaLink="false">Mikro/Mikro_06_.md</guid><pubDate>Sun, 21 Apr 2024 20:29:41 GMT</pubDate><enclosure url="mikro/20230203203903.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="mikro/20230203203903.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Readme]]></title><description><![CDATA[<br>Hier findest du die Folien, die ich in meinen Tutorien verwende. Sie behandeln den Stoff unvollstÃ¤ndig und sind nur eine ErgÃ¤nzung zum Tutorium. FÃ¼rs lernen empfehle ich euch die Zusatzvideos sehr :)]]></description><link>rechnerorganisation/tut/readme.html</link><guid isPermaLink="false">Rechnerorganisation/tut/Readme.md</guid><pubDate>Sun, 21 Apr 2024 20:27:54 GMT</pubDate></item><item><title><![CDATA[Rorg_tut12]]></title><description><![CDATA[<br><br><br><br><img src="rechnerorganisation/img_b88a7876cfcd-1.jpeg" target="_self"><br>
<img src="rechnerorganisation/20230209205748.png" target="_self"><br>
<img src="rechnerorganisation/img_46ed4549b8b6-1.jpeg" target="_self"><br>
<img src="rechnerorganisation/20230209211444.png" target="_self"><br>
ps æœ¬å›¾ä¸»è¦çœ‹ppt<br><br><img src="rechnerorganisation/20230209211620.png" target="_self"> <br><br><img src="rechnerorganisation/20230209212059.png" target="_self"><br>
å…ˆè¿›å…ˆå‡ºçš„ç®—æ³•ï¼ˆFIFOï¼‰ï¼šé€‰æ‹©åœ¨å†…å­˜ä¸­é©»ç•™æ—¶é—´æœ€ä¹…çš„é¡µé¢äºˆä»¥æ›¿æ¢ã€‚<br><br><img src="rechnerorganisation/20230209212748.png" target="_self"><br>
æœ€è¿‘æœ€ä¹…æœªä½¿ç”¨ç®—æ³•ï¼ˆLRUï¼‰ï¼šé€‰æ‹©è¿‡å»æœ€é•¿æ—¶é—´æœªè¢«è®¿é—®çš„é¡µé¢äºˆä»¥æ›¿æ¢ã€‚<br><br><img src="rechnerorganisation/20230209213148.png" target="_self"> <br>æœ€ä½³æ·˜æ±°ç®—æ³•ï¼ˆOPTï¼‰ï¼šé€‰æ‹©æ°¸ä¸ä½¿ç”¨æˆ–åœ¨æœªæ¥æœ€é•¿æ—¶é—´å†…ä¸å†è¢«è®¿é—®çš„é¡µé¢äºˆä»¥æ›¿æ¢ã€‚<br>
åœ¨tag=4æ—¶å‡ºç°missçš„æƒ…å†µ:<br>
<br>way 0: 3åœ¨æœªæ¥å‡ºç°äº†2æ¬¡
<br>way 1: 0åœ¨æœªæ¥å‡ºç°äº†3æ¬¡
<br>way 2: 1åœ¨æœªæ¥å‡ºç°äº†2æ¬¡
<br>way 3: 2åœ¨æœªæ¥å‡ºç°äº†2æ¬¡
<br>æ›¿æ¢way2çš„ç†ç”±ï¼šå› ä¸ºway 0ï¼Œ2ï¼Œ3çš„å€¼åœ¨æœªæ¥å‡ºç°çš„æ¬¡æ•°ç›¸ç­‰ï¼Œæ ¹æ®fifo,way 2æœ€ä¹…æ²¡æœ‰è¢«è®¿é—®<br><br>TU CLOUD: bit.lz/ROrgTUT<br><img src="rechnerorganisation/20230210102121.png" target="_self"> <br><br>
<br>Problem1 <br>wie findet die Seite("Cache-Block")ins Archiv zurueck?
<br>"Tag": merkt sich Herkunftsort("Blockadress")einer Seite <br>Problem 2 <br>Wo legen wir die Seite in die Ablage("Cache"<br>
)?
<br>z.B beliebige Stelle, wo nach Platz ist("vollassoziativ") <br>Problem 3 <br>Sortierung der Seiten in Ablage?(um Seiten schneller zu finden)
<br>"Cache-Sets": Faecher fuer Seiten mit gleichen "Anfangsbuchstaben" <br>Problem 4 <br>was machen, wenn die Ablage voll ist?
<br>"Ersetzungsstragie": alte Seite ausstauchen und zurueckbringen <br><br><img src="rechnerorganisation/20230210105051.png" target="_self"> <br><br>cache-Typen:<br>
<br>vollassoziati("fully associative"): <br>1.Satz ("Stapel"),wo alle Cache-Block <br>direkt abgebildet("Direct Mapped"): <br>assoziativitaet = 1. jeder Satz enthaelt maximal einen Cache-Block <br>n-fach satz assoziativ: <br>Assoziativtaet = n <br><br>
<br>direkt abgebildet -&gt; Assoziativitaet = 1
<br>Kapazitaet = 8 KiB = 8 * 1024 Bytes = 2^13 Bytes (und nicht 8000 Byte!!)
<br>Cacheblock-Groesse = 2^5 Bytes
<br>32, 8192, 48, 8208, 32, 8224, 48, 8240, 32, 8256<br>
Simulation: â€¢ Index, â€¢ Tag <br>Wie viele Bits hat der Blockoffset? (die Adresse innerhalb des Blocks)<br>
<br>:
<br>Wie viele Bits hat der Index?<br>
<br>Zuerst: wie viele SÃ¤tze gibt es im Cache?
<br>SatzgrÃ¶ÃŸe = (Cacheblock-GrÃ¶ÃŸe â€¢ AssoziativitÃ¤t) = 2^5 Bytes
<br>
<br>
<br>wie viele Bits hat der Tag?<br>
<br>Das wissen wir nicht, mÃ¼ssen wir nicht wissen (sagen wir, es sind genug Bits;-).)
<br>Lustig: wir haben keine vorgegebene GrÃ¶ÃŸe fÃ¼r die Adresse des Prozessor.)
<br>Blockadresse = (Adresse / CacheblockgrÃ¶ÃŸe)<br>
Blockadresse = (Adresse &gt;&gt;(blockoffset Bits))<br>Index = Blockadresse % (2^(Index Bits))<br>
Index = â€¢ Blockadresse &amp; (grÃ¶ÃŸten Index) <br>grÃ¶ÃŸter Index = 2^(index bits) - 1 = 2^8 - 1 = FF16<br>
Tag = Blockadresse / 2^(Index Bits)<br>
Tag = Blockadresse &gt;&gt; (Index â€¢ Bits)<br>
<img src="rechnerorganisation/20230210160153.png" target="_self"> <br><br>
<br>2-fachâ€¢satz-assoziativ - AssoziativitÃ¤t=2
<br>KapazitÃ¤t = 8KiB = 8 â€¢ 1024 Bytes = 2^13 Bytes
<br>CacheblockgrÃ¶ÃŸe = 8 WÃ¶rter = 8â€¢4 Bytes = 2^5 Bytes
<br>ByteaddressengrÃ¶ÃŸe = 40 Bits
<br>Prozessor schickt Byteadresse (1 Byte = 2 Nybble = Hexadezimalziffer):<br>
a)<br>
Wie grÃ¶ÃŸ ist der Index?
<br>SatzgrÃ¶ÃŸe = BlockgrÃ¶ÃŸe * AssoziativitÃ¤t = 2^5 â€¢ 2^1 Bytes = 2^6 Bytes <br>Anzahn an SÃ¤tze = KapazitÃ¤t / SatzgrÃ¶ÃŸe = 2^13 / 2^6 â€¢ Bytes = 2^7 Bytes:
<br>IndexgrÃ¶ÃŸe = log2 ( Anzahl an SÃ¤tze ) = 7 Bit<br>
Wie groÃŸ ist der Tag?
<br>BlockoffsetgrÃ¶ÃŸe = log2 ( BlockgrÃ¶ÃŸe)Bits = log2 (2^5)Bits = 5 Bits
<br>AdressgrÃ¶ÃŸe - IndexgrÃ¶ÃŸe - BlockoffsetgrÃ¶ÃŸe = 40 - 7 - 5 = 28 Bits<br>
b)<br>
Adresse = [tag = 28 Bits, index = 7 Bits, blockoffset = 5 Bits ]<br>
Adresse = 55236<br>
Blockadresse = (Adresse / BlockgrÃ¶ÃŸe)<br>
Index = Blockadresse % 2^7 = 62
<br><br>AMAT = Average Memory Access Time (durchschnittliche Zugriffszeit)<br>
Es gibt jetzt verschiedene FÃ¤lle (verschiedene FÃ¤lle).<br>
<br>Fall: wir-finden denâ€¢ Cache-Block im sog. L1-Cache
<br>Fall: wenn nicht im LI-Cache, finden wir den Cache-Block im L2-Cache
<br>Fall: wenn nicht im L2-Cache, finden wir den-Cache-Block im RAM (Random Access Memory)<br>
FÃ¼r jeden Fall die HÃ¤ufigkeit (Wahrscheinlichkeit) berechnen.<br>
FÃ¼r jeden Fall die Zeitdauer berechnen.
<br>-&gt; AMAT = gewichtete Mittelwert<br>
-&gt; Miss-Rate = HÃ¤ufigkeit eines Cache-Misses (in Prozent)<br>
<br>lokal: fÃ¼r jeden Cache-Zugriff, wie hÃ¤ufig gibt es einen Cache-Miss? (Dieser ist gegeben!! wenn nichts weiter gesagt ist.).
<br>global: wie viele Speicherzugriffe vom Prozessor landen im Cache und erzeugen einen Cache-Miss?
<br>1.Fall (L1-Cache):<br>
<br>
Zeit = 3 Takte <br>
globale HÃ¤ufigkeit = 100% - 7% = 93% <br>
100% der FÃ¤lle erreichen L1-Cache, davon 93% der FÃ¤lle ein Cache-Hit
1.Fall (L2-Cache): <br>
Zeit = L1-Cache-Zeit + 15 Takte = 18 Takte <br>
globale HÃ¤ufigkeit = 7% (100% - 34%) = 7% 66% = 4.62% <br>
7% der FÃ¤lle erreichen den L2-Cache, davon 66% der FÃ¤lle ein Cache-Hit
2.Fall (RAM): <br>
Zeit = L2-Cache-Zeit + 100 Takte = 118 Takte <br>
globale HÃ¤ufigkeit = 7% * 34% = 100% - 93% - 4.62% = 2.38% <br>
7% der FÃ¤lle erreichen L2-Cache und dort in 34% der FÃ¤lle gehen wir zum RAM weiter <br>AMAT = 93% 3 Takte + 4.62% 18 Takte + 2.38% * 118 Takte AMAT = 6.43 Takte]]></description><link>rechnerorganisation/rorg_tut12.html</link><guid isPermaLink="false">Rechnerorganisation/Rorg_tut12.md</guid><pubDate>Sun, 21 Apr 2024 20:24:33 GMT</pubDate><enclosure url="rechnerorganisation/img_b88a7876cfcd-1.jpeg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src="rechnerorganisation/img_b88a7876cfcd-1.jpeg"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Rechnerorganisasion TUT 11]]></title><description><![CDATA[<br><br><br><br>was ist ein nop-Befehl<br>
<br>No Operation
<br>Befehl der nichts ausfÃ¼hrt(keinen Zustand verÃ¤ndert)
<br>gewÃ¶hnlich Befehl dessen 32 Bit auf 0 gesetzt sind
<br>in MIPS: sll $zero, $zero, 0<br>
AuflÃ¶sung von Datenkonflikten in Pipelined-Prozessoren:
<br>nop-Befehle <br>simpleres Design(weniger Baauteile/kostengÃ¼nstig)
<br>Compiler/Programmierer muss manuell nop's einfÃ¼gen <br>alternativ: Hardware-Forwarding
<br><br>
<br>
ursprÃ¼ngliches Proplem bei Eintaktprozessor: Abschnitten im Eintaktprozessor werden nicht vollstÃ¤ndig ausgenutzt. <br>
Idee: wir fangen an, Befehle auszufÃ¼hren, bevor der vorherige Befehl fertig ist. <br>damit die Datenpfad-Abschnitte mehr genutzt werden (mehr Arbeit ausfÃ¼hren)
<br>sobald der Befehl zu den Registern geht, wird schon ein neuer Befehl aus dem Speicher geladen <br>
wir haben 5 Abschnitte: Instruction Fetch, Instruction Decode, Execute, Memory (Read/Write), Write Back <br>sobald ein Befehl in Instruction Decode ist, wird der nÃ¤chste Befehl angefangen <br><br>
<br>manche Bestandteile aus dem Eintaktprozessor wurden "bewegt" an andere Stelle
<br>es gibt solche "Balken" (zusÃ¤tzlichen Rechtecke) = Pipeline-Register
<br><br>
<br>
diese trennen die verschiedenen Stufen <br>
aber warum brauchen wir diese Register wirklich? <br>weil wir jede Stufe in der gleichen Zeit ausfÃ¼hren wollen
<br>wir wissen aus letzter Woche: die Stufen sind unterschiedlich schnell<br>
(z.B. Instruction Fetch = Speicherzugriff 150ps, Register-Lesen = 50 ps, ALU = 100ps)
<br>wir wollen nicht, dass eine frÃ¼here Stufe die nÃ¤chste vorzeitig unterbricht =&gt; die Pipeline-Register halten die Eingangsdaten (fÃ¼r eine Stufe) und warten, bis der nÃ¤chste Takt anfÃ¤ngt (Synchronisation) <br><br>
<br>
Datenkonflikte (Data Hazard) <br>
Register-Werte fehlen, wenn diese gebraucht werden <br>
wenn ein Befehl das Ergebnis von dem vorherigen Befehl braucht, dann ist der vorherige Befehl noch nicht fertig!!<br>
Die Daten des vorherigen Befehls sind nicht da<br>
Die gelesen Register vom nÃ¤chsten Befehl (weiter links in der Pipeline) sind noch nicht upgedatet, also falsch <br>
wir kÃ¶nnen das richtige Ergebnis erst aus dem Register laden, wÃ¤hrend das Ergebnis geschrieben wird<br>
warum? <br>Idee: wir kÃ¶nnen den Takt in zwei HÃ¤lften unterteilen
<br>erste HÃ¤lfte: schreibe das Ergebnis in Register in Write Back
<br>zweite HÃ¤lfte: Register werden gelesen in Instruction Decode <br>
wie kann machen, damit Data Hazards weniger Zeit verschwenden? <br>Forwarding Unit + Hazard Detection (Ergebnis wird weitergereicht, sobald das Ergebnis berechnet wurde, also schon vor Write-Back) <br>
Steuerkonflikte (Control Hazard) <br>
die Sprungentscheidung, Sprungadresse fehlt, wenn wir diese bereits brauchen <br>
der Kontrollfluss (also die BefehlsausfÃ¼hrung) ist verzÃ¶gert (ist noch nicht entschieden) <br>
wir kÃ¶nnen Befehle ausfÃ¼hren, die eigentlich nicht ausgefÃ¼hrt werden sollen <br>
wie schneller machen? <br>"Branch Prediction" (siehe unten) <br>wenn wir hÃ¤ufig richtig raten, sind wir schneller <br>Sprungentscheidung viel frÃ¼her berechnen (z.B. in Instruction-Decode, dafÃ¼r Extra-Hardware nÃ¶tig) <br>
Strukturelle Konflikte (Structural Hazard) (nennen wir nur wegen der VollstÃ¤ndigkeit) <br>wenn zwei Befehle dieselbe Pipeline-Stufe gleichzeitig nutzen wollen
<br>z.B. wenn es zwei Pipelines gibt (2K-Zahlen und Floating-Point-Zahlen) und diese zusammenlaufen (zusammengefÃ¼hrt werden) <br>Advanced Computer Architectures <br>kommen bei uns nicht vor <br>
wie verhindern (entschÃ¤rfen) wir die Hazards? <br>"Stall Cycles" (Takte wo angehalten wird), "der Prozessor hÃ¤lt die vordere Pipeline an (Instruction Fetch und Instruction Decode)
<br>wir ignorieren das Problem, Compiler soll das Problem lÃ¶sen <br>Compiler fÃ¼gt "Wartebefehle" ein, "NOP"s = No operation
<br>Delay Slot (= Takte die gewartet werden mÃ¼ssen, bis das richtige Ergebnis da ist) = Latenz ("Bearbeitungszeit") <br>wir kÃ¶nnen auch andere Befehle statt NOPs nutzen, die fehlende Ergebnis nicht brauchen <br>"Flushing" ("herunterspÃ¼len") <br>die Pipeline bis zu Instruction Decode wird geleert (d.h. das wir die Befehle spÃ¤ter nochmal laden) <br>fÃ¼r Control Hazards: wir kÃ¶nnen raten (Spekulation, "Branch Prediction"), welche Sprungentscheidung genommen wird <br>wenn wir falsch raten, dann werden wir bestraft, indem wir alle falsch ausgefÃ¼hrten Befehle rÃ¼ckgÃ¤ngig machen mÃ¼ssen ("Flushing" + andere Sachen)
<br>wenn wir richtig raten, dann sind wir richtig schnell ğŸ˜€ <br><br>a)<br>
<br>ohne Optimierung: <br>wenn ein Register-Ergebnis berechnet wird, dann ist das Ergebnis die nÃ¤chsten zwei Takte nicht verfÃ¼gbar
<br>siehe Bild <br>0 addi *$t0* ,$a0 ,4
1 addi *$t1* ,$a1 ,4
2 sub $t2 ,*$t0* ,*$t1*
3 sll *$t3* ,$a2 ,2
4 add *$t4* ,$t0 ,*$t3*
5 add $t5 ,$t1 ,*$t3*
6 sw $t2 ,0( *$t4* )
å¤åˆ¶<br>b)<br>
<br>keine Reihenfolge Ã¤ndern, nur Wartebefehle (NOPs) einfÃ¼gen
<br>0 addi $t0 ,$a0 ,4 1 addi $t1 ,$a1 ,4 1.2 nop
1.3 nop 2 sub $t2 , $t0 , $t1 3 sll $t3 ,$a2 ,2 3.1 nop
3.2 nop 4 add $t4 ,$t0 , $t3 5 add $t5 ,$t1 , $t3 5.1 nop 6 sw $t2 ,0( $t4 )
å¤åˆ¶<br>c)<br>
<br>noch besser machen: jetzt so wenig wie mÃ¶glich NOPs brauchen, Befehle umordnen
<br>wie vorgehen ? wir gucken, welche Befehle brauchen das Ergebnis von welchen anderen Befehlen? =&gt; grafisch aufzeichnen <br>List Scheduling (siehe Internet? â†’ Compiler Design Kurs. Statt "AuftrÃ¤ge" "Maschinen" zuzuweisen, weisen wir der Pipeline neue Befehle zu) <br><br>a)<br>
<br>
Speicherzugriff = 200ps, ALU-Operation = 100ps, Registerzugriff = 50ps <br>
Benchmark (Programm, um die AusfÃ¼hrungszeit zu messen) <br>
Annahmen: gleiche Anzahl an Befehle fÃ¼r beide Prozessoren <br>
Jeder Prozessor hat eine (eigene) konstante Taktzeit, T_SC = Taktdauer des Eintaktprozessor (Single Cycle), T_PP = Taktdauer fÃ¼r Pipeline-Prozessor <br>
es gibt keine Data Hazards mehr (wurden entfernt durch Umordnung) <br>
es gibt aber alle Control-Hazards noch! -&gt; jeder Sprungbefehl dauert 4 Takte! Der Prozessor hÃ¤lt bei Sprungbefehlen einfach an! <br>
Speicherbefehle -&gt; 12% (1 Takt pro Speicherbefehl weil keine Datenkonflikte Data Hazards) <br>
ALU-Befehle -&gt; 72% (1 Takt pro Speicherbefehl weil keine Datenkonflikte) <br>
Sprung-Befehle -&gt; 16% (4 Takte pro Sprungbefehl, wegen den Steuerkonflikten Control Hazards) <br>
wozu die Informationen? Damit wir die Schnelligkeit des Pipeline-Prozessors berechnen kÃ¶nnen. Eintaktprozessor fÃ¼hrt jeden Befehl gleichschnell aus <br>
unbekannte Anzahl N an Befehlen <br>
Pipeline ist zu Beginn der Benchmark gefÃ¼llt <br>
Speedup berechnen, S = Vergleichszeit t_SC / (betrachtete Zeit) t_PP -&gt; wie viel Faktor schneller ist der betrachtete Prozessor <br>
t_SC = AusfÃ¼hrungszeit Eintaktprozessor = (Anzahl an Takte) Â· (Taktdauer) = (N Â· CPI_SC) Â· T_SC <br>
t_PP = AusfÃ¼hrungszeit Pipelineprozessor = (Anzahl an Takte) Â· (Taktdauer) = (N Â· CPI_PP) Â· T_PP <br>
CPI = Befehlsdauer in Takten = wie lange braucht ein Befehl an Takten zur AusfÃ¼hrung <br>CPI_SC = 1 da jeder Befehl einen Takt braucht
<br>CPI_PP = jeder Befehl braucht unterschiedlich viele Takte (hÃ¤ngt ab von den Hazards) <br>gewichteter Mittelwert: 12% 1 + 72% 1 + 16% * 4 = 1.48 <br>
T = Taktdauer, wie viel Sekunden braucht ein Takt <br>T_SC = 600ps = 2Â·200ps + 100ps + 2Â·50ps (2-mal Speicherzugriff, 2-mal Registerzugriff, 1-mal ALU)
<br>T_PP = maximale Dauer einer Stufe = 200ps (wir brauchen eine Taktdauer in der jede Stufe ausgefÃ¼hrt wird) <br>
S = (N Â· CPI_SC) Â· T_SC / ((N Â· CPI_PP) Â· T_PP) = 600ps / (1.48 * 200ps) = 2,027027027â€¦ = 2 + 27/999 <br>b) wie kÃ¶nnen wir den Pipeline-Prozessor schneller machen? siehe Aufgabe 1<br>c) Was ist, wenn wir nur die ALU schneller machen, um 25% ?<br>ALU-Operation braucht nur 75ps<br>-&gt; T_SC = 2Â·200ps + 75ps + 2Â·50ps = 575ps<br>T_PP Ã¤ndert sich nicht!! Immernoch die gleichen Hazards, und Speicherbefehle dauern immernoch 200ps<br>=&gt; der Speedup wird schlechter, weil der Pipeline-Prozessor nicht profitiert<br>=&gt; Pipeline wird nur schneller, wenn man die am lÃ¤ngsten dauernde Stufe optimiert.<br><br><img src="rechnerorganisation/20230203105924.png" target="_self"><br>
<img src="rechnerorganisation/bildschirmÂ­foto-2023-02-03-um-10.51.40.png" target="_self"><br>
<img src="rechnerorganisation/bildschirmÂ­foto-2023-02-03-um-11.48.40.png" target="_self"><br>Aufgabe 3<br>a) Verbesserung ist, dass man die EX und MEM-Stufe zusammenlegen kann. Die Pipeline wird kÃ¼rzer. Load-Use-Konflikte sind einen Takt schneller (0 statt 1 Takte VerzÃ¶gerung).<br>b)<br>Verbesserungen gibt es, wenn Speicherfefehle keinen Offset brauchen<br>das ist der Fall bei Array-Zugriffen in Schleifen oder Integer-Pointer<br>alle anderen Zugriffe brauchen einen Offset<br>wenn man einen konstanten Offset braucht, wird man verlangsamt<br>der Offset muss in Extra-Befehl berechnet werden<br>der zusÃ¤tzliche Befehl wird nur durch kÃ¼rzere Load-Use-Hazards kompensiert<br>verbraucht ein Register (erhÃ¶ht den Registerdruck), sowie zusÃ¤tzlichen Platz im Befehlsspeicher (Cache-Verschmutzung)<br>in Praxis brauchen wahrscheinlich mehr Befehle einen konstanten Offset als keinen<br>alle struct-, Objekt-Zugriffe brauchen einen; hÃ¤ufiger Spezialfall: Stack-Frames<br>hÃ¤ufig in Praxis, vor allem Stack Frames, da es viel mehr innere Funktionsaufrufe mit Stack als Blatt-Funktionsaufrufe ohne Stack gibt.<br><img src="rechnerorganisation/20230203131555.png" target="_self"><br>
<img src="rechnerorganisation/20230203131618.png" target="_self"><br>
<img src="rechnerorganisation/20230203131640.png" target="_self"> ]]></description><link>rechnerorganisation/rorg_tut11.html</link><guid isPermaLink="false">Rechnerorganisation/Rorg_tut11.md</guid><pubDate>Sun, 21 Apr 2024 20:24:33 GMT</pubDate><enclosure url="rechnerorganisation/20230203105924.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="rechnerorganisation/20230203105924.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Rorg_tut09]]></title><description><![CDATA[<br><br><br><br><img src="rechnerorganisation/20230211202202.png" target="_self"><br>
<img src="rechnerorganisation/20230211202257.png" target="_self"> <br><br><img src="rechnerorganisation/20230211202413.png" target="_self"> <br><br><img src="rechnerorganisation/20230211202621.png" target="_self"><br>
å³ä¸‹å›¾:Wie viele Takte benÃ¶tigt eine Instruktion?(CPI)<br><br><img src="rechnerorganisation/20230211202841.png" target="_self"><br>
<img src="rechnerorganisation/20230211202918.png" target="_self"><br>
<img src="rechnerorganisation/20230211202943.png" target="_self"> <br><br>
<br>R-Typ-Befehl (ALUSrc = 0, RegDst = 1)
<br>I-Typ-Befehl (ALUSrc = 1 (meistens), RegDst = 0)
<br>J-Typ-Befehl (haben wir nicht im Datenpfad)
<br>Speicherbefehle (lw, sw) <br>MemToReg = 1, MemWrite, MemRead, RegWrite
<br>Branch = 0 <br>Rechenbefehle (add, sub, and, or, sll, â€¦) <br>MemToReg = 0, RegWrite = 1
<br>MemRead = 0!!, MemWrite = 0, Branch = 0 <br>Sprungbefehle <br>Branch = 1 (bzw. Jump = 1)
<br>RegWrite = 0, MemRead = 0!!, MemWrite = 0 <br><br>
<br>Schritt 1: Befehlsverhalten definieren
<br>Schritt 2: Funktion als Schaltnetz entwerfen <br>Eingabe: <br>â‰¤ 2 Register-Werte, â‰¤ 1 16-Bit-Konstanten, 32-Bit-Befehl <br>Ausgabe: <br>nÃ¤chste Befehlsadresse (PC)
<br>Ergebniswert(e) (optional)
<br>Zieladresse (Register und/oder RAM, optional) <br>Schritt 3: Schaltnetz auf bestehenden Datenpfad abbilden <br>alle nutzbaren Elemente im Datenpfad wiederverwenden <br>Schritt 4: Steuersignale/Muxe hinzufÃ¼gen (um Befehl zu aktivieren)
<br><br><br>a) was beeinflusst die VerÃ¤nderung des Registerinhalts in einem Befehl?<br>direkten Einfluss:<br>
<br>RegDst: R-Typ und I-Typ-Befehle -&gt; RT = Instruction[16 bis 20] und RD = Instruction[11 bis 15] (als Bitfelder im Befehl) <br>RegDst = 0 =&gt; RT ausgewÃ¤hlt (immer fÃ¼r I-Typ), RegDst = 1 =&gt; RD ausgewÃ¤hlt (immer fÃ¼r R-Typ)
<br>R-Typ [ Opcode, RS, RT, RD, shift amount, Func ] =&gt; RD = ...
<br>I-Typ [ Opcode, RS, RT, imm16 ] =&gt; RT = ... <br>RegWrite: Bestimmt, ob die Daten am Write-Data-Port in das Zielregister geschrieben werden sollen
<br>MemToReg: gibt an, von wo die Daten zum Schreiben kommen. MemToReg = 1 heiÃŸt, dass die Daten vom "Memory" kommen.
<br>indirekten Einflus:<br>
<br>MemRead: wenn = 1, kann es Daten fÃ¼r die Register aus dem Hauptspeicher lesen
<br>ALUOp: bestimmt, wie mÃ¶gliche Daten zum Schreiben berechnet werden
<br>ALUSrc: bestimmt, wie mÃ¶gliche Daten zum Schreiben berechnet werden (meistens: I-Typ =&gt; ALUSrc = 1, immer: R-Typ =&gt; ALUSrc = 0)
<br>keinen Einfluss:<br>
<br>Branch (beeinflusst nur PC)
<br>MemWrite: das Schreiben vom Hauptspeicher verÃ¤ndert die mÃ¶glichen geschriebenen Registerdaten nicht
<br>b) welche Steuersignale beeinflussen das Beschreiben des Hauptspeicher (RAM â€“ Random Access Memory)<br>
<br>MemWrite
<br>MemRead (es gibt eine Optimierung des Speicherzugriffs, die nennt sich Cache, und dort werden Lesezugriffe gemerkt. Dieser Cache verÃ¤ndert sich, wenn man liest, was zwar keine funktionale aber einen Performance-Unterschied macht. ZusÃ¤tzlich kann man beim Lesen auf bestimmte Speicheraddressen Register von Hardware auÃŸerhalb des Prozessors verÃ¤ndern, weil diese so funktioniert. Deshalb sollte fÃ¼hrt das Lesen zu einer ZustandsÃ¤nderung des Computers bzw. des Speichers.)
<br>Andere Steuersignale nicht, denn diese beschreiben nur VerÃ¤nderungen in den Prozessorregistern.<br><br>a) welche Steuersignale dÃ¼rfen niemals (bei keinem Befehl) einen nicht-definierten (beliebigen) Wert annehmen?<br>
<br>Branch: <br>weil Branch das Ãœberschreiben des Programm-Counters direkt beeinflusst und der nÃ¤chste Wert des PCs fÃ¼r jeden Befehl fest definiert ist <br>RegWrite, MemWrite: <br>es ist fÃ¼r jeden fest definiert, ob und welche Register wir schreiben und welche Speicheradresse <br>MemRead: <br>nur = 1, wenn wir wirklich lesen wollen
<br>weil: das Lesen von Hauptspeicher beeinflusst den Cache (eine Hardware-Optimierung), die sich Lesezugriffe merkt, um diese zu beschleunigen <br>b) welche Steuersignale sind egal, wenn RegWrite = 0?<br>
<br>in dem Fall: Write-Data und Write-Register-Ports (vom Register File) sind dann egal, sodass <br>RegDst beliebig sein kann
<br>MemToReg beliebig sein kann <br>NICHT EGAL! ist <br>ALUSrc
<br>ALUOp
<br>weil ist mÃ¶glich, dass wir einen Schreibbefehl ausfÃ¼hren (sw, sb) <br>in dem Fall nutzen wird die ALU, um die Speicheradresse zu berechnen <br>c) welche FunktionalitÃ¤t (oder welcher Befehl) passiert (wohl), wenn RegWrite = 1, MemRead = 1, MemToReg = 1 ist?<br>
<br>MemRead = 1 liest Daten aus dem Speicher,
<br>MemToReg = 1 leitet gelesene Daten aus Hauptspeicher zu Register-File (Registersatz) weiter
<br>anliegende Daten am Register-File werden mit RegWrite = 1 in ein Register geschrieben
<br>naheliegender Befehl: load word (lw)<br>
Berechnung der Speicheradresse nicht vorgegeben (kÃ¶nnte beliebig sein)<br><br>ADDI:<br>
<br>RegDst: wegen I-Typ wollen wir nach RT schreiben, das machen wir mit RegDst = 0
<br>Branch = 0, da wir nach dem Befehl den nachfolgenden Befehl ausfÃ¼hren
<br>MemRead = 0, da wir nur ein Registerwert berechnen wollen, keine SpeicherverÃ¤nderung
<br>MemToReg = 0, damit wir das ALU-Ergebnis an das Register weiterleiten kÃ¶nnen
<br>ALUOp = 00; die linke 0 sagt, dass es keinen Func-Code gibt und das rechte Bit bestimmt, ob Addition (= 0) oder Subtraktion (= 1) ist
<br>MemWrite = 0, weil wir den Hauptspeicher nicht verÃ¤ndern wollen
<br>ALUSrc = 1, da wir einen I-Typ-Befehl haben und mit der Immediate rechnen wollen
<br>RegWrite = 1, damit wir unser Additionsergebnis in das Register reinschreiben kÃ¶nnen
<br><br>a) BGTZ zum Datenpfad hinzufÃ¼gen.<br>Schritt 1: Verhalten definieren.<br>
BGTZ $rs, Label (Label = PC + 4 + imm4 )<br>
PC = PC + 4 + ( RS &gt; 0 ? immediate 4 : 0) // a ? b : c === if a then b else c<br>Schritt 2:<br>
<br>Eingabe: PC, RS, imm = (Label - 4)/4 =&gt; RT = $0 (weil nicht angegeben)
<br>Ausgabe: PC
<br> Schaltnetz:<br>
PC = PC + 4 + X -&gt; 2-mal Addition<br>
X = ( RS &gt; 0 ? immediate * 4 : 0)<br>PC = ( RS &gt; 0 ? PC + 4 + immediate * 4 : PC + 4 ) =&gt; nur noch 2 Additionen
å¤åˆ¶<br> Nebenbemerkung: $rs &gt; 0 &lt;==&gt; $rs[31] = 0 (d.h. $rs â‰¥ 0) und $rs â‰  0<br> PC ---+---+ | + |--+-----------------+---+ 4 ----+---+ | |MUX|----- PC | +--+---+ | | | +------+---+ | | | + |---+ | imm --- (&lt;&lt; 2) -----+---+ | | $rs[31] -----------------o+---+ | | &amp; |--+ $rs --------(NOR32)------o+---+
å¤åˆ¶<br>Schritt 3: Schaltung in Datenpfad einfÃ¼gen und mÃ¶glichst viele Komponenten wiederverwenden<br>
<br>
Zero-Signal gibt an, ob das ALU-Ergebnis = 0 ist! NOR32 kann durch zero-Signal ersetzt werden. <br>
Addierer und Multiplexer sind schon vorhanden, Befehle und Operanden (Register) laden ist auch vollstÃ¤ndig vorhanden.<br>
=&gt; $rs[31] kÃ¶nnen wir durch das oberste Bit des ALU-Ergebnisses (oder des oberen ALU-Eingangs) erhalten <br>
ZusÃ¤tzlich brauchen wir ein OR-Gatter zwischen dem AND und dem Multiplexer, um die MÃ¶glichkeit fÃ¼r andere Branch-Befehle offen zu halten. <br>Schritt 4: ein Steuersignal (und gegebenenfalls ein zusÃ¤tzlicher Multiplexer) hinzufÃ¼gen, um unseren Befehl zu de-/aktiveren<br>
<br>bgtz-Steuersignal ausgehend von der Control Unit bis zu dem neu eingefÃ¼gten AND-Gatter einzeichnen. Dieses schaltet das UND-Gatter an/aus und damit auch den Befehl.
<br>b) Steuersignale setzen, um den Befehl auszufÃ¼hren.<br>
<br>neues Steuersignal: BGTZ muss = 1 sein
<br>Branch = 0, das ist zwingend notwendig, den Branch = 1 bedeutet, dass BEQ ausgefÃ¼hrt wird.
<br>RegWrite = 0 =&gt; RegDst = X, MemToReg = X
<br>MemRead = MemWrite = 0
<br>Rechenoperation auswÃ¤hlen (Addition) <br>ALUOp = 00
<br>ALUSrc = 0!! obwohl I-Typ-Befehl (weil wir die Immediate nicht fÃ¼r ALU sondern PC-Berechnung nutzen) <br>das kÃ¶nnen wir machen, weil $rt = $0 ist ]]></description><link>rechnerorganisation/rorg_tut09.html</link><guid isPermaLink="false">Rechnerorganisation/Rorg_tut09.md</guid><pubDate>Sun, 21 Apr 2024 20:24:33 GMT</pubDate><enclosure url="rechnerorganisation/20230211202202.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="rechnerorganisation/20230211202202.png"&gt;&lt;/figure&gt;</content:encoded></item></channel></rss>