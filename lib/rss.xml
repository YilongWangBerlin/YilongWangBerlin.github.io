<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Obsidian Vault]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>lib/media/favicon.png</url><title>Obsidian Vault</title><link/></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Sun, 28 Apr 2024 11:43:17 GMT</lastBuildDate><atom:link href="lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Sun, 28 Apr 2024 11:43:11 GMT</pubDate><ttl>60</ttl><dc:creator/><item><title><![CDATA[Vererbung - Polymorphie]]></title><description><![CDATA[<br><br>
<br> Objekte einer Klasse können auch als Objekte der Superklasse<br>
behandelt werden
<br> Objekte gleicher Superklasse können so z.B. in einem Array<br>
zusammen gespeichert werden
<br><img alt="截屏2024-04-27 16.08.36.png" src="algorithmen-und-datenstrukturen/attachment/截屏2024-04-27-16.08.36.png" target="_self"><br><img alt="截屏2024-04-27 16.09.14.png" src="algorithmen-und-datenstrukturen/attachment/截屏2024-04-27-16.09.14.png" target="_self"><br><br>
<br> enthält nur Methodenköpfe
<br> wird ein Interface von einer Klasse implementiert, muss diese auch die Methoden des Interfaces implementieren
<br> „Vererbung" von mehreren „Klassen"
<br><img alt="截屏2024-04-27 16.10.42.png" src="algorithmen-und-datenstrukturen/attachment/截屏2024-04-27-16.10.42.png" target="_self"><img alt="截屏2024-04-27 16.10.54.png" src="algorithmen-und-datenstrukturen/attachment/截屏2024-04-27-16.10.54.png" target="_self"><br><br>
<br> im Gegensatz zu Interfaces Vererbung (von Attributen und<br>
Methoden) möglich
<br> zu implementierende Funktionen werden mit dem Stichwort abstract gekennzeichnet und sind (wie bei Interfaces) nur Funktionsköpfe
<br> wenn eine Klasse von einer abstrakten Klasse erbt, muss diese auch die abstrakten Funktionen der Superklasse implementieren
<br><img alt="截屏2024-04-27 16.13.16.png" src="algorithmen-und-datenstrukturen/attachment/截屏2024-04-27-16.13.16.png" target="_self"><img alt="截屏2024-04-27 16.13.41.png" src="algorithmen-und-datenstrukturen/attachment/截屏2024-04-27-16.13.41.png" target="_self"><br><br>• wenn noch unbekannt, welchen Datentyp ein Objekt hat<br>Beispiel:<br>Ihr schreibt einen Algorithmus, der zwei Arrays miteinander vergleicht.<br>Der Algorithmus funktioniert dabei immer gleich, egal welcher Datentyp in den Arrays gespeichert ist. Ihr wollt allerdings nicht für jeden Datentypen eine eigene Klasse schreiben.<br>
<img alt="截屏2024-04-27 16.15.25.png" src="algorithmen-und-datenstrukturen/attachment/截屏2024-04-27-16.15.25.png" target="_self"><br>
<img alt="截屏2024-04-27 16.15.54.png" src="algorithmen-und-datenstrukturen/attachment/截屏2024-04-27-16.15.54.png" target="_self"><br>
<img alt="截屏2024-04-27 18.03.53.png" src="algorithmen-und-datenstrukturen/attachment/截屏2024-04-27-18.03.53.png" target="_self"><br><br><img alt="截屏2024-04-27 16.29.26.png" src="algorithmen-und-datenstrukturen/attachment/截屏2024-04-27-16.29.26.png" target="_self"><img alt="截屏2024-04-27 16.32.15.png" src="algorithmen-und-datenstrukturen/attachment/截屏2024-04-27-16.32.15.png" target="_self">]]></description><link>algorithmen-und-datenstrukturen/tut01.html</link><guid isPermaLink="false">Algorithmen und Datenstrukturen/TUT01.md</guid><pubDate>Sat, 27 Apr 2024 16:03:58 GMT</pubDate><enclosure url="algorithmen-und-datenstrukturen/attachment/截屏2024-04-27-16.08.36.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="algorithmen-und-datenstrukturen/attachment/截屏2024-04-27-16.08.36.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Signale und System]]></title><link>signale-und-system/signale-und-system.html</link><guid isPermaLink="false">Signale und System/Signale und System.md</guid><pubDate>Tue, 23 Apr 2024 16:46:02 GMT</pubDate></item><item><title><![CDATA[Makro]]></title><link>makro/makro.html</link><guid isPermaLink="false">Makro/Makro.md</guid><pubDate>Tue, 23 Apr 2024 16:45:38 GMT</pubDate></item><item><title><![CDATA[Cognitive Algorithms]]></title><description><![CDATA[<br>here is lecture:<br><a data-href="lecture1_handout.pdf" href="cognitive-algorithms/lecture1_handout.pdf" class="internal-link" target="_self" rel="noopener">lecture1_handout.pdf</a><br>
<a data-href="lecture2.pdf.pdf" href="cognitive-algorithms/lecture2.pdf.pdf" class="internal-link" target="_self" rel="noopener">lecture2.pdf.pdf</a><br>
<a data-href="lecture_3LR.pdf" href="cognitive-algorithms/lecture_3lr.pdf" class="internal-link" target="_self" rel="noopener">lecture_3LR.pdf</a><br>
<a data-href="lecture4_Kernels-1.pdf" href="cognitive-algorithms/lecture4_kernels-1.pdf" class="internal-link" target="_self" rel="noopener">lecture4_Kernels-1.pdf</a><br>
<a data-href="lecture5_unsupervised.pdf" href="cognitive-algorithms/lecture5_unsupervised.pdf" class="internal-link" target="_self" rel="noopener">lecture5_unsupervised.pdf</a><br>
<a data-href="Lecture5-handout.pdf" href="cognitive-algorithms/lecture5-handout.pdf" class="internal-link" target="_self" rel="noopener">Lecture5-handout.pdf</a><br>
<a data-href="MLP6_lecture_new.pdf" href="cognitive-algorithms/mlp6_lecture_new.pdf" class="internal-link" target="_self" rel="noopener">MLP6_lecture_new.pdf</a>]]></description><link>cognitive-algorithms/cognitive-algorithms.html</link><guid isPermaLink="false">Cognitive Algorithms/Cognitive Algorithms.md</guid><pubDate>Tue, 23 Apr 2024 16:44:56 GMT</pubDate></item><item><title><![CDATA[Bilanzierung und Kostenrechnung]]></title><link>bilanzierung-und-kostenrechung/bilanzierung-und-kostenrechnung.html</link><guid isPermaLink="false">Bilanzierung und Kostenrechung/Bilanzierung und Kostenrechnung.md</guid><pubDate>Tue, 23 Apr 2024 16:41:37 GMT</pubDate></item><item><title><![CDATA[Analysis II]]></title><description><![CDATA[<br><a data-href="notiz-1.pdf" href="analysis-ii/notiz-1.pdf" class="internal-link" target="_self" rel="noopener">notiz-1.pdf</a><br>
<a data-href="notiz-2.pdf" href="analysis-ii/notiz-2.pdf" class="internal-link" target="_self" rel="noopener">notiz-2.pdf</a><br>
<a data-href="notiz-3.pdf" href="analysis-ii/notiz-3.pdf" class="internal-link" target="_self" rel="noopener">notiz-3.pdf</a>]]></description><link>analysis-ii/analysis-ii.html</link><guid isPermaLink="false">Analysis II/Analysis II.md</guid><pubDate>Tue, 23 Apr 2024 16:41:20 GMT</pubDate></item><item><title><![CDATA[Mikro_06]]></title><description><![CDATA[<br><br><br><img src="mikro/20230203203903.png" target="_self"> <br><img src="mikro/20230203203935.png" target="_self"><br>
<img src="mikro/20230203203958.png" target="_self"><br>
<img src="mikro/20230203204025.png" target="_self"><br>
<img src="mikro/20230203204056.png" target="_self"> <br><br>####Neues Haushaltsoptimum nach Preiserhoehung von Gut 1:<br>
<img src="mikro/20230204003627.png" target="_self"> <br>
<br>A:HHO vor Preisaenderung: <br>Ursachen:<br>
<br>Substitutionsverhaeltnis
<br>Realeinkommen
<br><br><img src="mikro/20230204005508.png" target="_self"> <br>
<br>A:HHO vor Preisaenderung:
<br>C:HHO nach Preisaenderung:
<br>B:HHO nach Preisaenderung bei Kaufkrafterhaltung(durch Einnkommenskompensation):
<br> <br><br>
Substitutionseffekt ist immer der Preisaenderung entgegengesetzt! <br><br><img src="mikro/20230204011052.png" target="_self"><br>
<br>
<br>normales Gut: <br>inferiores Gut: <br><br><br>
<br>gewoehnliches Gut: <br>Giffen-Gut: <br><br><img src="mikro/20230205103044.png" target="_self"><br>
<img src="mikro/20230205103153.png" target="_self"><br>
<img src="mikro/20230205103256.png" target="_self"> ]]></description><link>mikro/mikro_06.html</link><guid isPermaLink="false">Mikro/Mikro_06.md</guid><pubDate>Tue, 23 Apr 2024 08:32:19 GMT</pubDate><enclosure url="mikro/20230203203903.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="mikro/20230203203903.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Mikro_12]]></title><description><![CDATA[<br><br><br>Bestimmung des Konkurrenzgleichgewichtes für 2 Güt, 2 Konsumenten, allg. Cobb-Douglas Präferenzen<br>
<img src="mikro/20230206154832.png" target="_self"><br>
<img src="mikro/20230206154915.png" target="_self"><br>
<img src="mikro/20230206174217.png" target="_self"><br>
<img src="mikro/img_045039d5abaf-1.jpeg" target="_self"><br><br>
<br>
<br>Nettonachfrage = Bruttonachfrage - Erstausstattung
<br>wenn Nettonachfrage &gt; 0, Nachfrager
<br>wenn Nettonachfrage &lt; 0, Anbieter
<br><img src="mikro/20230206175857.png" target="_self"> <br><br><img src="mikro/20230206180014.png" target="_self"> <br><br><img src="mikro/img_5122b71db030-1.jpeg" target="_self"><br><br><img src="mikro/20230206180928.png" target="_self"> ]]></description><link>mikro/mikro_12.html</link><guid isPermaLink="false">Mikro/Mikro_12.md</guid><pubDate>Tue, 23 Apr 2024 08:32:03 GMT</pubDate><enclosure url="mikro/20230206154832.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="mikro/20230206154832.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Mikro]]></title><description><![CDATA[<br><a data-href="Mikro_06_" href="mikro/mikro_06_.html" class="internal-link" target="_self" rel="noopener">Mikro_06_</a><br>
<a data-href="Mikro_06" href="mikro/mikro_06.html" class="internal-link" target="_self" rel="noopener">Mikro_06</a><br>
<a data-href="Mikro_07" href="mikro/mikro_07.html" class="internal-link" target="_self" rel="noopener">Mikro_07</a><br>
<a data-href="Mikro_12" href="mikro/mikro_12.html" class="internal-link" target="_self" rel="noopener">Mikro_12</a><br>
<a data-href="Mikro_12" href="mikro/mikro_12.html" class="internal-link" target="_self" rel="noopener">Mikro_12</a><br>
<a data-href="Mikro_vl13" href="mikro/mikro_vl13.html" class="internal-link" target="_self" rel="noopener">Mikro_vl13</a>]]]></description><link>mikro/mikro.html</link><guid isPermaLink="false">Mikro/Mikro.md</guid><pubDate>Sun, 21 Apr 2024 21:01:24 GMT</pubDate></item><item><title><![CDATA[Mikro_vl13]]></title><description><![CDATA[<br><br>Lösungsweg<br>
Nicht Vergessen!!<br><br>
<br>
Güter: Konsum C und Arbeit L (bzw. Freizeit R) mit Preisen p bzw. w <br>
Unternehmen: <br>Outputgut: Konsumgut (C) <br>Inputgut: Arbeit (L) (bzw. Freizeit, ) <br> ist das maximal mögliche Arbeitsangebot (bzw. maximale mögliche Freizeit), z.B. 24 Stunden pro Tag <br>Produktionsfunktion: <br>
Zwei Konsumenten: A, B <br>Nutzenfunktion: ,
<br>Anfangsausstattungen: <br>Unternehmensanteile: <br>Konsument A:
<br>Konsument B: <br>
Konsumenten: <br>Nutzenfunktion: <br>Anfangsausstattungen: <br>Unternehmensanteile: <br>Konsument : <br><br><img src="mikro/20230209113338.png" target="_self"><br>
于c轴相交点为<br><br><img src="mikro/20230209113432.png" target="_self"> <br><br><img src="mikro/20230209113522.png" target="_self"> <br><br><img src="mikro/20230209113600.png" target="_self"> <br><br><img src="mikro/20230209113637.png" target="_self"> <br>
<br>Erstes Theorem der Wohlfahrtsökonomie: Das Konkurrenzgleichgewicht ist Pareto-effizient
<br>Zweites Theorem der Wohlfahrtsökonomie: Wenn alle Präferenzen konvex sind, dann ist jede Pareto-effiziente Allokation ein Gleichgewicht für eine entsprechende Ausstattung
<br><br>sieht Video 17: Produktionsökomomie<br><br><img src="mikro/20230209114132.png" target="_self"> <br>
<br>Ein allgemeines Gleichgewicht liegt vor, wenn die Preise genau so sind, dass die Märkte für alle Güter geräumt sind, d.h. die Summe der Nettonachfragen aller Konsumenten nach jedem Gut ist gleich der Summe des Nettoangebots an diesem Gut
<br><br><img src="mikro/20230209114324.png" target="_self"> <br><br><br><img src="mikro/20230211144930.png" target="_self"><br>
<img src="mikro/20230211144953.png" target="_self"><br>
<img src="mikro/20230211145010.png" target="_self"> <br><br> für alle Güter<br><br><img src="mikro/20230211145420.png" target="_self"> <br>
<br>
<br> <br><img src="mikro/20230211150241.png" target="_self"> <br><br><img src="mikro/20230211150308.png" target="_self"> <br><br><br><img src="mikro/20230211150650.png" target="_self"><br>
<img src="mikro/20230211150738.png" target="_self"><br>
<img src="mikro/20230211150808.png" target="_self"><br>
<img src="mikro/20230211150831.png" target="_self"><br>
<img src="mikro/20230211150850.png" target="_self"> <br><br><img src="mikro/20230211150915.png" target="_self"> <br><br><img src="mikro/20230211151012.png" target="_self"> ]]></description><link>mikro/mikro_vl13.html</link><guid isPermaLink="false">Mikro/Mikro_vl13.md</guid><pubDate>Sun, 21 Apr 2024 20:29:41 GMT</pubDate><enclosure url="mikro/20230209113338.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="mikro/20230209113338.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Mikro_07]]></title><description><![CDATA[<br><br><br><img src="mikro/20230205120910.png" target="_self"><br>
<img src="mikro/20230205121013.png" target="_self"><br>
<img src="mikro/20230205121041.png" target="_self"><br>
<img src="mikro/20230205121105.png" target="_self"> ]]></description><link>mikro/mikro_07.html</link><guid isPermaLink="false">Mikro/Mikro_07.md</guid><pubDate>Sun, 21 Apr 2024 20:29:41 GMT</pubDate><enclosure url="mikro/20230205120910.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="mikro/20230205120910.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Mikroökonomik VL06]]></title><description><![CDATA[<br><br><br><img src="mikro/20230203203903.png" target="_self"><br>
<img src="mikro/20230203203935.png" target="_self"><br>
<img src="mikro/20230203203958.png" target="_self"><br>
<img src="mikro/20230203204025.png" target="_self"><br>
<img src="mikro/20230203204056.png" target="_self"><br>
]]></description><link>mikro/mikro_06_.html</link><guid isPermaLink="false">Mikro/Mikro_06_.md</guid><pubDate>Sun, 21 Apr 2024 20:29:41 GMT</pubDate><enclosure url="mikro/20230203203903.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="mikro/20230203203903.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Readme]]></title><description><![CDATA[<br>Hier findest du die Folien, die ich in meinen Tutorien verwende. Sie behandeln den Stoff unvollständig und sind nur eine Ergänzung zum Tutorium. Fürs lernen empfehle ich euch die Zusatzvideos sehr :)]]></description><link>rechnerorganisation/tut/readme.html</link><guid isPermaLink="false">Rechnerorganisation/tut/Readme.md</guid><pubDate>Sun, 21 Apr 2024 20:27:54 GMT</pubDate></item><item><title><![CDATA[Rorg_tut12]]></title><description><![CDATA[<br><br><br><br><img src="rechnerorganisation/img_b88a7876cfcd-1.jpeg" target="_self"><br>
<img src="rechnerorganisation/20230209205748.png" target="_self"><br>
<img src="rechnerorganisation/img_46ed4549b8b6-1.jpeg" target="_self"><br>
<img src="rechnerorganisation/20230209211444.png" target="_self"><br>
ps 本图主要看ppt<br><br><img src="rechnerorganisation/20230209211620.png" target="_self"> <br><br><img src="rechnerorganisation/20230209212059.png" target="_self"><br>
先进先出的算法（FIFO）：选择在内存中驻留时间最久的页面予以替换。<br><br><img src="rechnerorganisation/20230209212748.png" target="_self"><br>
最近最久未使用算法（LRU）：选择过去最长时间未被访问的页面予以替换。<br><br><img src="rechnerorganisation/20230209213148.png" target="_self"> <br>最佳淘汰算法（OPT）：选择永不使用或在未来最长时间内不再被访问的页面予以替换。<br>
在tag=4时出现miss的情况:<br>
<br>way 0: 3在未来出现了2次
<br>way 1: 0在未来出现了3次
<br>way 2: 1在未来出现了2次
<br>way 3: 2在未来出现了2次
<br>替换way2的理由：因为way 0，2，3的值在未来出现的次数相等，根据fifo,way 2最久没有被访问<br><br>TU CLOUD: bit.lz/ROrgTUT<br><img src="rechnerorganisation/20230210102121.png" target="_self"> <br><br>
<br>Problem1 <br>wie findet die Seite("Cache-Block")ins Archiv zurueck?
<br>"Tag": merkt sich Herkunftsort("Blockadress")einer Seite <br>Problem 2 <br>Wo legen wir die Seite in die Ablage("Cache"<br>
)?
<br>z.B beliebige Stelle, wo nach Platz ist("vollassoziativ") <br>Problem 3 <br>Sortierung der Seiten in Ablage?(um Seiten schneller zu finden)
<br>"Cache-Sets": Faecher fuer Seiten mit gleichen "Anfangsbuchstaben" <br>Problem 4 <br>was machen, wenn die Ablage voll ist?
<br>"Ersetzungsstragie": alte Seite ausstauchen und zurueckbringen <br><br><img src="rechnerorganisation/20230210105051.png" target="_self"> <br><br>cache-Typen:<br>
<br>vollassoziati("fully associative"): <br>1.Satz ("Stapel"),wo alle Cache-Block <br>direkt abgebildet("Direct Mapped"): <br>assoziativitaet = 1. jeder Satz enthaelt maximal einen Cache-Block <br>n-fach satz assoziativ: <br>Assoziativtaet = n <br><br>
<br>direkt abgebildet -&gt; Assoziativitaet = 1
<br>Kapazitaet = 8 KiB = 8 * 1024 Bytes = 2^13 Bytes (und nicht 8000 Byte!!)
<br>Cacheblock-Groesse = 2^5 Bytes
<br>32, 8192, 48, 8208, 32, 8224, 48, 8240, 32, 8256<br>
Simulation: • Index, • Tag <br>Wie viele Bits hat der Blockoffset? (die Adresse innerhalb des Blocks)<br>
<br>:
<br>Wie viele Bits hat der Index?<br>
<br>Zuerst: wie viele Sätze gibt es im Cache?
<br>Satzgröße = (Cacheblock-Größe • Assoziativität) = 2^5 Bytes
<br>
<br>
<br>wie viele Bits hat der Tag?<br>
<br>Das wissen wir nicht, müssen wir nicht wissen (sagen wir, es sind genug Bits;-).)
<br>Lustig: wir haben keine vorgegebene Größe für die Adresse des Prozessor.)
<br>Blockadresse = (Adresse / Cacheblockgröße)<br>
Blockadresse = (Adresse &gt;&gt;(blockoffset Bits))<br>Index = Blockadresse % (2^(Index Bits))<br>
Index = • Blockadresse &amp; (größten Index) <br>größter Index = 2^(index bits) - 1 = 2^8 - 1 = FF16<br>
Tag = Blockadresse / 2^(Index Bits)<br>
Tag = Blockadresse &gt;&gt; (Index • Bits)<br>
<img src="rechnerorganisation/20230210160153.png" target="_self"> <br><br>
<br>2-fach•satz-assoziativ - Assoziativität=2
<br>Kapazität = 8KiB = 8 • 1024 Bytes = 2^13 Bytes
<br>Cacheblockgröße = 8 Wörter = 8•4 Bytes = 2^5 Bytes
<br>Byteaddressengröße = 40 Bits
<br>Prozessor schickt Byteadresse (1 Byte = 2 Nybble = Hexadezimalziffer):<br>
a)<br>
Wie größ ist der Index?
<br>Satzgröße = Blockgröße * Assoziativität = 2^5 • 2^1 Bytes = 2^6 Bytes <br>Anzahn an Sätze = Kapazität / Satzgröße = 2^13 / 2^6 • Bytes = 2^7 Bytes:
<br>Indexgröße = log2 ( Anzahl an Sätze ) = 7 Bit<br>
Wie groß ist der Tag?
<br>Blockoffsetgröße = log2 ( Blockgröße)Bits = log2 (2^5)Bits = 5 Bits
<br>Adressgröße - Indexgröße - Blockoffsetgröße = 40 - 7 - 5 = 28 Bits<br>
b)<br>
Adresse = [tag = 28 Bits, index = 7 Bits, blockoffset = 5 Bits ]<br>
Adresse = 55236<br>
Blockadresse = (Adresse / Blockgröße)<br>
Index = Blockadresse % 2^7 = 62
<br><br>AMAT = Average Memory Access Time (durchschnittliche Zugriffszeit)<br>
Es gibt jetzt verschiedene Fälle (verschiedene Fälle).<br>
<br>Fall: wir-finden den• Cache-Block im sog. L1-Cache
<br>Fall: wenn nicht im LI-Cache, finden wir den Cache-Block im L2-Cache
<br>Fall: wenn nicht im L2-Cache, finden wir den-Cache-Block im RAM (Random Access Memory)<br>
Für jeden Fall die Häufigkeit (Wahrscheinlichkeit) berechnen.<br>
Für jeden Fall die Zeitdauer berechnen.
<br>-&gt; AMAT = gewichtete Mittelwert<br>
-&gt; Miss-Rate = Häufigkeit eines Cache-Misses (in Prozent)<br>
<br>lokal: für jeden Cache-Zugriff, wie häufig gibt es einen Cache-Miss? (Dieser ist gegeben!! wenn nichts weiter gesagt ist.).
<br>global: wie viele Speicherzugriffe vom Prozessor landen im Cache und erzeugen einen Cache-Miss?
<br>1.Fall (L1-Cache):<br>
<br>
Zeit = 3 Takte <br>
globale Häufigkeit = 100% - 7% = 93% <br>
100% der Fälle erreichen L1-Cache, davon 93% der Fälle ein Cache-Hit
1.Fall (L2-Cache): <br>
Zeit = L1-Cache-Zeit + 15 Takte = 18 Takte <br>
globale Häufigkeit = 7% (100% - 34%) = 7% 66% = 4.62% <br>
7% der Fälle erreichen den L2-Cache, davon 66% der Fälle ein Cache-Hit
2.Fall (RAM): <br>
Zeit = L2-Cache-Zeit + 100 Takte = 118 Takte <br>
globale Häufigkeit = 7% * 34% = 100% - 93% - 4.62% = 2.38% <br>
7% der Fälle erreichen L2-Cache und dort in 34% der Fälle gehen wir zum RAM weiter <br>AMAT = 93% 3 Takte + 4.62% 18 Takte + 2.38% * 118 Takte AMAT = 6.43 Takte]]></description><link>rechnerorganisation/rorg_tut12.html</link><guid isPermaLink="false">Rechnerorganisation/Rorg_tut12.md</guid><pubDate>Sun, 21 Apr 2024 20:24:33 GMT</pubDate><enclosure url="rechnerorganisation/img_b88a7876cfcd-1.jpeg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src="rechnerorganisation/img_b88a7876cfcd-1.jpeg"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Rechnerorganisasion TUT 11]]></title><description><![CDATA[<br><br><br><br>was ist ein nop-Befehl<br>
<br>No Operation
<br>Befehl der nichts ausführt(keinen Zustand verändert)
<br>gewöhnlich Befehl dessen 32 Bit auf 0 gesetzt sind
<br>in MIPS: sll $zero, $zero, 0<br>
Auflösung von Datenkonflikten in Pipelined-Prozessoren:
<br>nop-Befehle <br>simpleres Design(weniger Baauteile/kostengünstig)
<br>Compiler/Programmierer muss manuell nop's einfügen <br>alternativ: Hardware-Forwarding
<br><br>
<br>
ursprüngliches Proplem bei Eintaktprozessor: Abschnitten im Eintaktprozessor werden nicht vollständig ausgenutzt. <br>
Idee: wir fangen an, Befehle auszuführen, bevor der vorherige Befehl fertig ist. <br>damit die Datenpfad-Abschnitte mehr genutzt werden (mehr Arbeit ausführen)
<br>sobald der Befehl zu den Registern geht, wird schon ein neuer Befehl aus dem Speicher geladen <br>
wir haben 5 Abschnitte: Instruction Fetch, Instruction Decode, Execute, Memory (Read/Write), Write Back <br>sobald ein Befehl in Instruction Decode ist, wird der nächste Befehl angefangen <br><br>
<br>manche Bestandteile aus dem Eintaktprozessor wurden "bewegt" an andere Stelle
<br>es gibt solche "Balken" (zusätzlichen Rechtecke) = Pipeline-Register
<br><br>
<br>
diese trennen die verschiedenen Stufen <br>
aber warum brauchen wir diese Register wirklich? <br>weil wir jede Stufe in der gleichen Zeit ausführen wollen
<br>wir wissen aus letzter Woche: die Stufen sind unterschiedlich schnell<br>
(z.B. Instruction Fetch = Speicherzugriff 150ps, Register-Lesen = 50 ps, ALU = 100ps)
<br>wir wollen nicht, dass eine frühere Stufe die nächste vorzeitig unterbricht =&gt; die Pipeline-Register halten die Eingangsdaten (für eine Stufe) und warten, bis der nächste Takt anfängt (Synchronisation) <br><br>
<br>
Datenkonflikte (Data Hazard) <br>
Register-Werte fehlen, wenn diese gebraucht werden <br>
wenn ein Befehl das Ergebnis von dem vorherigen Befehl braucht, dann ist der vorherige Befehl noch nicht fertig!!<br>
Die Daten des vorherigen Befehls sind nicht da<br>
Die gelesen Register vom nächsten Befehl (weiter links in der Pipeline) sind noch nicht upgedatet, also falsch <br>
wir können das richtige Ergebnis erst aus dem Register laden, während das Ergebnis geschrieben wird<br>
warum? <br>Idee: wir können den Takt in zwei Hälften unterteilen
<br>erste Hälfte: schreibe das Ergebnis in Register in Write Back
<br>zweite Hälfte: Register werden gelesen in Instruction Decode <br>
wie kann machen, damit Data Hazards weniger Zeit verschwenden? <br>Forwarding Unit + Hazard Detection (Ergebnis wird weitergereicht, sobald das Ergebnis berechnet wurde, also schon vor Write-Back) <br>
Steuerkonflikte (Control Hazard) <br>
die Sprungentscheidung, Sprungadresse fehlt, wenn wir diese bereits brauchen <br>
der Kontrollfluss (also die Befehlsausführung) ist verzögert (ist noch nicht entschieden) <br>
wir können Befehle ausführen, die eigentlich nicht ausgeführt werden sollen <br>
wie schneller machen? <br>"Branch Prediction" (siehe unten) <br>wenn wir häufig richtig raten, sind wir schneller <br>Sprungentscheidung viel früher berechnen (z.B. in Instruction-Decode, dafür Extra-Hardware nötig) <br>
Strukturelle Konflikte (Structural Hazard) (nennen wir nur wegen der Vollständigkeit) <br>wenn zwei Befehle dieselbe Pipeline-Stufe gleichzeitig nutzen wollen
<br>z.B. wenn es zwei Pipelines gibt (2K-Zahlen und Floating-Point-Zahlen) und diese zusammenlaufen (zusammengeführt werden) <br>Advanced Computer Architectures <br>kommen bei uns nicht vor <br>
wie verhindern (entschärfen) wir die Hazards? <br>"Stall Cycles" (Takte wo angehalten wird), "der Prozessor hält die vordere Pipeline an (Instruction Fetch und Instruction Decode)
<br>wir ignorieren das Problem, Compiler soll das Problem lösen <br>Compiler fügt "Wartebefehle" ein, "NOP"s = No operation
<br>Delay Slot (= Takte die gewartet werden müssen, bis das richtige Ergebnis da ist) = Latenz ("Bearbeitungszeit") <br>wir können auch andere Befehle statt NOPs nutzen, die fehlende Ergebnis nicht brauchen <br>"Flushing" ("herunterspülen") <br>die Pipeline bis zu Instruction Decode wird geleert (d.h. das wir die Befehle später nochmal laden) <br>für Control Hazards: wir können raten (Spekulation, "Branch Prediction"), welche Sprungentscheidung genommen wird <br>wenn wir falsch raten, dann werden wir bestraft, indem wir alle falsch ausgeführten Befehle rückgängig machen müssen ("Flushing" + andere Sachen)
<br>wenn wir richtig raten, dann sind wir richtig schnell 😀 <br><br>a)<br>
<br>ohne Optimierung: <br>wenn ein Register-Ergebnis berechnet wird, dann ist das Ergebnis die nächsten zwei Takte nicht verfügbar
<br>siehe Bild <br>0 addi *$t0* ,$a0 ,4
1 addi *$t1* ,$a1 ,4
2 sub $t2 ,*$t0* ,*$t1*
3 sll *$t3* ,$a2 ,2
4 add *$t4* ,$t0 ,*$t3*
5 add $t5 ,$t1 ,*$t3*
6 sw $t2 ,0( *$t4* )
复制<br>b)<br>
<br>keine Reihenfolge ändern, nur Wartebefehle (NOPs) einfügen
<br>0 addi $t0 ,$a0 ,4 1 addi $t1 ,$a1 ,4 1.2 nop
1.3 nop 2 sub $t2 , $t0 , $t1 3 sll $t3 ,$a2 ,2 3.1 nop
3.2 nop 4 add $t4 ,$t0 , $t3 5 add $t5 ,$t1 , $t3 5.1 nop 6 sw $t2 ,0( $t4 )
复制<br>c)<br>
<br>noch besser machen: jetzt so wenig wie möglich NOPs brauchen, Befehle umordnen
<br>wie vorgehen ? wir gucken, welche Befehle brauchen das Ergebnis von welchen anderen Befehlen? =&gt; grafisch aufzeichnen <br>List Scheduling (siehe Internet? → Compiler Design Kurs. Statt "Aufträge" "Maschinen" zuzuweisen, weisen wir der Pipeline neue Befehle zu) <br><br>a)<br>
<br>
Speicherzugriff = 200ps, ALU-Operation = 100ps, Registerzugriff = 50ps <br>
Benchmark (Programm, um die Ausführungszeit zu messen) <br>
Annahmen: gleiche Anzahl an Befehle für beide Prozessoren <br>
Jeder Prozessor hat eine (eigene) konstante Taktzeit, T_SC = Taktdauer des Eintaktprozessor (Single Cycle), T_PP = Taktdauer für Pipeline-Prozessor <br>
es gibt keine Data Hazards mehr (wurden entfernt durch Umordnung) <br>
es gibt aber alle Control-Hazards noch! -&gt; jeder Sprungbefehl dauert 4 Takte! Der Prozessor hält bei Sprungbefehlen einfach an! <br>
Speicherbefehle -&gt; 12% (1 Takt pro Speicherbefehl weil keine Datenkonflikte Data Hazards) <br>
ALU-Befehle -&gt; 72% (1 Takt pro Speicherbefehl weil keine Datenkonflikte) <br>
Sprung-Befehle -&gt; 16% (4 Takte pro Sprungbefehl, wegen den Steuerkonflikten Control Hazards) <br>
wozu die Informationen? Damit wir die Schnelligkeit des Pipeline-Prozessors berechnen können. Eintaktprozessor führt jeden Befehl gleichschnell aus <br>
unbekannte Anzahl N an Befehlen <br>
Pipeline ist zu Beginn der Benchmark gefüllt <br>
Speedup berechnen, S = Vergleichszeit t_SC / (betrachtete Zeit) t_PP -&gt; wie viel Faktor schneller ist der betrachtete Prozessor <br>
t_SC = Ausführungszeit Eintaktprozessor = (Anzahl an Takte) · (Taktdauer) = (N · CPI_SC) · T_SC <br>
t_PP = Ausführungszeit Pipelineprozessor = (Anzahl an Takte) · (Taktdauer) = (N · CPI_PP) · T_PP <br>
CPI = Befehlsdauer in Takten = wie lange braucht ein Befehl an Takten zur Ausführung <br>CPI_SC = 1 da jeder Befehl einen Takt braucht
<br>CPI_PP = jeder Befehl braucht unterschiedlich viele Takte (hängt ab von den Hazards) <br>gewichteter Mittelwert: 12% 1 + 72% 1 + 16% * 4 = 1.48 <br>
T = Taktdauer, wie viel Sekunden braucht ein Takt <br>T_SC = 600ps = 2·200ps + 100ps + 2·50ps (2-mal Speicherzugriff, 2-mal Registerzugriff, 1-mal ALU)
<br>T_PP = maximale Dauer einer Stufe = 200ps (wir brauchen eine Taktdauer in der jede Stufe ausgeführt wird) <br>
S = (N · CPI_SC) · T_SC / ((N · CPI_PP) · T_PP) = 600ps / (1.48 * 200ps) = 2,027027027… = 2 + 27/999 <br>b) wie können wir den Pipeline-Prozessor schneller machen? siehe Aufgabe 1<br>c) Was ist, wenn wir nur die ALU schneller machen, um 25% ?<br>ALU-Operation braucht nur 75ps<br>-&gt; T_SC = 2·200ps + 75ps + 2·50ps = 575ps<br>T_PP ändert sich nicht!! Immernoch die gleichen Hazards, und Speicherbefehle dauern immernoch 200ps<br>=&gt; der Speedup wird schlechter, weil der Pipeline-Prozessor nicht profitiert<br>=&gt; Pipeline wird nur schneller, wenn man die am längsten dauernde Stufe optimiert.<br><br><img src="rechnerorganisation/20230203105924.png" target="_self"><br>
<img src="rechnerorganisation/bildschirm­foto-2023-02-03-um-10.51.40.png" target="_self"><br>
<img src="rechnerorganisation/bildschirm­foto-2023-02-03-um-11.48.40.png" target="_self"><br>Aufgabe 3<br>a) Verbesserung ist, dass man die EX und MEM-Stufe zusammenlegen kann. Die Pipeline wird kürzer. Load-Use-Konflikte sind einen Takt schneller (0 statt 1 Takte Verzögerung).<br>b)<br>Verbesserungen gibt es, wenn Speicherfefehle keinen Offset brauchen<br>das ist der Fall bei Array-Zugriffen in Schleifen oder Integer-Pointer<br>alle anderen Zugriffe brauchen einen Offset<br>wenn man einen konstanten Offset braucht, wird man verlangsamt<br>der Offset muss in Extra-Befehl berechnet werden<br>der zusätzliche Befehl wird nur durch kürzere Load-Use-Hazards kompensiert<br>verbraucht ein Register (erhöht den Registerdruck), sowie zusätzlichen Platz im Befehlsspeicher (Cache-Verschmutzung)<br>in Praxis brauchen wahrscheinlich mehr Befehle einen konstanten Offset als keinen<br>alle struct-, Objekt-Zugriffe brauchen einen; häufiger Spezialfall: Stack-Frames<br>häufig in Praxis, vor allem Stack Frames, da es viel mehr innere Funktionsaufrufe mit Stack als Blatt-Funktionsaufrufe ohne Stack gibt.<br><img src="rechnerorganisation/20230203131555.png" target="_self"><br>
<img src="rechnerorganisation/20230203131618.png" target="_self"><br>
<img src="rechnerorganisation/20230203131640.png" target="_self"> ]]></description><link>rechnerorganisation/rorg_tut11.html</link><guid isPermaLink="false">Rechnerorganisation/Rorg_tut11.md</guid><pubDate>Sun, 21 Apr 2024 20:24:33 GMT</pubDate><enclosure url="rechnerorganisation/20230203105924.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="rechnerorganisation/20230203105924.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Rorg_tut09]]></title><description><![CDATA[<br><br><br><br><img src="rechnerorganisation/20230211202202.png" target="_self"><br>
<img src="rechnerorganisation/20230211202257.png" target="_self"> <br><br><img src="rechnerorganisation/20230211202413.png" target="_self"> <br><br><img src="rechnerorganisation/20230211202621.png" target="_self"><br>
右下图:Wie viele Takte benötigt eine Instruktion?(CPI)<br><br><img src="rechnerorganisation/20230211202841.png" target="_self"><br>
<img src="rechnerorganisation/20230211202918.png" target="_self"><br>
<img src="rechnerorganisation/20230211202943.png" target="_self"> <br><br>
<br>R-Typ-Befehl (ALUSrc = 0, RegDst = 1)
<br>I-Typ-Befehl (ALUSrc = 1 (meistens), RegDst = 0)
<br>J-Typ-Befehl (haben wir nicht im Datenpfad)
<br>Speicherbefehle (lw, sw) <br>MemToReg = 1, MemWrite, MemRead, RegWrite
<br>Branch = 0 <br>Rechenbefehle (add, sub, and, or, sll, …) <br>MemToReg = 0, RegWrite = 1
<br>MemRead = 0!!, MemWrite = 0, Branch = 0 <br>Sprungbefehle <br>Branch = 1 (bzw. Jump = 1)
<br>RegWrite = 0, MemRead = 0!!, MemWrite = 0 <br><br>
<br>Schritt 1: Befehlsverhalten definieren
<br>Schritt 2: Funktion als Schaltnetz entwerfen <br>Eingabe: <br>≤ 2 Register-Werte, ≤ 1 16-Bit-Konstanten, 32-Bit-Befehl <br>Ausgabe: <br>nächste Befehlsadresse (PC)
<br>Ergebniswert(e) (optional)
<br>Zieladresse (Register und/oder RAM, optional) <br>Schritt 3: Schaltnetz auf bestehenden Datenpfad abbilden <br>alle nutzbaren Elemente im Datenpfad wiederverwenden <br>Schritt 4: Steuersignale/Muxe hinzufügen (um Befehl zu aktivieren)
<br><br><br>a) was beeinflusst die Veränderung des Registerinhalts in einem Befehl?<br>direkten Einfluss:<br>
<br>RegDst: R-Typ und I-Typ-Befehle -&gt; RT = Instruction[16 bis 20] und RD = Instruction[11 bis 15] (als Bitfelder im Befehl) <br>RegDst = 0 =&gt; RT ausgewählt (immer für I-Typ), RegDst = 1 =&gt; RD ausgewählt (immer für R-Typ)
<br>R-Typ [ Opcode, RS, RT, RD, shift amount, Func ] =&gt; RD = ...
<br>I-Typ [ Opcode, RS, RT, imm16 ] =&gt; RT = ... <br>RegWrite: Bestimmt, ob die Daten am Write-Data-Port in das Zielregister geschrieben werden sollen
<br>MemToReg: gibt an, von wo die Daten zum Schreiben kommen. MemToReg = 1 heißt, dass die Daten vom "Memory" kommen.
<br>indirekten Einflus:<br>
<br>MemRead: wenn = 1, kann es Daten für die Register aus dem Hauptspeicher lesen
<br>ALUOp: bestimmt, wie mögliche Daten zum Schreiben berechnet werden
<br>ALUSrc: bestimmt, wie mögliche Daten zum Schreiben berechnet werden (meistens: I-Typ =&gt; ALUSrc = 1, immer: R-Typ =&gt; ALUSrc = 0)
<br>keinen Einfluss:<br>
<br>Branch (beeinflusst nur PC)
<br>MemWrite: das Schreiben vom Hauptspeicher verändert die möglichen geschriebenen Registerdaten nicht
<br>b) welche Steuersignale beeinflussen das Beschreiben des Hauptspeicher (RAM – Random Access Memory)<br>
<br>MemWrite
<br>MemRead (es gibt eine Optimierung des Speicherzugriffs, die nennt sich Cache, und dort werden Lesezugriffe gemerkt. Dieser Cache verändert sich, wenn man liest, was zwar keine funktionale aber einen Performance-Unterschied macht. Zusätzlich kann man beim Lesen auf bestimmte Speicheraddressen Register von Hardware außerhalb des Prozessors verändern, weil diese so funktioniert. Deshalb sollte führt das Lesen zu einer Zustandsänderung des Computers bzw. des Speichers.)
<br>Andere Steuersignale nicht, denn diese beschreiben nur Veränderungen in den Prozessorregistern.<br><br>a) welche Steuersignale dürfen niemals (bei keinem Befehl) einen nicht-definierten (beliebigen) Wert annehmen?<br>
<br>Branch: <br>weil Branch das Überschreiben des Programm-Counters direkt beeinflusst und der nächste Wert des PCs für jeden Befehl fest definiert ist <br>RegWrite, MemWrite: <br>es ist für jeden fest definiert, ob und welche Register wir schreiben und welche Speicheradresse <br>MemRead: <br>nur = 1, wenn wir wirklich lesen wollen
<br>weil: das Lesen von Hauptspeicher beeinflusst den Cache (eine Hardware-Optimierung), die sich Lesezugriffe merkt, um diese zu beschleunigen <br>b) welche Steuersignale sind egal, wenn RegWrite = 0?<br>
<br>in dem Fall: Write-Data und Write-Register-Ports (vom Register File) sind dann egal, sodass <br>RegDst beliebig sein kann
<br>MemToReg beliebig sein kann <br>NICHT EGAL! ist <br>ALUSrc
<br>ALUOp
<br>weil ist möglich, dass wir einen Schreibbefehl ausführen (sw, sb) <br>in dem Fall nutzen wird die ALU, um die Speicheradresse zu berechnen <br>c) welche Funktionalität (oder welcher Befehl) passiert (wohl), wenn RegWrite = 1, MemRead = 1, MemToReg = 1 ist?<br>
<br>MemRead = 1 liest Daten aus dem Speicher,
<br>MemToReg = 1 leitet gelesene Daten aus Hauptspeicher zu Register-File (Registersatz) weiter
<br>anliegende Daten am Register-File werden mit RegWrite = 1 in ein Register geschrieben
<br>naheliegender Befehl: load word (lw)<br>
Berechnung der Speicheradresse nicht vorgegeben (könnte beliebig sein)<br><br>ADDI:<br>
<br>RegDst: wegen I-Typ wollen wir nach RT schreiben, das machen wir mit RegDst = 0
<br>Branch = 0, da wir nach dem Befehl den nachfolgenden Befehl ausführen
<br>MemRead = 0, da wir nur ein Registerwert berechnen wollen, keine Speicherveränderung
<br>MemToReg = 0, damit wir das ALU-Ergebnis an das Register weiterleiten können
<br>ALUOp = 00; die linke 0 sagt, dass es keinen Func-Code gibt und das rechte Bit bestimmt, ob Addition (= 0) oder Subtraktion (= 1) ist
<br>MemWrite = 0, weil wir den Hauptspeicher nicht verändern wollen
<br>ALUSrc = 1, da wir einen I-Typ-Befehl haben und mit der Immediate rechnen wollen
<br>RegWrite = 1, damit wir unser Additionsergebnis in das Register reinschreiben können
<br><br>a) BGTZ zum Datenpfad hinzufügen.<br>Schritt 1: Verhalten definieren.<br>
BGTZ $rs, Label (Label = PC + 4 + imm4 )<br>
PC = PC + 4 + ( RS &gt; 0 ? immediate 4 : 0) // a ? b : c === if a then b else c<br>Schritt 2:<br>
<br>Eingabe: PC, RS, imm = (Label - 4)/4 =&gt; RT = $0 (weil nicht angegeben)
<br>Ausgabe: PC
<br> Schaltnetz:<br>
PC = PC + 4 + X -&gt; 2-mal Addition<br>
X = ( RS &gt; 0 ? immediate * 4 : 0)<br>PC = ( RS &gt; 0 ? PC + 4 + immediate * 4 : PC + 4 ) =&gt; nur noch 2 Additionen
复制<br> Nebenbemerkung: $rs &gt; 0 &lt;==&gt; $rs[31] = 0 (d.h. $rs ≥ 0) und $rs ≠ 0<br> PC ---+---+ | + |--+-----------------+---+ 4 ----+---+ | |MUX|----- PC | +--+---+ | | | +------+---+ | | | + |---+ | imm --- (&lt;&lt; 2) -----+---+ | | $rs[31] -----------------o+---+ | | &amp; |--+ $rs --------(NOR32)------o+---+
复制<br>Schritt 3: Schaltung in Datenpfad einfügen und möglichst viele Komponenten wiederverwenden<br>
<br>
Zero-Signal gibt an, ob das ALU-Ergebnis = 0 ist! NOR32 kann durch zero-Signal ersetzt werden. <br>
Addierer und Multiplexer sind schon vorhanden, Befehle und Operanden (Register) laden ist auch vollständig vorhanden.<br>
=&gt; $rs[31] können wir durch das oberste Bit des ALU-Ergebnisses (oder des oberen ALU-Eingangs) erhalten <br>
Zusätzlich brauchen wir ein OR-Gatter zwischen dem AND und dem Multiplexer, um die Möglichkeit für andere Branch-Befehle offen zu halten. <br>Schritt 4: ein Steuersignal (und gegebenenfalls ein zusätzlicher Multiplexer) hinzufügen, um unseren Befehl zu de-/aktiveren<br>
<br>bgtz-Steuersignal ausgehend von der Control Unit bis zu dem neu eingefügten AND-Gatter einzeichnen. Dieses schaltet das UND-Gatter an/aus und damit auch den Befehl.
<br>b) Steuersignale setzen, um den Befehl auszuführen.<br>
<br>neues Steuersignal: BGTZ muss = 1 sein
<br>Branch = 0, das ist zwingend notwendig, den Branch = 1 bedeutet, dass BEQ ausgeführt wird.
<br>RegWrite = 0 =&gt; RegDst = X, MemToReg = X
<br>MemRead = MemWrite = 0
<br>Rechenoperation auswählen (Addition) <br>ALUOp = 00
<br>ALUSrc = 0!! obwohl I-Typ-Befehl (weil wir die Immediate nicht für ALU sondern PC-Berechnung nutzen) <br>das können wir machen, weil $rt = $0 ist ]]></description><link>rechnerorganisation/rorg_tut09.html</link><guid isPermaLink="false">Rechnerorganisation/Rorg_tut09.md</guid><pubDate>Sun, 21 Apr 2024 20:24:33 GMT</pubDate><enclosure url="rechnerorganisation/20230211202202.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="rechnerorganisation/20230211202202.png"&gt;&lt;/figure&gt;</content:encoded></item></channel></rss>